---
title: QEUR23_VIVLM20 –  閑話休題～SOART3メトリックスの有効性を振り返る
date: 2024-09-29
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM20 –  閑話休題～SOART3メトリックスの有効性を振り返る

## ～ RT法というモノが、そもそも「良しあし」 ～

D先生 ： “（まえがき）Phi3-visionのVLM(Vision Language Model)を外観検査作業に適用するためのテストを行っており、正解が出てこないため壁にぶつかってしまいました。単純に不良画像をVLMにファインチューニングさせるだけでは判別精度があがらないですね。”

![imageVLM1-20-1](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-1.jpg)

QEU:FOUNDER ： “・・・ですから、以前、我々が見事に成功した「Vit+SOART3メトリックスによる外観検査自動機」の前処理（合成画像の生成）の精神に立ち返りたいと思います。まずはSOART3メトリックスを見てみましょう。もちろん、これはRT（Recognition Taguchi）の応用技術です。”

**(RT法とは？)**

![imageVLM1-20-2](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-2.jpg)

**(SOART3システム図)**

![imageVLM1-20-3](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-3.jpg)

D先生 ： “SOART3というのは、自分で言うのも何ですが**「変な手法」**です。RGBの画像をグレースケール化し、それを再度RGB画像に変換するために、「一次主成分(beta)」、「マンハッタン距離(yita)」および「チェビシェフ距離(gamma)」を使っているんですよね。そもそも、外観検査の自動化において、SOART3はどのような有用性があるのですか？”

![imageVLM1-20-4](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-4.jpg)

QEU:FOUNDER ： “**外観検査というのは、せいぜい画像の5%だけが違う状態を検出するものです。**それに対して、一般的に人々がVLMの判別精度がよいと騒ぐのは、犬と猫の画像を判別できるということなのです。そもそも、「良品と不良品の画像」と「犬とネコの画像」の判別では、VLMに要求されている能力が違います。だから、VLMでも、その「たった5%の異常部」を検出できるように画像を工夫しなければいけません。それでは、「閑話休題」として、むかしやってみたSOART3メトリックスをもう一度生成させてみましょう。”

![imageVLM1-20-5](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-5.jpg)

QEU:FOUNDER ： “サンプルは上記の通りです。「標準の画像」は角を丸めた正方形です。これを各図形の画像と比較するとどうなるか。ただし、この図形をグレースケール値に変換したCSVファイルとして入力したところから始まります。それでは解析用のプログラムをドン！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: metrics_via_SOART3.py
# SOART3メトリックスを出力する
# ---------------------------------------------------
# モジュールのインポート
from fastai.vision.all import *
import pandas as pd
import numpy as np
from scipy.spatial.distance import chebyshev

# ----
# ファイル参照先
nam_dir = "./soartc/"
nam_subdir1 = "IMAGE/"
nam_subdir2 = "INPUT/"
nam_subdir3 = "SOARTC_CONV/"
nam_subdir4 = "OUTPUT/"

#=================================================
# READ CSV FILES
#=================================================
# 画像ファイルを読み込み
def read_imagecsv(file_readcsv): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ---------------------------
    # イメージXs
    #mx_Xs = df.loc[:,"col1":"col11"].values
    mx_Xs = df.loc[:,:].values
  
    return mx_Xs

#=================================================
# MAIN PROGRAM : マトリックスの生成と合成画像の表示
#=================================================
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # 絶対値（マンハッタン）距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma

# ---------------------------
# Primitive image(beta, yita, gamma)を計算する
def calc_PrimImage(arr_standard, arr_measure): 

    # SOART3メトリックスの計算
    beta, yita, gamma = calc_soaRT3(arr_standard, arr_measure)             
    # -----
    #print("--- layer:0 ---")
    #print(mx_soart[100:120,100:120,0])

    arr_soart = [round(beta,5), round(yita,5), round(gamma,5)]

    return arr_soart

#=================================================
# SUB PROGRAM : 画像ファイルを読み込む、パラメタを指定する
#=================================================
# 標準画像を読み込み表示する
standard_image = "image_standard_rect"
# ---
list_image = ["NA"]*9
list_image[0] = "image_circle"
list_image[1] = "image_cross"
list_image[2] = "image_missing_circle"
list_image[3] = "image_missing_circle_20_0_0"
list_image[4] = "image_missing_circle_20_10_-10"
list_image[5] = "image_rotated_rect"
list_image[6] = "image_rotated_rect_20_0_0"
list_image[7] = "image_rotated_triangle_20_0_-10"
list_image[8] = "image_rounded_rect"

# ----
# 標準データの読み込み
filename = nam_dir+nam_subdir2+standard_image+".csv"
print(filename)
mx_standard = read_imagecsv(filename)
# ---
# 正規化
arr_standard = mx_standard.flatten()/255
print("--------")
print(arr_standard)

# ----
mx_soart = np.zeros((len(list_image), 3))
# 計測データの読み込みとSOART3メトリックスの生成
for i in range(len(list_image)):
    filename = nam_dir+nam_subdir2+list_image[i]+".csv"
    print(filename)
    mx_measure = read_imagecsv(filename)
    # ---
    # 正規化
    arr_measure = mx_measure.flatten()/255
    #print("--------")
    #print(arr_measure)

    # ---------------------------
    # Primitive image(beta, yita, gamma)を計算する
    arr_soart = calc_PrimImage(arr_standard, arr_measure)
    print("i:{}, arr_soart:{}".format(i,arr_soart))
    mx_soart[i, :] = arr_soart

# ------
# データフレームを形成する
arr_column = ["beta", "yita", "gamma"]
df_out = pd.DataFrame(mx_soart, columns=arr_column)
# 出力ファイル名を追加する
df_out["filename"] = list_image
print(df_out)

# ------
# CSVファイルへの出力
filename_csv = nam_dir+nam_subdir4+"soartc_csvfiles.csv"
df_out.to_csv(filename_csv)
```

QEU:FOUNDER ： “解析した結果は以下の通りです。3次元になっているので、これはRGB画像とすることができます。”

![imageVLM1-20-6](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-6.jpg)

D先生 ： “標準図形は「角を丸めた正方形」です。ですから、似たタイプの図形のyita値とgamma値が0に近くなるのはわかります。それにしても、beta値（主成分値）って、どうやって解釈すればいいんでしょうね？”

QEU:FOUNDER ： “そもそもbeta値が、きわめて小さいでしょ？つまり、beta値って、**それほど役に立たない**んですよ。”

D先生 ： “それを言ってはおしまい。RT法の存在意義が・・・。”

![imageVLM1-20-7](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-7.jpg)

QEU:FOUNDER ： “画像判定手法としてのRT法は、その定義から見て、以下の制約の下でのみ有効になります。”

- 対象（標準、計測）図形が極めて似ていること。
- 対象図形がブロブ（輪郭が閉じた図形）であること。
- 対象図形の画素値がより１に近く、背景がより0に近いこと。
- 対象図形の主要な差異が回転であること。

D先生 ： “いやあRT法は使いにくい・・・。もちろん、RT法程度の手法でも、それなりに図形の特徴を圧縮するので、ディープラーニングと併用すると役には立ちますが・・・。”

![imageVLM1-20-8](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-8.jpg)

QEU:FOUNDER ： “SOART3について、ここまで突き詰めて考えると、（我々が）その進化版であると提案したSOARTC（↑）の弱点が見えてきます。とりあえず、SOARTCメトリックスの計算フローを見てみましょう。”

**（SOARTC-上）**

![imageVLM1-20-9](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-9.jpg)

**（SOARTC-下）**

![imageVLM1-20-10](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-10.jpg)

D先生 ： “そうか・・・。SOARTC法って、マルチRT法でしたよね。忘れていました。開発の経緯からみると、まずSOART３を提案した後で、次にSTEP2（下）を追加しました。だから、今から考えると解析手法の流れが不自然です。SOARTC法をもっと改善できそうですね。FOUNDER・・・。現在のSOARTC法が不足している部分はなんだと思いますか？”

- STARTCはグレースケール画像のみであり、カラー(RGB)に適用できない。
- 処理に計算時間がかかる。
- メトリックス画像化すると、図形の輪郭がのこり、異常部分が強調されていない。

QEU:FOUNDER ： “カラーに適用できないこと、計算時間がかかるのは良くないですね。ただし、ブルーの輪郭線の存在自体は、（ViTによる）識別精度には影響を与えません。”

D先生 ： “あれ？ロジックが矛盾しています。カラー(RGB)の画像データと使うと、余計に計算時間がかかるんじゃないですか？”

QEU:FOUNDER  ： “そうだね。小生の意味は、**「カラー画像対応になるので計算時間はかかるが、処理方法がエレガントになるので従来法よりも計算が速くなる」**という意味です。これから、新しいSOARTCメトリックス(N-SOARTC)実験を始めましょう。”

## ～ まとめ ～

QEU:FOUNDER ： “すごいなあ。この人は（↓）・・・。”

[![MOVIE1](http://img.youtube.com/vi/54ltqPpB-s4/0.jpg)](http://www.youtube.com/watch?v=54ltqPpB-s4 "第１３回 浜矩子さん（経済学者）グレートウーマンに会いに行く～それぞれの人生と活動にリスペクトを込めて～")

C部長 : “**「女は度胸、男は愛嬌」**だそうです。”

![imageVLM1-20-11](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-11.jpg)

QEU:FOUNDER ： “確かに、女性の方が空気を読まない感じがあります。やっぱり、すごいですね。”

C部長 : “新しく、男性の**「エライ人」**が選ばれたそうですが・・・。彼は、口で言ったことを実行できるか・・・。”

QEU:FOUNDER ： “そんなもん興味ないです。もう、世の中が大きく変わっているので、J弱小国のトップの交代程度では何も変わりません。”

C部長 : “ひょっとしたら、**「J国の付近が険呑な雰囲気になる」**かもしれませんよ。”

![imageVLM1-20-12](/2024-09-29-QEUR23_VIVLM10/imageVLM1-20-12.jpg)

QEU:FOUNDER ： “本人はいろいろ言ってますが、自分が冷や飯食った時間が長すぎて、**平成時代でJ国が少しづつ弱小国になった自覚がマヒした**のかな？政治の頂点に上った後で周りの景色をみれば、**自分が言っていたことがおとぎ話の世界であった**ことが自動的にわかるでしょう。**あくまで先人が創った平和の遺産を維持するのが吉・・・。**”
