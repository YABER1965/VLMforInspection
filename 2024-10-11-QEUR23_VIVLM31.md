---
title: QEUR23_VIVLM31 : TraVisionLMモデルでOD推論をやってみた
date: 2024-10-11
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM31 : TraVisionLMモデルでOD推論をやってみた

## ～ 他のやり方もやってみましょう ～

QEU:FOUNDER ： “今回から、いよいよFlorence（以下FL）を使った**OD(Object Detection:物体検出)**をやってみましょう！！”

![imageVLM1-31-1](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-1.jpg)

D先生 ： “さっき、HuggingFaceから、おもしろいモデルを見つけました。**TraVisionLM（以下TRV）**といいます。なんとTU国の成果物です。”

![imageVLM1-31-2](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-2.jpg)

QEU:FOUNDER ： “おもしろい・・・。ちょっと、遊んでみましょう。プログラムをドン！！”

```python
# -----
from transformers import AutoModelForCausalLM, AutoProcessor
import torch
import requests 
from PIL import Image

# ---
model_id = 'ucsahin/TraVisionLM-Object-Detection-ft'
#model_id = 'microsoft/Florence-2-large-ft'
# ---
model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, de-vice_map="cuda")
processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
# ---
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg"
image = Image.open(requests.get(url, stream=True).raw).convert("RGB")

prompt = "Caption: car"     # İşaretle: araba
# prompt = "Detect: car"   # Tespit et: araba

inputs = processor(text=prompt, images=image, return_tensors="pt").to("cuda")

outputs = model.generate(**inputs, max_new_tokens=512, do_sample=True, temperature=0.6, top_p=0.9, top_k=50, repetition_penalty=1.2)

output_text = processor.batch_decode(outputs, skip_special_tokens=True)[0]

print("Model response: ", output_text)

```

QEU:FOUNDER ： “オリジナルのプロンプトはTU語なのですが、むりやりE語を入力するとどうなるか・・・。”

![imageVLM1-31-3](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-3.jpg)

D先生 ： “おおっ・・・。キャプションと、**キャプション用BOXの位置座標が出力されます**。ただし、E語のプロンプトに対して、TU語の出力ですね。”

QEU:FOUNDER ： “たぶん、Pre-training学習データには、E語がなかったようです。それでも、BOXがちゃんと検出されているので立派なモノです。せっかくキャプション用BOX座標があるので、画像を出力してみましょう。”

![imageVLM1-31-4](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-4.jpg)

D先生 ： “見事にBOXが作画されていますね。ひょっとして、モデルを「FL-2」に切り替えてやってみましたか？”

QEU:FOUNDER ： “全く同じプログラムでモデルをFLにかえてやってみました。キャプション文字は出てきますが、**BOX座標がでてきません**。”

D先生 ： “この2つは、全く構造が違ったモデルなんですね。”

QEU:FOUNDER ： “なんというか・・・。**TRVの方がFLよりもLLMの構造に近い**です。その分だけモデルのサイズが大きくなっているのかな？それでも、**サイズはたった3GB**ですよ。Phi-3-miniよりも小さいです。”

D先生 ： “じゃあ、これを使って遊んでみましょう。”


## ～ まとめ ～


QEU:FOUNDER ： “おっと、とうとう**「あの推理話（↓）」**が他のチャンネルからも聞こえるようになった！”

[![MOVIE1](http://img.youtube.com/vi/KKpr5_Shmn0/0.jpg)](http://www.youtube.com/watch?v=KKpr5_Shmn0 "ヘイトの犬笛吹きをGoogleトレンドで突き止める 菅野完さん")

C部長 : “この話は**とても刺激的**ですからね。“

QEU:FOUNDER ： “ある意味で、タイミングが良く出てきました。ある意図を感じるが・・・。特に、**A知県の情勢は非常に注目**しています。”

![imageVLM1-31-5](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-5.jpg)

C部長 : “そう・・・？ “

![imageVLM1-31-6](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-6.jpg)

QEU:FOUNDER ： “あの地方の**「下部構造（サプライチェーン体制）」が相当変わる**と思います。”

C部長 : “そうかなあ・・・。 “

![imageVLM1-31-7](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-7.jpg)

QEU:FOUNDER ： “あれだけの「お金持ちの市」のお偉いさんが、**なんの意図もなく途中でやめるとは思えない**んだよねえ・・・。

[![MOVIE2](http://img.youtube.com/vi/WwXfRlsUzh8/0.jpg)](http://www.youtube.com/watch?v=WwXfRlsUzh8 "既に自民党は崩壊している？衆議院選挙後に起きる日本政治の再編を考える。")

C部長 : “今回の選挙は、リベラルの勢いが強いので、それへの**「保守としての義憤」**だと思いますが・・・。 “

![imageVLM1-31-8](/2024-10-11-QEUR23_VIVLM31/imageVLM1-31-8.jpg)

QEU:FOUNDER ： “さっき、選挙の立候補予定者一覧を長い間見てたんだけど、もう面白くってしかたがない。小生の第一印象もこの人（↑）と同じですよ。ちょっと出馬の乱雑さがひどすぎ・・・。今回は、下部構造の本質的な変化が引き起こす、**国家構造の歴史的な変化の手前**なんじゃないでしょうか・・・。”
