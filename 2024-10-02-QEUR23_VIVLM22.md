---
title: QEUR23_VIVLM22: メトリックスを使った不良画像の可視化
date: 2024-10-02
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM22: メトリックスを使った不良画像の可視化

## ～ 本当に、簡単にできます ～

QEU:FOUNDER ： “それでは、いよいよメトリックスを使った画像の生成をします。前回のSOARTCとの最も大きな違いは**カラー(RGB)化されている**ことです。今回のテスト画像は、以下の不良画像です。これを標準画像と比較して、合成画像を生成します。”

![imageVLM1-22-1](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-1.jpg)

D先生 ： “今回は、なんの**「距離」を使う**んですか？”

![imageVLM1-22-2](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-2.jpg)

QEU:FOUNDER ： “**ミンコフスキー距離**にしています。なにしろ、「味付け」が自由自在ですからね、それでは、プログラムをドン！！”

```python
# ---
import numpy as np
import pandas as pd
from PIL import Image
import torch
import torch.nn.functional as F
from scipy.spatial.distance import minkowski

###########################
# 共通の部品関数
###########################
def read_csv_to_tensor(file_path):
    df = pd.read_csv(file_path)
    data = df.loc[:, "col1":"col11"].values
    tensor = torch.tensor(data, dtype=torch.float32)
    return tensor

def calc_convolution(mx_channel, filter_matrix):
    temp_tensor = torch.tensor(mx_channel, dtype=torch.float32)
    channel_matrix = temp_tensor.unsqueeze(0).unsqueeze(0)
    conv_matrix = F.conv2d(channel_matrix, filter_matrix, stride=5)
    out_matrix = conv_matrix.squeeze().cpu().numpy()
    return out_matrix

###########################
# クラスの定義
###########################
# ---
# Grey Imageを生成する
class GreyImageProcessor:
    def __init__(self, input_image_path, kernel_dir, output_dir):
        self.input_image_path = input_image_path
        self.kernel_dir = kernel_dir
        self.output_dir = output_dir
        self.gray_channel = self.read_image()

    def read_image(self):
        with Image.open(self.input_image_path) as img:
            gray_image = img.convert('L')
        img_array = np.array(gray_image)
        gray_channel = img_array[:, :] / 255.0
        return gray_channel

    def create_Greymatrix(self, name_kernel):
        kernel_path = f"./{self.kernel_dir}/{name_kernel}"
        filter_matrix = read_csv_to_tensor(kernel_path).unsqueeze(0).unsqueeze(0)
        out_matrix = calc_convolution(self.gray_channel, filter_matrix)
        return out_matrix

# ---
# RGB Imageを生成する
class RGBImageProcessor:
    def __init__(self, input_image_path, kernel_dir, output_dir):
        self.input_image_path = input_image_path
        self.kernel_dir = kernel_dir
        self.output_dir = output_dir
        self.red_channel, self.green_channel, self.blue_channel = self.read_image()

    def read_image(self):
        with Image.open(self.input_image_path) as img:
            img = img.convert("RGB")
        img_array = np.array(img)
        red_channel = img_array[:, :, 0] / 255.0
        green_channel = img_array[:, :, 1] / 255.0
        blue_channel = img_array[:, :, 2] / 255.0
        return red_channel, green_channel, blue_channel

    def create_RGBmatrix(self, name_kernel):
        kernel_path = f"./{self.kernel_dir}/{name_kernel}"
        filter_matrix = read_csv_to_tensor(kernel_path).unsqueeze(0).unsqueeze(0)
        red_out_matrix = calc_convolution(self.red_channel, filter_matrix)
        green_out_matrix = calc_convolution(self.green_channel, filter_matrix)
        blue_out_matrix = calc_convolution(self.blue_channel, filter_matrix)
        return red_out_matrix, green_out_matrix, blue_out_matrix

###########################
# まとめ関数
###########################
# ---
# グレースケール関数
def Calc_Grayscale(kernel_dir, output_dir, arr_names_kernel, Gray_image_path):
    # ---
    # RGBインスタンス化
    Gray_processor = GreyImageProcessor(Gray_image_path, kernel_dir, output_dir)
    # RGB繰り返し計算
    # image size: 382 x 214 -> 214,382,7
    Gray_matrix_all = np.zeros([214,382,7])
    for i, name_kernel in enumerate(arr_names_kernel):
        gray_matrix = Gray_processor.create_Greymatrix(name_kernel)
        Gray_matrix_all[:,:,i] = gray_matrix
    return Gray_matrix_all

# ---
# RGBスケール関数
def Calc_RGBscale(kernel_dir, output_dir, arr_names_kernel, RGB_image_path):
    # ---
    # RGBインスタンス化
    RGB_processor = RGBImageProcessor(RGB_image_path, kernel_dir, output_dir)
    # RGB繰り返し計算
    # image size: 382 x 214 x 3 -> 214,382,3,7
    RGB_matrix_all = np.zeros([214,382,3,7])
    for i, name_kernel in enumerate(arr_names_kernel):
        red_out_matrix, green_out_matrix, blue_out_matrix = RGB_processor.create_RGBmatrix(name_kernel)
        RGB_matrix_all[:,:,0,i] = red_out_matrix
        RGB_matrix_all[:,:,1,i] = green_out_matrix
        RGB_matrix_all[:,:,2,i] = blue_out_matrix
    return RGB_matrix_all

# ---
def Draw_DSTImage(RGB_image_path):
    # ---
    # パラメタを設定する
    kernel_dir = "SOARTC_CONV"
    output_dir = "output_images"
    arr_names_kernel = [
        "BEND1.csv", "BEND2.csv", "BEND3.csv", "BEND4.csv", 
        "LINE1.csv", "LINE2.csv", "DATUM.csv"
    ]
    # ---
    # 画像の設定
    Gray_image_path = 'average_pic_circle.jpg'
    #RGB_image_path = 'camera0_0_492_400_89_0_0_BENDNG.png'
    # ---
    # 画像マトリックス生成
    Gray_matrix_all = Calc_Grayscale(kernel_dir, output_dir, arr_names_kernel, Gray_image_path)
    RGB_matrix_all  = Calc_RGBscale(kernel_dir, output_dir, arr_names_kernel, RGB_image_path)
    # ---
    # 距離(DST)メトリックスの生成
    DST_matrix = np.zeros([214,382,3])
    for i in range(214):
        for j in range(382):
            arr_gray  = Gray_matrix_all[i,j,:]
            arr_red   = RGB_matrix_all[i,j,0,:]
            arr_green = RGB_matrix_all[i,j,1,:]
            arr_blue  = RGB_matrix_all[i,j,2,:]
            # ---
            # ミンコフスキー距離（Minkowski Distance）
            val_red   = minkowski(arr_gray, arr_red, 4) # p=4 
            val_green = minkowski(arr_gray, arr_green, 4) # p=4 
            val_blue  = minkowski(arr_gray, arr_blue, 4) # p=4 
            DST_matrix[i,j,:] = [val_red, val_green, val_blue]
    # ---
    # 距離画像を出力する
    max_data = np.max(DST_matrix)
    out_image = (255 * DST_matrix / max_data).astype(np.uint8)
    image_DST = Image.fromarray(out_image)
    out_filename = f'{RGB_image_path}_DST.jpg'.replace(".png", "")
    out_filename = out_filename.replace("./", "")
    out_filename = out_filename.replace("/", "_")
    image_DST.save(f'./{output_dir}/{out_filename}')

###########################
# MAIN関数
###########################
# ---
# Excelファイルからデータフレームを作成
df = pd.read_excel('file_42YM10.xlsx')
#df

# ---
num_df = len(df)
arr_outFilename = df.loc[:,"file_name"]
for i in range(num_df):
    RGB_image_path = arr_outFilename[i]+".png"
    print(RGB_image_path)
    Draw_DSTImage(RGB_image_path)

```

QEU:FOUNDER ： “このプログラムを使えば、**(Pytorch)テンソルの威力**で手軽に差分画像が手に入ります。”

![imageVLM1-22-3](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-3.jpg)

D先生 ： “見た目は白黒になっていますが、これは**「カラー」**なんでしょ？”

QEU:FOUNDER ： “そうです。ですから、**端子（円柱）の色に異常が発生した場合にも画像で検出してくれます**。”

![imageVLM1-22-4](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-4.jpg)

D先生 ： “前回のSOARTCマルチ法の場合には、フレーム状の画像ができました。この手法を、今回のやり方でシミュレートできますか？”

QEU:FOUNDER ： “D先生は、このスタイルが好みなの？じゃあ、このアウトプットに近づけてみましょう。メトリックスを2次加工する簡単な処理を加えるとフレーム画像になります。差分のプログラムのみを示します。”

```python
# ---
def metrics_Diff(arr_input):
    #arr_names_kernel = [
    #    "BEND1.csv", "BEND2.csv", "BEND3.csv", "BEND4.csv", 
    #    "LINE1.csv", "LINE2.csv", "DATUM.csv"
    #]
    # arr_gray  = Gray_matrix_all[i,j,:]
    val1 = arr_input[0] - arr_input[2] + 0.01
    val2 = arr_input[1] - arr_input[3] + 0.01
    val3 = arr_input[4] - arr_input[5] + 0.01
    return np.array([val1, val2, val3])

# ---
def Draw_DSTImage(RGB_image_path):
    # ---
    # パラメタを設定する
    kernel_dir = "SOARTC_CONV"
    output_dir = "output_images"
    arr_names_kernel = [
        "BEND1.csv", "BEND2.csv", "BEND3.csv", "BEND4.csv", 
        "LINE1.csv", "LINE2.csv", "DATUM.csv"
    ]
    # ---
    # 画像の設定
    Gray_image_path = 'average_pic_circle.jpg'
    #RGB_image_path = 'camera0_0_492_400_89_0_0_BENDNG.png'
    # ---
    # 画像マトリックス生成
    Gray_matrix_all = Calc_Grayscale(kernel_dir, output_dir, arr_names_kernel, Gray_image_path)
    RGB_matrix_all  = Calc_RGBscale(kernel_dir, output_dir, arr_names_kernel, RGB_image_path)
    # ---
    # 距離(DST)メトリックスの生成
    DST_matrix = np.zeros([214,382,3])
    for i in range(214):
        for j in range(382):
            arr_gray  = Gray_matrix_all[i,j,:]
            arr_red   = RGB_matrix_all[i,j,0,:]
            arr_green = RGB_matrix_all[i,j,1,:]
            arr_blue  = RGB_matrix_all[i,j,2,:]
            # ---
            # ミンコフスキー距離（Minkowski Distance）
            val_red   = minkowski(metrics_Diff(arr_gray), metrics_Diff(arr_red), 4) # p=4 
            val_green = minkowski(metrics_Diff(arr_gray), metrics_Diff(arr_green), 4) # p=4 
            val_blue  = minkowski(metrics_Diff(arr_gray), metrics_Diff(arr_blue), 4) # p=4 
            # ---
            DST_matrix[i,j,:] = [val_red, val_green, val_blue]
    # ---
    # 距離画像を出力する
    max_data = np.max(DST_matrix)
    out_image = (255 * DST_matrix / max_data).astype(np.uint8)
    image_DST = Image.fromarray(out_image)
    out_filename = f'{RGB_image_path}_DST.jpg'.replace(".png", "")
    out_filename = out_filename.replace("./", "")
    out_filename = out_filename.replace("/", "_")
    image_DST.save(f'./{output_dir}/{out_filename}')

```

QEU:FOUNDER ： “元の方法と差分法は良し悪しだと思うんです。形状に変化が発生するタイプのエラーには、この差分法がしっかりと反応するんじゃないかなあ・・・。”

![imageVLM1-22-5](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-5.jpg)

D先生 ： “ただし、**フレーム状になると本当の不良事象と画像の回転やシフトで発生する画像ズレとの区別がつきにくい**ですね。”

QEU:FOUNDER ： “外観検査のための機械でしょ？**「治具をもっとしっかりしてよ！」**と言いたいですよね(笑)。”

D先生 ： “画像の回転やシフトをソフトウェアでおさえることはできますか？”

QEU:FOUNDER  ： “もちろん、**「がんばれば」**できるでしょう。でも、**その「頑張り」は必要なモノなんですか**？非常に賢いPhi3-visionが学習して回答してくれるんです。回転やシフトの影響なんかはすぐに理解してくれますよ。もちろん、前回の我々のアウトプットのような美しいAttention map画像（↓）を出すことは無理ですけどね。”

![imageVLM1-22-6](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-6.jpg)

D先生 ： “了解です。それでは、このNEW画像を使ってVLMを学習させてみたいですね。”

QEU:FOUNDER  ： “どんどん面白くなってきたでしょ？”


## ～ まとめ ～

QEU:FOUNDER ： “我らが宗主国様が・・・。ちょっと、このA国の状態は家臣としても気が重くなりますね。”

[![MOVIE1](http://img.youtube.com/vi/TwXZuJKbCSQ/0.jpg)](http://www.youtube.com/watch?v=TwXZuJKbCSQ "会田弘継 氏出演！「深層／真相のアメリカを考える」")

C部長 : “J国は奴隷じゃないの？それにしても、昔、オリンピックの獲得メダルデータを分析して、長期的に見たA国の凋落を可視化したFOUNDERが今更ぬけぬけと・・・（笑）。 “

![imageVLM1-22-7](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-7.jpg)

QEU:FOUNDER ： “このように、世の中が大きく変わっていますから・・・。小生は、A国の衰退を示しただけでなく、**「J国は弱小国」**って言っているでしょ？いよいよ、近々、**「ディエン・ビエン・フー(DIEN BIEN PHU)」がくる**よ！”

![imageVLM1-22-8](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-8.jpg)

QEU:FOUNDER ： “小生が、最近、常々「J国は弱小国」と言っているのは、**J国は世界のトレンドを作る力を失った**からですよ。せめて、**J国は15年前にASEANに入るべき**だった。”

![imageVLM1-22-9](/2024-10-02-QEUR23_VIVLM22/imageVLM1-22-9.jpg)

C部長 : “ついでにいうと、お役所的な東京偏重をやめ**沖縄重視に動くべ**きだった。そうすれば、**ASEANの中枢に手が届いた**・・・。ちなみに、いまでも遅くはないと思います。”
