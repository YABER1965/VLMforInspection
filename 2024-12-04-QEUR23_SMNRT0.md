---
title: QEUR23_SMNRT0 – Euclid距離を使ってSiamese NNを学習する
date: 2024-12-04
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT0 – Euclid距離を使ってSiamese NNを学習する

## ～ こんなに簡単な距離で予測ができるのに驚いた！！ ～

D先生 ： “今回は、Siamese Neural Netをプロセスの異常検出に適用するために、前回のプロジェクトと距離の概念を変えてみましょう。参考となる資料は見つかりました？”

![imageSMR1-1-1](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-1.jpg)

QEU:FOUNDER ： “おっと！ありました。我々の方向性にバッチリあっているものが・・・。**この事例はEuclid距離を使っています**。しかし、驚いたことにテーマが画像の分類なんです。”

C部長 ： “えっ？画像分類で、Euclid距離を使うんですか？”

![imageSMR1-1-2](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-2.jpg)

QEU:FOUNDER ： “このKaggle Notebookが使っているデータセットは、みなさんお馴染みの「fashion MNIST」です。何はともあれ、このプログラムを動かしてみましょう。Pythonコードをドン！！我々のテーマにとって重要でないSnippetは省略します。詳細は元のページ（↑）を参照してください。”

```python
# ---
# Import libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import random

# ---
# Download the library and store it
# load the dataset
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()

# ---
# Normalize and prepare the images to be used
train_images = np.array((train_images / 255.0), dtype="float32")
test_images = np.array((test_images / 255.0), dtype="float32")

# ---
# 類似しているかどうかを示す画像とそのタグのペアが必要になります。類似している場合は 1 の値を使用し、類似していない場合は 0 の値を使用します。
def create_pairs(x, digit_indices):
    pairs = []
    labels = []
    n = min([len(digit_indices[d]) for d in range(10)]) - 1 #What is the minimum amount of images that we have on a specific class
    for d in range(10): #For all the classes
        for i in range(n): #For the minimum amount in one class
            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1] #Take 2 indices in the same class
            pairs += [[x[z1], x[z2]]]
            inc = random.randrange(1, 10)
            dn = (d + inc) % 10
            z1, z2 = digit_indices[d][i], digit_indices[dn][i] #Take 2 indices from different classes
            pairs += [[x[z1], x[z2]]]
            labels += [1, 0] #The first couple of images are similar, the second are different 
            
    return np.array(pairs), np.array(labels)

def create_pairs_on_set(images, labels):
    # Function to get indices of the same class and create couples of images 
    # Parameters
    # images (np.ndarray): mnist images
    # labels(np.ndarray): mnist tags 
    digit_indices = [np.where(labels == i)[0] for i in range(10)] #Get a list of arrays with the indices
    pairs, y = create_pairs(images, digit_indices)
    y = y.astype('float32')
    
    return pairs, y

train_pairs, train_labels = create_pairs_on_set(train_images, train_labels)
test_pairs, test_labels = create_pairs_on_set(test_images, test_labels)

# ---
# Let's see some images
def plot_images(train_pairs, train_labels):
    n = np.random.randint(train_pairs.shape[0])
    plt.subplot(1,2,1)
    plt.imshow(train_pairs[n,0,:,:])
    plt.subplot(1,2,2)
    plt.imshow(train_pairs[n,1,:,:])
    if train_labels[n] == 1:
        print("Images are similar")
    else:
        print("Images are not similar")
plot_images(train_pairs, train_labels)
```

D先生 ： “1枚だけ、サンプル画像をみてみましょう。”

![imageSMR1-1-3](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-3.jpg)

QEU:FOUNDER ： “当たり前のこと、画像はペアになります。プログラムはつづきます。ここが、今回のポイントになる関数です！！”

```python
# ---
# Calculate euclidean distance
def euclidean_distance(vects):
    x, y = vects    # １次元ベクトル-外カッコつき
    #x = np.array([x.flatten()])
    #y = np.array([y.flatten()])
    sum_square = np.sum(np.square(x - y), axis=1, keepdims=True)
    return tf.keras.backend.sqrt(tf.keras.backend.maximum(sum_square, tf.keras.backend.epsilon()))
# ---
#output = euclidean_distance(train_pairs[0])
#print(output)
#tf.Tensor([[11.888937]], shape=(1, 1), dtype=float32)

```

QEU:FOUNDER ： “この関数を特別に、独立させて動してみました。”

![imageSMR1-1-4](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-4.jpg)

D先生 ： “この関数を組み込みながらディープラーニングができるように、Kerasでテンソル変換がなされています。この部分が２つの画像を比較するために**ユーグリット距離をとっている**のですね。”

![imageSMR1-1-5](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-5.jpg)

QEU:FOUNDER ： “前回のSiamese NNのトライアルでは、この距離（↑）はラベルの一致性(0 or 1)で判断していました。ここでは、それがEuclid距離値になったわけです。我々は、今後、この関数だけを変えていくわけです。さて、Pythonプログラムはつづきます。”

```python
# ---
# モデルを構築し、カスタムレイヤーを定義して、2つの画像の違いを測定します。
def base_network():
    Input = tf.keras.layers.Input(shape=(28,28,), name="Input")
    L1 = tf.keras.layers.Flatten(name="flatten_input")(Input)
    L2 = tf.keras.layers.Dense(128, activation='relu', name="Dense_1")(L1)
    L3 = tf.keras.layers.Dropout(0.1, name="Dropout_1")(L2)
    L4 = tf.keras.layers.Dense(128, activation='relu', name="Dense_2")(L3)
    L5 = tf.keras.layers.Dropout(0.1, name="Dropout_2")(L4)
    Out = tf.keras.layers.Dense(128, activation='relu', name="Dense_3")(L5)
    model = tf.keras.models.Model(inputs=Input, outputs=Out)
    return model
# ---
base = base_network()
tf.keras.utils.plot_model(base, show_shapes=True, show_layer_names=True, to_file="base.png")

# ---
# create the left input and point to the base network
input1 = tf.keras.layers.Input(shape=(28,28,), name="Input_layer1")
output1 = base(input1)

# create the right input and point to the base network
input2 = tf.keras.layers.Input(shape=(28,28,), name="Input_layer2")
output2 = base(input2)

# Custom Lambda layer; measure the similarity of the two vector outputs
output = tf.keras.layers.Lambda(euclidean_distance, name="output_layer", out-put_shape=(1,))([output1, output2])

# Wrap the base network, inputs and lambda layer in a model
model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)

# plot model graph
tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='outer-model.png')

```

D先生 ： “Siamese NNのモデルが出てきました。”

![imageSMR1-1-6](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-6.jpg)

QEU:FOUNDER ： “もう、お馴染みのNN構造ですね・・・（笑）。”

```python
# ---
def contrastive_loss_with_margin(margin):
    def contrastive_loss(y_true, y_pred):
        square_pred = tf.keras.backend.square(y_pred)
        margin_square = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))
        return tf.keras.backend.mean(y_true * square_pred + (1 - y_true) * margin_square)
    return contrastive_loss

rms = tf.keras.optimizers.RMSprop()
model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=rms)

# ---
# モデルをトレーニングします。train_pairs変数は(119980, 2, 28, 28)の形状を持っていることを覚えておいてください。そのため、スライスtr_pairs[:,0]を使用して最初の画像を取得し、スライスtf_pairs[:,1]を使用して2番目の画像を取得します。
history = model.fit([train_pairs[:,0], train_pairs[:,1]], train_labels, epochs=25, batch_size=128, vali-dation_data=([test_pairs[:,0], test_pairs[:,1]], test_labels))

# Let's see some examples
predictions = model.predict([test_pairs[:,0], test_pairs[:,1]])

# ---
# utility to display a row of digits with their predictions
def display_images(left, right, predictions, labels, title, n):
    plt.figure(figsize=(17,3))
    plt.title(title)
    plt.yticks([])
    plt.xticks([])
    plt.grid(None)
    left = np.reshape(left, [n, 28, 28])
    left = np.swapaxes(left, 0, 1)
    left = np.reshape(left, [28, 28*n])
    plt.imshow(left)
    plt.figure(figsize=(17,3))
    plt.yticks([])
    plt.xticks([28*x+14 for x in range(n)], predictions)
    for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):
        if predictions[i] > 0.5: t.set_color('red') # bad predictions in red
    plt.grid(None)
    right = np.reshape(right, [n, 28, 28])
    right = np.swapaxes(right, 0, 1)
    right = np.reshape(right, [28, 28*n])
    plt.imshow(right)

# ---
predictions = np.squeeze(predictions)
indexes = np.random.choice(len(predictions), size=10)
display_images(test_pairs[:, 0][indexes], test_pairs[:, 1][indexes], predictions[indexes], test_labels[indexes], "clothes and their dissimilarity", 10)

```

D先生 ： “予測の結果が画像つきで出てきました。この場合、画像ラベルが不一致のときには、その出力値が1.0に近くなるんですね。”

![imageSMR1-1-7](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-7.jpg)

QEU:FOUNDER ： “まとめとして、今回のモデルの性能評価をしましょう。”

```python
# ----
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

pred_labels = []
for i in range(len(predictions)):
    if predictions[i] < 0.3:
        pred_labels.append(1)
    else:
        pred_labels.append(0)
print(pred_labels[0:20])

# ---
cm = confusion_matrix(test_labels, pred_labels)
print("--- CONFUSION MATRIX ---")
print(cm)

# ---
print("--- ACCURACY SCORE ---")
print(accuracy_score(test_labels, pred_labels))

# ---
sns.heatmap(cm)
plt.show()

```

C部長： “渋い結果ですね。**絶妙なバランスで「判別性能が微妙」です**・・・（笑）。”

![imageSMR1-1-8](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-8.jpg)

QEU:FOUNDER ： “今後、この性能が上がるかどうかが「見もの」なんです。”


## ～ まとめ ～

QEU:FOUNDER ： “いやあ、やるねえ・・・。K国は・・・。”

[![MOVIE1](http://img.youtube.com/vi/klWfdkQs3CY/0.jpg)](http://www.youtube.com/watch?v=klWfdkQs3CY "徐台教の韓国通信】尹錫悦大統領 非常戒厳令を発令")

C部長 : “はっきりいって、「ナニコレ！？」と思いました。こんなことで、ここまで重大なことができるのかと・・・。”

![imageSMR1-1-9](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-9.jpg)

QEU:FOUNDER ： “この手の「変なの」って、どこでもいます。さらに、そんな人がたまたま高い地位にいることがあります。**「そこを何とかする。しかも、一瞬で解決する」**のが、すごいですよね。K国リスペクト！・・・と、「パワハラ特区」住民でもない小生が言ってみます。”

![imageSMR1-1-10](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-10.jpg)

C部長 : “まあ、あの件（↓）を10年間以上も解決できないですから。J国は・・・。”

![imageSMR1-1-11](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-11.jpg)

QEU:FOUNDER ： “J国がK国よりも、少しマシなのは出生率の件だけかな？これについても、ここまでの**知性の有る国民**であれば、将来はなんとかなると思うんです。世界地図をイメージしながら、このランキングを見てください。”

![imageSMR1-1-12](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-12.jpg)

C部長 : “低いのは、東アジアですよね・・・。**女性蔑視の価値観**かな？”

![imageSMR1-1-13](/2024-12-04-QEUR23_SMNRT0/imageSMR1-1-13.jpg)

QEU:FOUNDER ： “南の国って、女性の社会進出がすごいですからね。**「統計上では女性が尊敬を得られていない」と言われているが、これは女性の社会進出が急激に発展し、それに相当するリスペクトがないから」**という意味だとおもうんです。そうでないと、こんなに急激に満足度が下がりません。”

[![MOVIE1](http://img.youtube.com/vi/rsftlfykEIg/0.jpg)](http://www.youtube.com/watch?v=rsftlfykEIg "あかたx菅野 読書会 上野千鶴子『家父長制と資本制』を読む")

QEU:FOUNDER ： “その一方で、遅れた文化が起因で社会進出が低い国では時間を問わず常に満足度が低くなるはずです。そういう意味で、この動画で述べている本の主旨は先進的なんでしょうね。”

C部長 : “失われた40年のお話でした。”
