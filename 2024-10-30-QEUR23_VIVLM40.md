---
title: QEUR23_VIVLM40 – vit-large-patch16-224でファインチューニングする
date: 2024-10-30
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM40 – vit-large-patch16-224でファインチューニングする

## ～ それなりに、モノになるのではないでしょうか（まだepoch数は少ないが） ～

QEU:FOUNDER ： “じゃあ、いよいよファインチューニングに行きましょう。今回は、比較的軽いモデルである「google/vit-large-patch16-224（以下G224）」でいきます。前回の繰り返しですが、学習データの中身はこんな感じ（↓）になっています。”

![imageVLM1-40-1](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-1.jpg)

D先生 ： “ただし、Florence-2ではないのですから、画像のようにキャプションはつきません。”

QEU:FOUNDER ： “G224はシンプルなディープラーニングモデルなので、キャプション付けの機能はありません。非常に簡単な画像分類のモデルですよ、Transformersがベースの・・・。それでは、プログラムに入りましょう。”

```python
######################################
# DATASET LOADING
######################################
# ---
from datasets import load_dataset

# ---
# データセットの読み込み
dataset = load_dataset("YxBxRyXJx/FRAMEimages_train_1028")

# ---
split_dataset = dataset["train"].train_test_split(test_size=0.2, shuffle=True)
ds_train = split_dataset["train"]
ds_val = split_dataset["test"]
# ----
dataset = load_dataset("YxBxRyXJx/FRAMEimages_test_1028")
ds_test = dataset["train"]
print("Train len: ", len(ds_train))
print("Val len: ", len(ds_val))
print("Test len: ", len(ds_test))

# ---
# Combine the splits into a new DatasetDict
final_dataset = {
    'train': ds_train,
    'val': ds_val,  # Validation set
    'test': ds_test  # Test set
}

# Display the structure of the final dataset
final_dataset

# ---
train_ds = final_dataset["train"]
val_ds = final_dataset["val"]
test_ds = final_dataset["test"]
train_ds[0]

```

QEU:FOUNDER ： “ここまでで、プログラムをtrain-validation-testの3種類に分割しています。モデルの学習に使うのはtrainとvalidationです。Testは学習後のモデル評価用です。ついでに、このデータセットの構成を再度みてみましょう。”

![imageVLM1-40-2](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-2.jpg)

D先生 ： “前回のデータセットの生成でも説明しましたが、今回のプロジェクトでは、responseとして**ディクショナリを使用している**んですね。”

QEU:FOUNDER ： “このresponse情報の構成の違いが**collatorの設計**の差異の原因になります。Responseからlabelを抽出する必要があります。その他のプログラムは、前回のものとほとんど変わりません。つづきにいきましょう。”

```python
#####################################
# responseからlabelを抽出する関数
#####################################
# ---
import ast

def resp_to_label(str_response):

    # 文字列を辞書に変換
    dictionary = ast.literal_eval(str_response)
    # 結果を表示
    #print(dictionary)
    # ---
    arr_bbox = dictionary['bboxes'][0]
    str_label = dictionary['labels'][0]
    #print(dictionary['bboxes'][0])
    #print(dictionary['labels'][0])

    return arr_bbox, str_label

str_response = train_ds[1]['response']
arr_bbox, str_label = resp_to_label(str_response)
print(str_response)
print(arr_bbox)
print(str_label)

#####################################
# 代表的な事例を表示する
#####################################
# ---
import matplotlib.pyplot as plt

# Initialize a set to keep track of shown labels
shown_labels = set()

# Initialize the figure for plotting
plt.figure(figsize=(15, 10))

# Loop through the dataset and plot the first image of each label
for i, sample in enumerate(train_ds):
    # ---
    str_response = sample['response']
    _, label = resp_to_label(str_response)
    if label not in shown_labels:
        plt.subplot(1, 4, len(shown_labels) + 1)
        plt.imshow(sample["image"])
        plt.title(label)
        plt.axis("off")
        shown_labels.add(label)
        if len(shown_labels) == 4:
            break
# ---
plt.show()

```

D先生 ： “このコードスニペットでは、データセットの中身を覗いているんですね。”

![imageVLM1-40-3](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-3.jpg)

QEU:FOUNDER ： “次では、**resp_to_label関数を使って、responseの辞書からlabelとして不良情報を抽出している**ことが技術的なポイントです。”

```python
# ---
id2label = {0: 'passed',
            1: 'Xplus',
            2: 'Xminus',
            3: 'Yplus',
            4: 'Yminus'}
# ---
label2id = {'passed': 0,
            'Xplus': 1,
            "Xminus": 2,
            'Yplus': 3,
            "Yminus": 4}

```

QEU:FOUNDER ： “このG224モデルは、生成AIではなく、伝統的なの機械学習モデルの**分類問題**のコンセプトに近いです。ですから、モデルの学習はIDがベースになっています。”

```python
######################################
# 判別用モデルを切換可能 (patch32-384 vs patch16-224)
######################################
# ---
from transformers import ViTImageProcessor

model_name = 'YxBxRyXJx/tanshi-models'
#model_name = 'google/vit-large-patch32-384'
#model_name = "google/vit-large-patch16-224"
processor = ViTImageProcessor.from_pretrained(model_name)
processor

# ---
from torchvision.transforms import (
    CenterCrop,
    Compose,
    Normalize,
    RandomHorizontalFlip,
    RandomResizedCrop,
    ToTensor,
    Resize,
)

image_mean, image_std = processor.image_mean, processor.image_std
size = processor.size["height"]

normalize = Normalize(mean=image_mean, std=image_std)

train_transforms = Compose(
    [
        RandomResizedCrop(size),
        RandomHorizontalFlip(),
        ToTensor(),
        normalize,
    ]
)

# ---
def apply_transforms(examples):
    examples["pixel_values"] = [train_transforms(image.convert("RGB")) for image in examples["image"]]
    return examples

# ---
train_ds.set_transform(apply_transforms)
val_ds.set_transform(apply_transforms)
test_ds.set_transform(apply_transforms)

# ---
import torch
from torch.utils.data import DataLoader

# ---
def collate_fn(examples):
    pixel_values = torch.stack([example["pixel_values"] for example in examples])
    # ---
    arr_label = []
    for example in examples:
        str_response = example['response']
        arr_bbox, str_label = resp_to_label(str_response)
        arr_label.append(label2id[str_label])
    # ---
    #labels = torch.tensor([example["label"] for example in examples])
    labels = torch.tensor(arr_label)
    return {"pixel_values": pixel_values, "labels": labels}

train_dl = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4)

batch = next(iter(train_dl))
for k, v in batch.items():
    if isinstance(v, torch.Tensor):
        print(k, v.shape)

# ---
from transformers import ViTForImageClassification

model = ViTForImageClassification.from_pretrained(
    model_name,
    num_labels = 5,   # len(labels)
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True
)

# ---
from transformers import TrainingArguments, Trainer
import numpy as np

train_args = TrainingArguments(
    output_dir="drive/MyDrive/google-vit/tanshi-models-224",
    per_device_train_batch_size=16,
    evaluation_strategy="steps",
    num_train_epochs=3,
    fp16=True,
    save_steps=100,
    eval_steps=20,
    logging_steps=50,
    learning_rate=2e-4,
    save_total_limit=2,
    remove_unused_columns=False,
    load_best_model_at_end=True,
)
     
trainer = Trainer(
    model,
    train_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    data_collator=collate_fn,
    tokenizer=processor,
)
trainer.train()

```

D先生 ： “おっと、ちゃんと学習が始まっていますね。”

![imageVLM1-40-4](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-4.jpg)

QEU:FOUNDER ： “ちゃんと学習損失がスムーズに減少しつづけているでしょう？”

D先生 ： “ステップ数は多いものの、epoch数ではたった2なんですね。たった2回のepoch数ですが、学習後のモデルの判別パフォーマンスはどの程度なのでしょうか？”

QEU:FOUNDER ： “じゃあ、**confusion matrixの型式**で見てみましょう。”

![imageVLM1-40-5](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-5.jpg)

D先生 ： “まだ、（パフォーマンスが）ぜんぜんダメですね。学習損失の推移を見ると、まだ学習が飽和する様子はなさそうです。Epochを増やす必要がありますね。”

QEU:FOUNDER ： “じゃあ、step5まで増やしてみましょう。結果だけをドン！！”

![imageVLM1-40-6](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-6.jpg)

D先生 ： “やっぱり、ずいぶんパフォーマンスがよくなってきました。まだ、学習の過程なんでしょうね。Epoch数は、いくらぐらい必要なのかなあ？”

QEU:FOUNDER ： “最低でも10epoch。もし、お金持ちのユーザであれば、15epochも投入すれば安心というところじゃない？・・・でも、小生としては計算時間がかかるから、もうやりたくないなあ・・・。あくまで、これはテストなんだし・・・。”

D先生 ： “でも、計算に時間がかかると言っても、A100を使っているわけじゃないでしょ？”

QEU:FOUNDER ： “**T4で十分です。**そもそもモデルのサイズが2GBもないですからね。ここら辺が、このシンプルなViTモデルのありがたいところです。”

D先生 ： “じゃあ、次は、なにをしますか？google/vit-large-patch32-384とか・・・。”

QEU:FOUNDER ： “いや。今回学習したG224のAttention mapをやりましょう。”


## ～ まとめ ～

C部長 : “J国の政治なんか、つまんなくありませんか？“

![imageVLM1-40-7](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-7.jpg)

QEU:FOUNDER ： “全然つまらないですよ。J国なんか、しょせん**「大波の中の笹船」**でしょう？自分では、自分の行きつく先をコントロールできないでしょう。そして、大波はコレ（↑）・・・。”

C部長 : “あそこで、何が決まったんでしょうね？ “

![imageVLM1-40-8](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-8.jpg)

QEU:FOUNDER ： “AIにきいてみたら、決定事項について親切に教えてくれました。ほんとに便利だわ、AI・・・。この中身にハルシネーションがあるのかは知らんけど・・・。これによると、BRICSのお金のアジェンダは２つあるようですね。一つは、**BRICS共通通貨**、もう一つは**自国通貨での決済システム**です。”

C部長 : “最近、よく聞く**「BRICS PAY」**は？ “

![imageVLM1-40-9](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-9.jpg)

QEU:FOUNDER ： “決済システムのことのようです。もしも、自国通貨で気軽に国際決済ができるのであればとてもありがたいわあ・・・。自国通貨決済が一番いいのは、**「自分の身の丈にあった取引ができること」**です。相手国とのwin-winになるような取引をすれば、貿易赤字がふえることはあり得ません。共通通貨になると財政がおかしくなるんです。その典型がリーマンのときのバルカン半島のG国です。”

[![MOVIE1](http://img.youtube.com/vi/hPOPEE5AGAg/0.jpg)](http://www.youtube.com/watch?v=hPOPEE5AGAg "藤井聡氏出演！『安倍政治総括と日本政治・経済の行方』")

C部長 : “海外に広く使われてきたドルが使われなくなるんだ・・・。どうなるんだろう、A国・・・。あっ、そうだ！われらが**ケルトン教授**によると、財政問題はないんだ！！ MYTH OF DEFICIT!! むかし、**「ひげの国士教授（↑）」**なんかが、虎の威を借る狐で大騒ぎしていたじゃないですか！！“

![imageVLM1-40-10](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-10.jpg)

QEU:FOUNDER ： “これもAI様に質問してみました。”

**(QUESTION)**

アメリカの国債発行残高が過去最高になっています。一方で、BRICS Payなどの脱ドル化が進んでいます。
ステファニー・ケルトン教授によると、アメリカが国債を多量に発行してもインフレ以外の経済への悪影響はないとしています。
現在の状況を考えると、ケルトン教授の考えるようにアメリカ経済は、今後も政府支出によって順調に成長できるのでしょうか？

The outstanding balance of US national debt is at an all-time high. At the same time, efforts to de-dollarize, such as through BRICS Pay, are underway.
According to Professor Stephanie Kelton, even if the US issues a large amount of national debt, there will be no negative impact on the economy other than inflation.
Given the current situation, is it possible for the US economy to continue to grow smoothly through government spending, as Professor Kelton believes?

C部長 : “ずいぶんダイレクトに質問しましたね。人間を相手にこういう質問するのは、怒られるんじゃないですか（笑）？ “

**(ANSWER)**

The current state of the U.S. national debt, which has surpassed $35 trillion, raises important ques-tions about the sustainability of government spending and its impact on economic growth. Professor Stephanie Kelton's perspective, rooted in Modern Monetary Theory (MMT), posits that the U.S. can continue to issue debt without detrimental effects on the economy, aside from potential inflation. This view is particularly relevant given the ongoing efforts to de-dollarize through initiatives like BRICS Pay.

35兆ドルを超える米国の国家債務の現状は、政府支出の持続可能性とそれが経済成長に与える影響について重要な疑問を提起しています。現代貨幣理論（MMT）に根ざしたステファニー・ケルトン教授の見解は、潜在的なインフレを除けば、米国は経済に悪影響を与えることなく債務を発行し続けることができるとしています。この見解は、BRICS Payなどのイニシアチブを通じてドル化を解消する取り組みが進行中であることを考えると、特に重要です。


**Current National Debt Situation：**

As of late 2023, the U.S. national debt reached a staggering $35 trillion, a figure that has been rising due to various factors, including tax cuts, stimulus packages, and increased defense spending12. The Congressional Budget Office (CBO) projects that federal debt held by the public will rise from about 99% of GDP in 2024 to 116% by 2034, indicating a persistent upward trajectory unless significant fiscal changes are made3.

2023 年末現在、米国の国家債務は驚異的な 35 兆ドルに達しており、この数字は減税、景気刺激策、国防費の増加など、さまざまな要因により増加しています12。議会予算局 (CBO) は、国民が抱える連邦債務が 2024 年の GDP の約 99% から 2034 年までに 116% に増加すると予測しており、大幅な財政改革が行われない限り、増加傾向が続くことを示しています3。

・・・ 略 ・・・

**Future Growth Prospects:**

Kelton's assertion that government spending can stimulate economic growth hinges on several fac-tors:
Productive Investment: If government spending is directed toward productive investments (e.g., in-frastructure, education), it could enhance economic capacity and growth potential.
Inflation Management: Effective management of inflation through monetary policy will be crucial. If inflation remains controlled, the negative impacts of increased debt may be mitigated.
Global Economic Context: The rise of alternatives to the dollar, such as BRICS Pay, poses risks to U.S. economic dominance and could impact future borrowing costs and currency stability4.
In conclusion, while Kelton's perspective offers a framework for understanding how government spending can theoretically support economic growth despite high debt levels, practical challenges such as rising interest payments, inflation risks, and political gridlock must be navigated carefully. The path forward will require balancing fiscal responsibility with strategic investments aimed at fos-tering sustainable economic growth.

政府支出が経済成長を刺激できるというケルトンの主張は、いくつかの要因にかかっています。
生産的投資: 政府支出が生産的投資 (インフラ、教育など) に向けられれば、経済力と成長の可能性を高めることができます。
インフレ管理: 金融政策によるインフレの効果的な管理が重要になります。インフレが抑制されれば、債務増加の悪影響は軽減される可能性があります。
世界経済の状況: BRICS Pay など、ドルに代わる通貨の台頭は、米国の経済的優位性にリスクをもたらし、将来の借入コストと通貨の安定性に影響を与える可能性があります4。
結論として、ケルトンの視点は、高い債務水準にもかかわらず、政府支出が理論的に経済成長を支える方法を理解するための枠組みを提供しますが、利払いの増加、インフレリスク、政治的行き詰まりなどの実際的な課題には慎重に対処する必要があります。今後の道のりでは、持続可能な経済成長を促進することを目的とした戦略的投資と財政責任のバランスを取る必要があります。

C部長 : “ケルトン教授って、B大統領が就任直後に大統領府経済顧問だったんじゃなかったでしたっけ・・・。“

QEU:FOUNDER ： “最近、国際情勢が変わり、**「（こいつの理屈は）ヤバイ・・・」と思われた**のではないでしょうか。ともあれ、このAI先生の回答（↓）は秀逸ですね。もちろん、AIが考えたものではなく、誰かが考えた内容を反映しているのでしょう。”

### 生産的投資: 政府支出が生産的投資 (インフラ、教育など) に向けられれば、経済力と成長の可能性を高めることができます。

QEU:FOUNDER ： “ケルトンさんの理屈って、近年の環境下では無意味なんですよね。むしろ、小生は、この動画(↓)を見てから「経済がわかった！！」と思わずさけんだもん。”

[![MOVIE2](http://img.youtube.com/vi/FCc8cojW3ZU/0.jpg)](http://www.youtube.com/watch?v=FCc8cojW3ZU "田内学×宮台真司：人を幸せにする経済とは")

C部長 : “この2人の経済の考え方は、最初に**「我々と外部世界に分けましょう」**と考えます。そして、**「我々（内部コミュニティ）の中の経済の在り方」**には大きな自由度があります。極端に言えば、中は物物交換だろうと、タダでモノを配ろうと問題ありません。 “

![imageVLM1-40-11](/2024-10-30-QEUR23_VIVLM40/imageVLM1-40-11.jpg)

QEU:FOUNDER ： “コミュニティ（国家）経済の前提は、**「われわれ（自国）と外部世界との交易がどのようになっているか」**だけです。例をいえば、自由な国際貿易が確立された現在では、戦争による植民地支配をする必要がないんです。**貿易を通じて搾取すればいい**わけで・・・。”

C部長 : “「搾取」って物騒な・・・。“

QEU:FOUNDER ： “**「貿易を通じた搾取」**って表現は、別に大げさじゃないよ。小生が言ったんじゃないよ。これは、石橋湛山の**「小日本主義」**の考え方です。国が豊かになるには、戦争は必要はない。貿易をすればよいだけだ。現に、リーマンのときにバルカンのG国が国家破産したでしょ？そういえば、バルカンのG国の主要産業って、当時はインバウンド（観光）と、海運、オリーブぐらいしかなかったじゃないですか・・・。”

C部長 : “インバウンド・・・。嫌な予感・・・。“
