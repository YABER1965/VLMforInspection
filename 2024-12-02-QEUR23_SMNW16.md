---
title: QEUR23_SMNW17 – 閑話休題～NSOARTCメトリックスができるまで
date: 2024-12-02
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW17 – 閑話休題～NSOARTCメトリックスができるまで

## ～ QEUシステムの成果のひとつ： RT法を進化させたこと ～

QEU:FOUNDER ： “NSOARTCメトリックスは、我々が考える外観検査用メトリックスの最終形になると思っています。ただし、「目下のところ」はね・・・。このメトリックの細かい解説は次回にするとして、今回は閑話休題（前座）として、どのようにしてこのメトリックスが開発されたのかについての簡単な歴史を説明したいとおもいます。”

D先生 ： “リニア(線形)理論をベースとしたRTメトリックスのロジックから離れ、非線形に対応した外観検査自動機用のNSOARTCメトリックスの開発まで8年ぐらいかかりました。思えば、これはQEUシステムがいかにタグチメソッドから離れていったかの8年でした。タグチ・メソッド（TM）の現状認識をドン！！”

![imageSMNW3-7-1](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-1.jpg)

QEU:FOUNDER ： “思えば、RT法の数理の改造が始まったのは、我々がRT法をディープラーニングと組み合わせて使うようになってからです。ディープラーニングを使うと、タグチメソッドの問題点がよくわかります。一言でいえば、**タグチメソッドは「リニア（線形）手法群」にすぎません**。さて、RT法は、いつ頃提案されたのでしょうか？D先生に質問ですよ、コレ・・・。”

![imageSMNW3-7-2](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-2.jpg)

D先生 ： “確か、ようやく21世紀になってからでしょう？その手法のすばらしさにTM信者が感動したと聞いています。そのJ国の局所的なお祭り騒ぎの一方で、ディープラーニングは少しづつ水面下で発展してきました。いまから思うと、RT法は1990年代にリリースしていれば、少しは普及していたでしょうね。”

![imageSMNW3-7-3](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-3.jpg)

QEU:FOUNDER ： “RT法って、結局のところ、ほとんど流行らなかったんですよね。まあ、あの程度のロジックなのであたりまえだが・・・。もし、世間の計算能力が圧倒的に少ない1990年代に公開されたならば、世間にかなりの感動を与えたかもしれません。この能天気の先生（↑）が言うように「複雑系～！」とまでは言えないが、ちょっと大胆な売り込みもできたかもしれない。”

**(QEU流RT法の発展史)**

- RT法（メトリックス）
- 新RT法
- SOART3法
- NSOARTC法

D先生 ： “それでは、はじめましょう。そもそものRT法の解説からはじめるといいですね。RT法とは、以下の図に示すように、如何に多次元のベクトルであっても、標準ベクトルを与えることによって、たった2次元に変換される方法です。2次元ベクトルになれば、マハラノビス距離を生成することは簡単です。”

![imageSMNW3-7-4](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-4.jpg)

QEU:FOUNDER ： “RT法って、21世紀になってリリースされても「鳴り物もならなかった」し、「モノにもならなかった」です。この方法は、競合手法との優位性からみて、「使える用途」がとても限定されるんです。以前にやってみた実験をもとに、RT法の限界を理解しましょう。”

![imageSMNW3-7-5](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-5.jpg)

QEU:FOUNDER ： “RT法は、**「ブロブ(blob)図形」**のみに効果を発揮します。しかも、**背景が黒（値が0に近い）こと**が必要です。RT法の長所は、判別に特に寄与するη成分は、blob図形が回転しても移動しても値が安定します。”

![imageSMNW3-7-6](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-6.jpg)

QEU:FOUNDER ： “その一方で、そのη値は、「図形が変形した」、「大きさが変化した」、「図形の色が変わった」ときに大きく変化します。この特性は、RT法を図形認識法として考えると良し悪しです。”

![imageSMNW3-7-7](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-7.jpg)

D先生 ： “もしも、図形の大きさと色に対しても値が安定していれば、RT法は使いでがあるんだがなあ・・・。”

QEU:FOUNDER ： “そのデメリットを補うために、我々は非線形手法（ニューラルネットetc）を使うのです。さて、その一方でη（ひずみ成分）値としてユーグリッド距離を使うことに対して、大きな疑念が生じました。”

![imageSMNW3-7-8](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-8.jpg)

D先生 ： “あ～あ、懐かしい・・・。ゲーム2048のプロジェクトですね。昔、このゲームを環境として強化学習をするためにRTメトリックスを使っていました。”

QEU:FOUNDER ： “RTメトリックスをつかった2048ゲームの強化学習の収束速度が悪かったのです。そこで、RTメトリックスのη成分をマンハッタン距離に変えたところ、より収束速度が速くなりました。つまり、画像認識の手段としては、**2乗距離より絶対値距離の方が判別性能が高い**のです。これが「新RT法」の誕生です。ここまでを、Python-snippetの形でまとめましょう。”

```python
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# ---------------------------
# New-RTメトリックスを計算する(テンソル活用版)
def calc_NewRT(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array

    # dot回転を計測
    xx = torch.dot(x,x) + 0.0001
    xy = torch.dot(x,y) + 0.0001
    beta = xy/xx.item()

    # 値距離を計測
    mDistance = L1_loss(y, beta*x)  # 絶対値距離（マンハッタン）
    mDistance = MSE_loss(y, beta*x)  # 二乗距離（ユーグリッド）
    #print("mDistance: ", mDistance.item())
    
    # 値を変換し、3つのメトリックスを生成する
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance.item()+1.0)
    
    return log_beta, log_yita

```

QEU:FOUNDER ： “これは、RTメトリックスのpython表現であり、伝統的なエクセル表現ではありません。Pythonで表現すると簡単になるでしょう？エクセル表現がお好きな、ディープな人は、その道のエライ人たちが**「エクセルでできる」本**を出していますので、それを使ってください。”

D先生 ： “その代わり、EXCELのロジックをプログラムにすると計算速度が圧倒的に遅くなります（笑）。ちなみに、このpythonコードでは「tensor表現」を用いています。このやりかたが「最速」です。さて、次はSOART3メトリックスです。いままでは、単純なニューラルネットをつかっていましたが、これから**Vision Transformer**が登場します。”

![imageSMNW3-7-9](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-9.jpg)

QEU:FOUNDER ： “べつに、ViTでなくともCNN（Convolutional Neural Network）を使っても良いです。もちろん、ViTの方が性能が高いと言われています。ただし、両方とも3-Channel(RGB)のインプットがないと、うまく動かないシステムなんです。・・・ですから、我々は、2次元のアウトプットしか出てこないRT法を無理やり3次元に拡張したのです。”

**（変換前）**

![imageSMNW3-7-10](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-10.jpg)

**（変換後）**

![imageSMNW3-7-11](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-11.jpg)

D先生 ： “ここで「合成画像」という新しい概念を導入したことにより、外観検査の異常判定だけではなく、Attention Mapも生成できるようになりました。これは大変な成果です。さて、ここでSOARTとは？”

![imageSMNW3-7-12](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-12.jpg)

QEU:FOUNDER ： “SOARTは、**「State of Art – Recognition Taguchi」**という意味です。「State of the art(SOTA)」ではありません。「THE（唯一の）」という単語が抜けています。つまり、実のところ大したものではないです（笑）。ただし、RT法としては昔よりも圧倒的に良いです。ここで、先ほどと同様にPython表現として、どのように変わっていったのかを見てみましょう。”

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(y,beta*x, 4) # p=4 

    # 絶対値（マンハッタン）距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の変換
    log_beta = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = log_yita - math.log(vDistance+1.0)
    
    return round(log_beta,5), round(log_yita,5), round(log_gamma,5)

```

D先生 ： “ここで、もともとのRTメトリックスと全く変わってきています。2乗距離（ユーグリット距離）が消えています。かわりに、**ユーグリッド距離はマンハッタン（一次）距離とミンコフスキー（自由多次元）距離に分離しました**。”

![imageSMNW3-7-13](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-13.jpg)

QEU:FOUNDER ： “ミンコフスキ距離は、定義が自由な多次元距離です。”

![imageSMNW3-7-14](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-14.jpg)

D先生 ： “FOUNDERは、便宜的に「p=4」あたりにパラメタを設定しているんですね。”

QEU:FOUNDER ： “「高次元に設定したいけど、さすがにチェビシェフはいやだな」というノリです・・・（笑）。重要なのは、第3のメトリックスのgammaではlog値の引き算になっていることです。”

D先生 ： “そもそも、メトリックスは、なぜlog値に変換されているんですか？”

![imageSMNW3-7-15](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-15.jpg)

QEU:FOUNDER ： “タグチメソッドの汎用技術構造（↑）を思い出してください。外側マトリックス(MX)から派生したメトリックス(Y1,Y2…)は一般的には対数で処理されています。これは、**「対数処理した場合、その値は線形的な性質を持ちやすい」**という理由により、故田口博士が採用したものです。”

D先生 ： “つまり、SN比のDB（デシベル）というのは、べつに信号理論から派生したものではない。”

QEU:FOUNDER ： “そういうことです。さて、ここで「我々の便宜」を考えてみます。我々は、β-η-γメトリックス群を生成した後で、その値をNNモデルに入力します。この場合、モデルへ入力する値はどのような変換がなされていても問題がないのです。”

![imageSMNW3-7-16](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-16.jpg)

C部長： “値が一意であり、それがの関係性が無茶苦茶にならない限り、どのような処理でもいいですね。”

QEU:FOUNDER ： “もちろん、メトリックス値の分布が線形化されていると、モデルが単純にできるので便利ですよ。その特性は、簡単なモデルを採用するSiamese Networkでは特に効いてきます。いよいよ、最終形のNSOARTC法に行きますか？実は、今回は深くは説明しないけど・・・（笑）。”

![imageSMNW3-7-17](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-17.jpg)

D先生 ： “SOART3メトリックスは、**Gray Scaleの画像をインプットにする**んですよね。”

![imageSMNW3-7-18](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-18.jpg)

QEU:FOUNDER ： “単色の部品はたくさんあります。この場合には、Grey Scale画像にして判別しても特に問題はないでしょう。ただし、外観部品や組立品の場合には「原画像の色（RGB）」が意味をもっている場合が多いです。そのためにSOART3メトリックスを拡張する必要があります。ここで、次回において本格的に述べるが、ここではNSOARTCの前半処理の構造だけを見てみましょう。”

![imageSMNW3-7-19](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-19.jpg)

D先生 ： “入力画像がRGBになっています。そうなると、当然、SOART3メトリックス（3種）のすべてを使えません。2個を外す必要があります。その結果、**GAMMA（γ）値であるミンコフスキー距離のみを採用した**んですね。”

QEU:FOUNDER ： “厳密にはミンコフスキ―距離とマンハッタン距離の差分値です。この値そのものが意味を持ちます。さきほどの外観検査機の処理フローチャートをもう一度見てみましょう。”

**（処理フロー：再掲）**

![imageSMNW3-7-20](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-20.jpg)

QEU:FOUNDER ： “SOART3メトリックスのうち、βとηの値は低次値なのです。すでに述べたように、βの値はシフトと回転しか対応しないので「0次値」です。マンハッタン距離はその数理上、「1次値」です。つまり、**GAMMA値（=ミンコフスキー距離-マンハッタン距離）は、低次の影響を除いた値となり、「純粋な高次値」になります**。”

D先生 ： “でも、判別に低次値はいらないんですか？”

QEU:FOUNDER ： “「SOART3法は次元別に値を分離すること」であるといっても、現実には、**GAMMA値には画像のシフトと回転の影響も完全に除去されていない**んですよ。ですから、事実上は、全ての要素が機械学習モデルにインプットされているんです。”

D先生 ： “なるほど・・・。”

QEU:FOUNDER ： “残るNSOARTC法の詳細説明は次回にしましょう。そのあとで、**「QEUシステムにおけるSiamese Networkの位置づけ」**についても説明しましょう。今後の拡張の方針についてもね・・・。”


## ～ まとめ ～

QEU:FOUNDER ： “昨日、孔子様が枕元にでてきました。”

### 子曰く：「恒産なくして恒心無し。恒心無くしてワンチャンあり。」

C部長 : “あの孔子様ですか？”

![MOVIE1](http://img.youtube.com/vi/zNYiJZBNwdY/0.jpg)](http://www.youtube.com/watch?v=zNYiJZBNwdY "立花率いるN国党は「反社会的カルト集団」と言われても裁判に勝てない理由")

QEU:FOUNDER ： “小生は、夢の中で孔子様に聞きました。**「ワンチャン」という言葉**は、どこから出て来たのですかって？”

C部長 : “なんと答えてくれたんですか・・・？”

![imageSMNW3-7-21](/2024-12-02-QEUR23_SMNW16/imageSMNW3-7-21.jpg)

QEU:FOUNDER ： “孔子様、この人たち（↑）を見ていて、**「ワンチャン」**だって・・・（笑）。”

C部長 : “それにしても、**「A倍大明神様がおわしましたころ」**と比較して、**ワンチャン層が薄くなってきました**ね。”

QEU:FOUNDER ： “是非、この調子でお願いします。”
