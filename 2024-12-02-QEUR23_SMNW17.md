---
title: QEUR23_SMNW18 – 閑話休題～NSOARTCメトリックスのロジックとSiamese Network
date: 2024-12-02
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW18 – 閑話休題～NSOARTCメトリックスのロジックとSiamese Network

## ～ NSOARTC法はコンピュータによる外観検査の必然です ～

QEU:FOUNDER ： “前回で、NSOARTCメトリックスができるまでの発展史について説明しました。今回は、いよいよ**NSOARTC法について説明します**。”

**(QEU流RT法の発展史)**

- RT法（メトリックス）
- 新RT法
- SOART3法
- NSOARTC法

D先生 ： “その前に、RT法について復習したほうがいいですね。**RT法は、現実的には外観検査でしかまともに使えない**んです。”

QEU:FOUNDER ： “RT法が出力するメトリックスはβ(感度)とη(SN比)です。そのうち、判別に特に影響するのはηのほうです。このηは、前回紹介した実験結果によると、**「図形の変形」、「図形の大きさの変化」、そして「図形の色の変化」によって値が変わります**。”

**(テスト画像群)**

![imageSMNW3-8-1](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-1.jpg)

**(テスト結果の抜粋)**

![imageSMNW3-8-2](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-2.jpg)

QEU:FOUNDER ： “つまり、標準ベクトル（画像）と計測ベクトルが似ていれば似ているほどRT法による判別は有効になります。このような極端なケースは、**計測環境が厳密に管理されている検査作業しかない**のです。”

![imageSMNW3-8-3](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-3.jpg)

D先生 ： “FOUNDER、つづいて機械学習モデルの入力情報の制限事項についても解説をお願いします。”

![imageSMNW3-8-4](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-4.jpg)

QEU:FOUNDER ： “なるほど。これも重要な話です。Vision Transformer(ViT)を例として挙げてみましょう。ViTのモデルは、いろいろなベンダーが出していますが、ここではG社のViTモデル（↓）を見てみましょう。ViTモデルへの入力画像は、たとえユーザーが製品検査として4080x2040の画像を使いたいといっても、**224ｘ224の画像しか入力できない**んです。これって、外観検査のあるべき姿として、ひどくない！？”

![imageSMNW3-8-5](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-5.jpg)

D先生 ： “・・・ということは、**大きな製品の上にある微小な欠陥が見つからない**ということです。もちろん、沢山の「マシン」を配置すればいいのですが、そんなことはしたくないですね。ViTを製品検査に使うためには、製品異常の情報を保持しながらも、画像サイズを最大限に圧縮してくれる技術が必要です。”

![imageSMNW3-8-6](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-6.jpg)

QEU:FOUNDER ： “以上、我々はRT法とViTモデルの特性について説明しました。重要なことは、**RT法とViTは外観検査用に組み合わせて使用すると、「絶妙の組み合わせ」になってしまう**んです。すなわち、双方のもつ弱点を、相手方が補ってくれるんです。それでは、次にNSOARTCメトリックスの構造の説明に移りましょう。このメトリックスは2段階になっています。タグチメソッドの表現でいうと、「多段階マルチ法」ですね。”

**(NSOA(RT)C：第1段階)**

![imageSMNW3-8-7](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-7.jpg)

**(NSOARTC：第2段階)**

![imageSMNW3-8-8](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-8.jpg)

D先生 ： “NSOARTC法が2段階あることはわかりました。しかし、なぜ1段階目の処理の名前が**NSOA(RT)C**なんですか？この「カッコ」の意味は？”

**（畳み込み部品群）**

![imageSMNW3-8-9](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-9.jpg)

**（メトリックス抽出の考え方）**

![imageSMNW3-8-10](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-10.jpg)

QEU:FOUNDER ： “第1段階目は、RT法を使っていないからです。複数の畳み込み部品をユーザーが任意に設定し、標準画像と計測画像の畳み込みの値をプロットして、メトリックス（β、η、γ）を抽出しているわけです。”

D先生 ： “そうすると、これは厳密な意味では「マルチ法」とはいえませんね。”

QEU:FOUNDER ： “歴史的に解説すると、このNSOARTC法の前には、SOARTC法というものを提案していました。このときは、1段目の処理もRT法を使っていたのです。このときは計算時間がすごくかかりました。一方、畳み込み(convolution)法は、画像認識として優秀であるとの評価が高く、なによりもtensorを有効につかうことにより**畳み込み計算は非常に高速になる**のです。そうであるならば、一段目ぐらいはRT法を使うのをやめても良くないですか？そして、この1段目のNSOA（RT）C処理が終わったときに、以下の合成(RGB)画像になるのです。”

![imageSMNW3-8-11](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-11.jpg)

D先生 ： “これは、VLMによる外観検査自動機の開発などで、さんざん使ってきた画像です。”

QEU:FOUNDER ： “一見は白黒画像に見えるかもしれませんが、実際にはRGB画像です。その証拠に青みがかった画像や赤みがかった画像があると思います。それは、それなりの意味があるのです。この画像のRGBデータを入力情報として、第2段目のNSOARTC処理が行われます。”

D先生 ： “そして、この2段階目の処理は、SOART3処理と同じということでいいんですよね？”

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(y,beta*x, 4) # p=4 

    # 絶対値（マンハッタン）距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の変換
    log_beta = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = log_yita - math.log(vDistance+1.0)
    
    return round(log_beta,5), round(log_yita,5), round(log_gamma,5)

```

QEU:FOUNDER ： “はい。これはSOART3処理です。例によって、低次メトリックスであるβとηは必要ありません。**高次メトリックスであるGAMMA（γ）値だけでいいです**。さらに言えば、もうひとつ「Feature Engineering」が必要になるでしょう。”

D先生 ： “先ほどのフロー図の中に、その言葉がありましたね。”

**(再掲：NSOARTC法の処理フロー)**

![imageSMNW3-8-12](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-12.jpg)

QEU:FOUNDER ： “このFeature Engineeringの意味を理解する上において、Siamese Neural Netのインプット情報を見るとよいです。”

![imageSMNW3-8-13](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-13.jpg)

D先生 ： “この図は、NSOARTC法（2段階目）によるデータ処理の前後を示しています。それにしても、この処理によって情報量を大幅に減らしました。さらにいうと、インプットは3-Channelの情報(RGB)だが、それを1-Channelに変換したのですね。これは、どのようにしましたか？”

QEU:FOUNDER ： “**そこらへんのFeature-Engineeringはユーザーが好きなようにすればいいと思います**。ここで大事なのは、RT法の長所は大幅な次元削減が簡単にできることで、ケースバイケースで設計すればよいと思います。以上、定性的にNSOARTC法の物語は、こんな感じになります。C部長、わかりましたか？”

C部長 ： “もう文学的な意味で、とても分かりやすいです。もちろん、現実にプログラムを組むと、それなりに複雑になってしまうのでしょうが・・・。”

QEU:FOUNDER ： “Siamese NNって、次元削減のためにNSOARTC法を2段階分すべて処理する必要があるので、前処理プログラムは当然に複雑になります。まあ、それはしようがないよね。Siamese NNは、簡単なNeural Networkモデルで複雑な検査作業をするので、判別精度を上げるには、前処理をその分だけ工夫するしかないのです。今回は、つづいて「まとめ（番外編）」として、我々が最近イチオシしているSiamese Neural Networkについて、少しだけ追加の議論をしましょう。”


## ～ まとめ ～

QEU:FOUNDER ： “さきほどのつづきとして、Siamese Neural Networkについて説明しましょう。”

![imageSMNW3-8-14](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-14.jpg)

C部長 : “（Siamese NNとは、）アタマが２つある。あの**シンプルな手法**ですね。この手法が20世紀のうち(1993)にできているなんて、ホントに思いもしませんでした。”

![imageSMNW3-8-15](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-15.jpg)

QEU:FOUNDER ： “小生も不覚でした。もうちょっと早くこれに取り組みたかった。さて、いきなりタグチメソッドに話が飛びます。マハラノビス距離について・・・。”

![imageSMNW3-8-16](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-16.jpg)

C部長 : “FOUNDERの従来からの考え方によると、**「MT法というのは存在しない」**、**「単位空間を１つしかとれないのが重大な欠点だ」**でしょ？“

![imageSMNW3-8-17](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-17.jpg)

QEU:FOUNDER ： “まあ、それもあります。それにしても、小生がもっとも、この手法で危険だと思う欠点が、**「外挿法である」**ということです。RT法の場合は、複数の均質空間で比較するので外挿ではないと考えることもできます。マハラノビス（MT）距離は、**異常を示す根拠が外挿になります**。”

C部長 : “ボクも外挿による予測をやって、失敗した経験があります。本当に外挿による予測はやばいです。さらに、**複数の単位空間があるとさらにヤバイ**です。”

QEU:FOUNDER ： “まあ、害の規模が小さい民生品の場合はさておき、航空宇宙や医療の分野でマハラノビスによる異常検出を使うのはやめた方がいいよね。むしろ、非線形モデルによる分類学習を使った方が安心できますよ。さて、小生は、このように「マハラノビス距離を使った異常判定はダメ」と言っている反面、同時に、**「なんとかマハラノビス距離を有効に使いたい」**と思っているんです。Siamese NNのPython-snippetをみてみましょう。ドン！！”

```python
# ---
import keras
from keras import Input
from keras.layers import Dense, Lambda
from keras.ops import norm
from keras.models import Sequential, Model
from keras.saving import register_keras_serializable
import tensorflow as tf
from tensorflow.keras import backend as K

# Register the custom function for serialization
@register_keras_serializable()
def euclidean_distance(twins):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    twin1_output, twin2_output = twins
    return tf.sqrt(tf.reduce_sum(tf.square(twin1_output - twin2_output), axis=1, keepdims=True))

# Define inputs
input1 = Input(shape=(image_size,))
input2 = Input(shape=(image_size,))

# Define the network
network = Sequential(
    [
        Input(shape=(image_size,)),
        Dense(512, activation="relu"),
        Dense(256, activation="relu"),
        Dense(128, activation=None),
    ]
)

# Create twin networks
twin1 = network(input1)
twin2 = network(input2)

# Compute distance using Lambda layer with output_shape specified
distance = Lambda(euclidean_distance, output_shape=(1,))([twin1, twin2])

# Define the model
model = Model(inputs=[input1, input2], outputs=distance)

# Define and register contrastive loss function for serialization
@register_keras_serializable()
def contrastive_loss(y, d):
    margin = 1
    y = tf.cast(y, d.dtype)
    loss = (1 - y) / 2 * K.square(d) + y / 2 * K.square(K.maximum(0.0, margin - d))
    return loss

# Compile the model using contrastive loss
model.compile(loss=contrastive_loss, optimizer="adam", metrics=['binary_accuracy'])

```

C部長 : “ボクは、あんまりプログラムにくわしくないんですが、これがKerasを使ったディープラーニングによる学習コードの一部なんですね。”

![imageSMNW3-8-18](/2024-12-02-QEUR23_SMNW17/imageSMNW3-8-18.jpg)

QEU:FOUNDER ： “これを概念図にすると、こんな感じ（↑）になります。我々がやったプロジェクトの場合は、2つの画像の属性が一致しているか（=1）、または違っているか(=0)でしょ？その**一致性が距離**になっており、ディープラーニング時にはbinary metricになるんです。さて、もしも、これがbinaryでなかったら、どうなるんでしょうか？”

C部長 : “binaryでなかったら？距離が？**マハラノビス距離にする**つもり？ああ・・・、そうか・・・。でも、そんなことをしてメリットはあるんですかね？”

QEU:FOUNDER ： “Siamese NNの距離にマハラノビス外挿距離を使うことは、少なくとも２つのメリットがあります。１つは情報量の差です。一般に、continuous valueの情報量はbinary valueよりも10倍以上多いです。その値を使えば、判別精度があがる可能性があります。あと、S**iamese Neural Networkとマハラノビス距離を併用すれば、単一の単位空間を組み合わせて、複数の単位空間に対応できるようになる**んです。”

C部長 : “なるほど・・・。・・・でも、具体的にはどんな用途で使えるですか？”

QEU:FOUNDER ： “製品の検査でSiamese NNを使いたいのであれば、「1(OK)/0(NG)評価」で十分です。マハラノビス距離によるSiamese NNの応用範囲は、**「プロセスの異常診断」**になるでしょうね。”

C部長 : “おっと！なんと、プロセスの異常診断ですか・・・！？うちの会社にも、そんなシステムが欲しいですね。何しろ、Siamese NNは軽い手法だし・・・。”

QEU:FOUNDER ： “現在、関連する情報を収集中です。他にやっている人がいるかなあ・・・。小生がやれるとしたら、もう少し後になるでしょう。”
