---
title: QEUR23_VIVLM35 – LoRAで端子外観検査用のデータセットを学習する
date: 2024-10-21
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM35 – LoRAで端子外観検査用のデータセットを学習する

## ～ LORAには限界がある ～

QEU:FOUNDER ： “前回のトライアルでFlorence-2モデルのファイン・チューニングのたたき台ができました。次は、いよいよ端子外観検査用のデータセットを学習しましょう。”

![imageVLM1-35-1](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-1.jpg)

QEU:FOUNDER ： “データセットの構造が変わったので、プログラムが少しだけ変わります。もっとも重要なのは、**DataLoaderの部分**かな・・・。”

```python
# ---
# フォーマットを整形する
class ODDataset(Dataset): 

    def __init__(self, data): 
        self.data = data
        
    def __len__(self): 
        return len(self.data)
        
    def __getitem__(self, idx):
        example = self.data[idx]
        question = "<OD>"
        bbox_str = example["bbox_str"]
        answer = bbox_str.replace("-","")
        #image = example['image'].convert("RGB")
        image = example['image']
        return question, answer, image    
    
# ---
# データセットを生成する
def collate_fn(batch):
    questions, answers, images = zip(*batch)
    inputs = processor(text=list(questions), images=list(images), return_tensors="pt", pad-ding=True).to(DEVICE)
    return inputs, answers

# ---
train_dataset = ODDataset(ds_train)
val_dataset = ODDataset(ds_val)

```

D先生 ： “項目名が変わっていますから、関数を作り替えたわけですね。でも、「replace文」をつかって「ハイフン(-)」を消した意味は？”

![imageVLM1-35-2](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-2.jpg)

QEU:FOUNDER ： “キャプションが見やすくなるでしょ？あと、ハイフンはあまり使わない文字なので、これによって学習速度が遅くなるのを恐れたんです。今回は12epochだけ処理してみました。まずは最初に学習損失（履歴）の結果をみてみましょう。”

![imageVLM1-35-3](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-3.jpg)

D先生 ： “順調に学習損失が低減されています。ただし、そろそろ飽和するんじゃないですかね。計算時間は、予定通りの結果でした。T4のGPUは使えましたか？”

QEU:FOUNDER ： “だめだった・・・。やはり**L4のパワーが必要**でしたね。それでは、学習に伴って予測性能がどうなるかを見てみましょう。”

![imageVLM1-35-4](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-4.jpg)

QEU:FOUNDER ： “まずは、学習されていない初期の状態の推論結果をみてみましょう。”

D先生 ： “**さすがにPre-trainモデルの中には「人工物」の情報は入っていませんね**。だから、予測がメタメタになりましたが、それはしようがないです。”

QEU:FOUNDER ： “ここからがモデルの学習準備になります。読み込んだTRVデータセットを加工して、モデルが学習のために消化しやすい状態に加工します。”

**（epoch=1）**

![imageVLM1-35-5](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-5.jpg)

**（epoch=4）**

![imageVLM1-35-6](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-6.jpg)

D先生 ： “結論からいうと、epochが3程度ではダメダメです。・・・でも、面白いですね。NSOART処理をした合成画像の方が、はやく学習されるようです。”

QEU:FOUNDER ： “あとは、最後のepochだけを見てみましょう。結論からいうと、ダメダメです。”

![imageVLM1-35-7](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-7.jpg)

D先生 ： “すでに予測はしていましたが、今回のLoRAでの物体検出は不可能でしたね。どれでも、なぜ**数字の部分を検出しているのか**が不思議です。”

QEU:FOUNDER ： “Pre-trainのモデルでは、すでに数字を学習しているからです。これはLLM（言語モデル）の知識ですが、事前モデルにはない情報をファインチューニングに入れてもダメです。事前にモデルにある情報の出力を微調整するのが、ファインチューニングの機能なんです。それでは、それを裏付ける実験をしてみます。次は推論において、例の「ねこちゃん」を使ってみましょう。”

![imageVLM1-35-8](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-8.jpg)

D先生 ： “当たり前ながら、変わらないですね。”

QEU:FOUNDER ： “**LoRAって、ほんの一部のデータしか書き換えていない**んですよ。LoRAアダプタの中身を見てみましょう。”

![imageVLM1-35-9](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-9.jpg)

D先生 ： “学んだ情報量って、こんなに少ないの！？”

QEU:FOUNDER ： “これがLoRAの現実です。もちろん、LoRAの設定パラメタを変えれば、若干は変えることができます。次のトライアルでは、ここの部分を変えてみなければいけないでしょう。”

![imageVLM1-35-10](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-10.jpg)

QEU:FOUNDER ： “ついでに、**端子検査画像で数字が挿入されていない**場合の推論結果を見てみましょう。”

![imageVLM1-35-11](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-11.jpg)

D先生 ： “数字が抜けちゃうと、画像がPOSTERと認識されるのか・・・。**数字のない検査画像群**も、ある程度学習されていないといけないですね。”

![imageVLM1-35-12](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-12.jpg)

QEU:FOUNDER ： “こんなことを現時点でこう言うのも何だが、最終的にはLoRAの限界を認識する必要もありますね。半分ぐらいのパラメタを書き換えるのであれば、十分に認識はできますよ。”

D先生 ： “その方法論の効果とプログラムは、すでに検討済みなので、これ以上はやらないでおきましょう。次は、もう一度LoRAにこだわりましょう。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “精神医学の知見によると、人々が前向きに生きるために最も障害となる意識は「恥」らしいよ。**J国の管理スタイルは空気を使って意図的にターゲットになる人々を「恥に追い込む」**でしょう？”

![imageVLM1-35-13](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-13.jpg)

C部長 : “このおっさん（↓）はQCサークル大会の訓示として、がんばって成果を出してくれたQCサークルのメンバーたちに向かって、こんなアホなことを言ったんでしょう？ああ・・・。恥ずかしい・・・。こんなに「くだらない管理（ハラスメント）」のために、無駄に金と時間、気力を使わず。もっと前向き、創造的なことをしたいですね。 “

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

QEU:FOUNDER ： “このおっさんの訓示がQC（品質管理）理論的に正しいものであるとするならば、もうQCサークルなんかいらないですよ。もう永遠にね・・・。さて、Cさんは、このニュース（↓）に興奮したでしょ？”

![imageVLM1-35-14](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-14.jpg)

C部長 : “こんなにスゴイことができることに驚きました！！この偉業はオペレータがやったのかな？その人の技能よりも、心臓の強さにおどろくわ・・・。 “

![imageVLM1-35-15](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-15.jpg)

QEU:FOUNDER ： “人間には絶対にやらせないよ。J国じゃあるまいし・・・。人間の操作技能がキーファクターになれば、今回はうまくいっても、次にうまくいく保証はないです。小生は、このニュースを聞いて、むかし、**イーロン・マスクがオーナーだったころのOPENAI-GYM**を思い出しました。あのころの強化学習のテーマ（↑：Lunar Landar）と同じなんだよね。今回の事例は・・・。”

C部長 : “イーロンは、J国のリーダよりも**「長いスパンでものを考えて」**います。 ああ！思い出した！2018年ごろにA国のT社の開発リーダのツイートを見たことがあります。「我々は毎日、会社の中でゲームばかりしている」って・・・。“

![imageVLM1-35-16](/2024-10-21-QEUR23_VIVLM35/imageVLM1-35-16.jpg)

QEU:FOUNDER ： “もはや**「仮想と現実」の垣根がない**んです。ましてや、業界間の少々の技術上の差異なんかは無いようなものです。ディープラーニングのモデルにとっては・・・。それらの情報を**組織間で共有(Shear)することで、改善が速く、レベルが高く**なります。”

C部長 : “QCサークルというのは、その活動が会社内で閉じていることが普通です。FOUNDERの考え方は、QCサークルの有効性を否定していませんか？“

QEU:FOUNDER ： “だから、QCサークルは今後は必要なの？率直に言って、いらないと思っているんです。”


