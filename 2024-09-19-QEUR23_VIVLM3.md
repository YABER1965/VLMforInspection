---
title: 技術振り返り： まとめ ～ SOART3メトリックスとViTを併用した外観検査自動機
date: 2024-09-19
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## 技術振り返り： まとめ ～ SOART3メトリックスとViTを併用した外観検査自動機

### 【発明の名称】 

SOART3メトリックスとViTを併用した外観検査自動機

### 【技術分野】  

【０００１】
本発明はコンピューターによる外観検査自動機に関するものです。

###【背景技術】

【０００２】
画像判別用の機械学習ロジックは、すでに提案されており、多くの成果が挙げられています(図1)。なかでもCNN（Convolutional Neural Network:畳み込みニューラルネットワーク）は、高い判別能力が得られています。

**(図1:画像認識のコンペの歴史)**

![imageVLM1-4-1](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-1.jpg)

【０００3】
ただし、これらの画像判別で成功した技術(図2)を、そのまま外観検査による異常検出に使用した場合には必ずしも良い結果が得られるとは限りません。一方、最近ではVision Transformer（以下ViT）という技術が提案されており、この手法の方がCNNよりも外観検査用に優れている可能性があります。CNNは畳み込みを重ねて情報を集約した特徴ベクトルを作るため、個体判別に優れています(図3)。しかし、CNNは特徴が空間的に分離した場合には判別精度はよくありません(図4)。一方、ViTは自然言語処理から派生した技術であるので、そのような制限はありません。学術成果として論文になっている事例もあります(図5)。

**(図2: 画像認識の例)**

![imageVLM1-4-2](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-2.jpg)

**(図3: 畳み込みニューラルネットワークの構造)**

![imageVLM1-4-3](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-3.jpg)

**(図4:Vision Transformerの構造)**

![imageVLM1-4-4](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-4.jpg)

**（図5:学術成果の例）**

![imageVLM1-4-5](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-5.jpg)

【０００４】
そのほか、既述のCNNやViT以外にも多くの異常検出手法が提案されており、プリント基板の品質管理などの転写性のきわめて高い製品を中心に実用化されています。代表的な手法を挙げると以下の通りです。

- 画像差分法
- 距離を計測する方法
- 教師あり学習（ディープラーニング）
- ※オートエンコーダ―(VAE)はディープラーニングと画像差分法の中間的手法と考えられます


### 【発明の概要】

### 【発明が解決しようとする課題】

【０００５】
CNNまたはViTのみで外観検査をすることは、ある程度は可能です。例えば、以下の農業の課題(図6)では、一部の画像の葉の枯れ具合が異常であると考えられます (図7)。

**（図6:異常検出の非常に原始的な事例）**

![imageVLM1-4-6](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-6.jpg)

**（図7: 葉の学習画像）**

![imageVLM1-4-7](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-7.jpg)

【０００６】
上記の豆の葉の病気判別の事例では、ViTモデルを使って異常（病気）を検出しています。さらに、ViTの場合には学習したモデルの情報からアテンション・マップを生成することができ、異常の位置を発見することができます (図8)。

**（図8: 葉の異常検出、アテンション・マップ）**

![imageVLM1-4-8](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-8.jpg)

【０００７】
ただし、現実の製造現場に適用するにはCNNやViTの個体判別の技術をそのまま適用して異常判別することは難しくなります。現実の製造プロセスでは、前述の葉の検査の事例のように画像に多様性はなく、製品の形状が欠陥部分を除きほとんど同じです。さらに、部品単位の検査の場合、製品の色は全く同じです(図9)。“

**（図9:製造現場の事例：プラスチック射出成型品）**

![imageVLM1-4-9](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-9.jpg)

【０００８】
また、製品欠陥は微小でも製品が不良になる場合が多く、高解像度(ex 1200x1200)の画像を使用して初めて検出できるものが多いです。しかし、CNNやViTの場合のように学習モデルを形成して予測する手法の場合には、モデルを成熟させるための学習データの準備コストと計算コストがより大規模になり、そのままでは品質管理への実用は難しい。その理由の一例を挙げると、ViTのモデルの事例では、224x224などの小さな画像を使うことが多いです。この程度の大きさの画像では外観検査には向きません。逆に言えば、この入力画像の大きさの要求が、画像差分(VAE)などの画像をそのまま使う技術が、外観検査でいまだに使用される理由でもあります。

### 【課題を解決するための手段】

【０００９】
本発明では、上記の課題を解決するためにViTとSOART3合成画像処理を併用します。SOART3は、RT(Recognition Taguchi)法というタグチメソッドの技術の拡張です。RT法とは、標準ベクトルと計測ベクトルを比較し、Ｙ１（感度：β）とＹ２（ＳＮ比：η）の2つのメトリックスを生成します(図10)。

**（図10:RT法の原理）**

![imageVLM1-4-10](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-10.jpg)

【００１０】
SOART3法は、RT法を3次元メトリックス出力へ拡張させ、RGB画像を出力する手法です。RT法では、SN比として標準ベクトルと感度による補正後の計測ベクトルを比較したユーグリッド距離を使用しています。ここで、２つのベクトルの距離を普遍化して、ミンコフスキー距離を考えました(図11)。この距離はパラメタのｐ値を変化させることで、マンハッタン距離(p=0)～チェビシェフ距離(p=∞)まで変化することができます。つまり、SOART3法では、ユーグリット距離のかわりに2つの独立したメトリックスに分離させて3次元化したいので、マンハッタン距離とチェビシェフ距離を使っているのです(図12)。

**（図11:ミンコフスキー距離の定義）**

![imageVLM1-4-11](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-11.jpg)

**（図12:SOART法の考え方）**

![imageVLM1-4-12](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-12.jpg)

【００１１】
SOART3法の処理プロセスをPythonプログラムで記述した事例を示します。まずは、標準ベクトル(x)と計測ベクトル(y)のデータから感度（β）を計算します。その後、xと感度で補正した計測ベクトルであるβyの間のチェビシェフ距離とマンハッタン距離をそれぞれ計算します。チェビシェフ距離とマンハッタン距離は同じベクトル(x, βy)から生成しており、このままでは2つの距離には若干の相関があると思われるので、チェビシェフ距離は対数変換したあとでマンハッタン距離との差を取っています。対数変換は、値の挙動を線形化し、学習モデルを小さくするために適用しています。

```python

# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # 感度(β)を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # マンハッタン距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma

```

【００１２】
さらに、SOART3法は、シングル・モード（カメラ1台）でも、ダブル・モード（カメラ3台）でも使用できます(図13)。プリント基板や多色の印刷物の外観検査ではシングル・モードが有効であり、立体製品の検査ではダブル・モードが有効です。本発明では、ダブル・モードのみについて説明します。

**（図13:ダブル・モードの考え方）**

![imageVLM1-4-13](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-13.jpg)

【００１3】
ダブル・モードで立体感を計測できるのは、人類（動物）が複数の画像から距離感を測定するのと同じ原理です(図14)。

**(図14:ダブル・モードで立体感を得る原理)**

![imageVLM1-4-14](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-14.jpg)

【００１４】
ここでは、簡単にSOART3（ダブル・モード）の計算手法を使って合成画像を作成してみます。まずは、中央カメラで複数の製品画像を撮り、元のRGB値をグレースケール化して、それらの平均画像を生成します(図15)。

**(図15: 丸端子の標準データ、平均画像)**

![imageVLM1-4-15](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-15.jpg)

【００１５】
その後で、被検査品の左画像と右画像を同時に撮影し、それらを標準画像と同様にグレースケールに変換します(図16,17)。

**（図16:左カメラの画像）**

![imageVLM1-4-16](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-16.jpg)

**（図17:右カメラの画像）**

![imageVLM1-4-17](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-17.jpg)

【００１６】
これらの3枚の画像情報（ベクトル）を処理すると、SOART3メトリックスが得られます。ダブル・モードでは、右カメラと左カメラのSOART3メトリックスの差を取ります。その結果、以下のようなSOART3合成画像を生成できます（図18）。

**（図18: SOART3合成画像）**

![imageVLM1-4-18](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-18.jpg)

### 【実施例】

【００１７】
この実施例では、ワイヤーハーネスのコネクタ端子の外観検査への適用事例を紹介します。ワイヤーハーネスは電気製品内の多数の部品間を接続する電線群をまとめる部品（図19）であり、そのコネクタのピンの状態を外観検査する装置を開発します（図20）。

**(図19：ワイヤーハーネスとは)**

![imageVLM1-4-19](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-19.jpg)

**(図20: コネクタの端子検査)**

![imageVLM1-4-20](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-20.jpg)

【００１８】
本発明では、コネクタ内のピン異常判定のためにViTを使います。ここで今回の事例では、小規模なモデルを生成しました(図21)。

**(図21: 今回の実験で使用したViTモデル)**

![imageVLM1-4-21](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-21.jpg)

【００１８】
SOART3合成画像をつくるために、3CGソフト（Blender）の仮想空間上にコネクタを生成し、右カメラ-中央カメラ-左カメラを設置しました(図22)。そして、検出する不良モードは丸端子ピン（円柱）の垂直抜けとピンの傾きとしました(図23)。もちろん、ピンの不良はコネクタ内の各ピン位置で発生するものとします。このViTモデルを学習する段階では、その不良位置は1か所だけとします。

**(図22: 左-中央-右カメラの画像)**

![imageVLM1-4-22](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-22.jpg)

**(図23: 不良モードの定義)**

![imageVLM1-4-23](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-23.jpg)

【００１９】
まず、最初に丸端子をもつコネクタのみのデータを学習します。正常コネクタと不良コネクタを回転、シフト、光源エネルギーをばらつかせて撮影をしました(図24)。また、学習データにはSOART3合成画像だけでなく、撮影画像も使用しました。こうすることで、学習データ数がより多くなります。この単種端子のデータを学習したところ、その学習の過程でACCURACY（判別精度）が変化する進捗が遅いという現象が見られました(図25)。

**（図24:学習データ：左右生画像と合成画像を含む）**

![imageVLM1-4-24](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-24.jpg)

**（図25:ViT学習の進捗）**

![imageVLM1-4-25](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-25.jpg)

【００２０】
ここで、学習を加速させる対策として別の端子種として角柱のCGモデルのデータを加えて学習します（図26）。この場合も、前述の円柱端子の場合と同様に、平均画像を作成し、SOART3処理を行います（図27）。

**（図26：角柱CGモデル）**

![imageVLM1-4-26](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-26.jpg)

**（図27：角柱端子のSOART3合成画像）**

![imageVLM1-4-27](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-27.jpg)

【００２１】
円柱端子と角柱画像を組み合わせて学習させたところ、Accuracyが変動を開始するEPOCHが早期になり、学習速度が単種よりもはやくなりました（図28）。つまり、端子種を増やしたことで、端子抜けは端子の形状に問わず、図形の移動と回転であることを、ViTモデルが理解したことが理由だと思われます。。

**（図28：丸端子と角端子を組み合わせた学習進捗）**

![imageVLM1-4-28](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-28.jpg)

【００２２】
さて、ViTモデルの学習の進捗に伴う、アテンションマップの変化について比較します（図29,30）。学習の初期は、アテンションが高い位置が欠陥の位置以外にも分布していました。それが学習の進展とともに、不良画像のときには欠陥位置にアテンションが集中します。一方、欠陥がないコネクタ画像の場合には、アテンションの分布が大きくばらつきます。

**（図29： 学習の初期段階～EPOCH:200）**

![imageVLM1-4-29](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-29.jpg)

**（図30： 学習の完了段階～EPOCH:600）**

![imageVLM1-4-30](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-30.jpg)

【００２3】
上記の学習が完了したモデルを使って、検査画像の中に2か所に欠陥がある場合のアテンションマップを生成した結果を紹介します。この場合でも、欠陥の2か所でのアテンションが高くなっています (図31、32)。

**(図31:  2か所に欠陥がある場合の画像)**

![imageVLM1-4-31](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-31.jpg)

**(図32:  2か所に欠陥がある場合のアテンション・マップ)**

![imageVLM1-4-32](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-32.jpg)

【００２４】
このように、SOART3+ViTによる外観検査は、外観検査の用途に対して非常に高いポテンシャルを有していると思います。その他、本発明では従来の判別モデルでは検出できないタイプの不良を発見ができます。端子の異品（例：本来は円形端子を使うはずだが、実際には角形をつかった）の場合には、通常の判別モデルでは良品としか判断しません。しかし、SOART3で標準画像と検査画像を比較して処理をしているので、その端子には異品欠陥があることがわかります(図33,34)。例えば、下記の欠陥画像の場合、角端子の中に丸画像の影が含まれており、異品不良があることがわかります。

**(図33:  製品実現プロセス)**

![imageVLM1-4-33](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-33.jpg)

**(図34:  製品実現プロセス)**

![imageVLM1-4-34](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-34.jpg)

【００２５】
ただし、ViTモデルを使用しているので、CNNモデルよりも大きな学習のためのデータ量が必要です。そのため、一つのコネクタの外観検査のために、これほど大きなデータ量を準備するのはコスト的に不適切です。そのため、ディープラーニングの転移学習を応用したファイン・チューニングのためのシステム構築が不可欠と思われます(図35)。さらに、プレ・トレーニングでCG画像を中心とした学習を行い、ファインチューニングで現場画像の学習をするとコストを抑制できます。

**(図35: ファイン・チューニングの適用)**

![imageVLM1-4-35](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-35.jpg)


## ～ まとめ ～

C部長: “この件（↓）、心底から恐ろしくありません？”

![imageVLM1-4-36](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-36.jpg)

QEU:FOUNDER: “**「うっそだろう？コレ・・・。」**って思いました。あの第一報から、かなり情報が出てきましたよね。他の場所でつくったこととか・・・。初めは、「横流れ品」を誰かが改造して、それが市場に流れたものだと思いました。なんと！**正規品！！**”

![imageVLM1-4-37](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-37.jpg)

C部長: “このシロモノは、そこ（本当の製造地）の**「made in」**だったんでしょうね？製造場所の表示には、それなりの「法律的なしばり」はあるでしょうに・・・。それにしても、これからmade in T〇って欲しい？”

QEU:FOUNDER: “もともとは、TWがかなり好きだったが、今回で大いに萎えたなあ・・・。それにしても、Iのつくテロ国家（↓）にはドン引きするわ・・・。”

![imageVLM1-4-38](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-38.jpg)

D先生: “**「meet amazing」**ねえ・・・。今回の件は、**かなり大きなものをぶち壊しにした**なあと思うなあ・・・。やれやれ・・・。一番怖いのは、**自動運転+EV**です。あれは、一歩間違えば兵器になりますからね。”

![imageVLM1-4-39](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-39.jpg)

QEU:FOUNDER: “自動運転技術は特にね・・・。もう、**システムをハッキングした国に核爆弾を落とすくらいの根性がないと、自動運転技術はモノにならない**ことが明らかになりました。その点で、H社って見切りが速くて優秀ですよね。2030年のあたりには、あそこは小さな**芝刈り機メーカ**になっていると思うが、それなりに頑張ってほしいです。”

[![MOVIE1](http://img.youtube.com/vi/jgZ8woRyBig/0.jpg)](http://www.youtube.com/watch?v=jgZ8woRyBig "African gospel music- Dangkat Geoffrey C. -Zan Yabe Ka (I Will Praise You Lord)")

QEU:FOUNDER: “ああっ！！もう、Iのつくテロ国家には全く同情がわかん。早く滅べ！これからは、**Iという国がなくなることによって中東が平和になり、アフリカが飛翔するんです。神に栄光あれ！**”
