---
title: QEUR23_VIVLM5 – VLMを用いて、画像を最も簡単に比較してみる
date: 2024-09-20
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM5 – VLMを用いて、画像を最も簡単に比較してみる

## ～ 最も簡単な外観検査のトライアルをやってみました ～

QEU:FOUNDER ： “さて、**VLM(Vision Language Model)**を使って、もっとも簡単な外観検査をやってみます。当たり前のことだが、まともに使える検査装置をつくるには最低でもファインチューニングをつかいます。さて、今回使うVLMモデルだが・・・。”

![imageVLM1-5-1](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-1.jpg)

D先生 ： “LLAVAじゃないんですか？”

QEU:FOUNDER ： “このモデルの方が、サイズが小さくて、しかも新しいです。このモデルでダメならば、LLAVAでもダメでしょう。”

C部長 ： “まずは、何の画像を評価しますか？”

![imageVLM1-5-2](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-2.jpg)

D先生 ： “かわいい・・・。”

QEU:FOUNDER ： “この手の認識はできるに決まっています。でも、最初なので確認のために推論の出来栄えをみてみましょう。プログラムをドン！”

```python
# -----
from PIL import Image 
from transformers import AutoModelForCausalLM 
from transformers import AutoProcessor 

model_id = "microsoft/Phi-3.5-vision-instruct" 

# Note: set _attn_implementation='eager' if you don't have flash_attn installed
model = AutoModelForCausalLM.from_pretrained(
  model_id, 
  device_map="cuda", 
  trust_remote_code=True, 
  torch_dtype="auto", 
  _attn_implementation='flash_attention_2'    
)

# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.
processor = AutoProcessor.from_pretrained(model_id, 
  trust_remote_code=True, 
  num_crops=16  # Changed to 16 for single-frame
) 

images = []
placeholder = ""

# Load local image
local_image_path = "IMG_5XX8.JPG"  # Replace with your actual image path
images.append(Image.open(local_image_path))
placeholder += "<|image_1|>\n"

messages = [
    {"role": "user", "content": placeholder+"Describe this image in detail, including the main subject, actions, and setting."},
]

prompt = processor.tokenizer.apply_chat_template(
  messages, 
  tokenize=False, 
  add_generation_prompt=True
)

inputs = processor(prompt, images, return_tensors="pt").to("cuda:0") 

generation_args = { 
    "max_new_tokens": 1000,
    "temperature": 0.7,  # Added some randomness
    "do_sample": True,  # Enable sampling
    "top_k": 50,  # Added top-k sampling
    "use_cache": True,  # Added this line
} 

generate_ids = model.generate(**inputs, 
  eos_token_id=processor.tokenizer.eos_token_id, 
  **generation_args
)

# remove input tokens 
generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]
response = processor.batch_decode(generate_ids, 
  skip_special_tokens=True, 
  clean_up_tokenization_spaces=False)[0] 

print("\nDesribing the image:")
print(response)

```

C部長： “普通の推論は本当に得意ですね。”

![imageVLM1-5-3](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-3.jpg)

QEU:FOUNDER ： “この「優秀なモデル」を使って、2つの画像の比較をします。対象の画像はコレ(↓)です。”

![imageVLM1-5-4](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-4.jpg)

D先生 ： “同一物体だが、少しだけ状態が違った画像を並べたんですね。”

### Compare the two images (separated by black horizontal bar). Describe two major differences be-tween upper and lower image. You should list difference only.

QEU:FOUNDER ： “このようにプロンプトを設定すれば、2つの画像の差を評価することができます。推論の結果をみてみましょう。”

![imageVLM1-5-5](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-5.jpg)

QEU:FOUNDER ： “若干はニュアンスが不正確ですが、それなりに差分の評価をしているようです。じゃあ、次は工業品でも同じようにやってみましょう。例によって、コネクタの端子検査をやってみました。”

![imageVLM1-5-6](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-6.jpg)

D先生 ： “比較はうまく行きましたか？プロンプトは？”

![imageVLM1-5-7](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-7.jpg)

QEU:FOUNDER ： “プロンプトは、あえてオープンにしません。ただし、どうやってもダメだと思います。なぜなら、LLMは明確に2つのイメージには差異がないとかんがえているからです。”

D先生 ： “う～む・・・。工業品の外観の良否評価方法なんかは、Pre-train段階では教えられていないですからね。”

![imageVLM1-5-8](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-8.jpg)

QEU:FOUNDER ： “何度も言いますが、外観検査のタスクって、この手のLVMモデルではあまり得意ではないかもしれません。今回のシリーズでは、この問題がFine-tuningを使って、どこまで克服できるかを試しているんです。”

C部長： “あと、SOART3メトリックスで合成した画像で、どこまで改善できるかですね。”

QEU:FOUNDER ： “シーッ！！その話は、いまは言わないの！！”

## ～ まとめ ～

C部長 : “例によって、この番組が何か（↓）言ってます。このチャンネルは**「スポンサード」が多い**んですよね。結局、これは何を言いたいのかな？”

[![MOVIE1](http://img.youtube.com/vi/NEWi_7nWPFU/0.jpg)](http://www.youtube.com/watch?v=NEWi_7nWPFU "【AIで変わるビジネスの世界】アナログかデジタルかの二項対立ではない／精度の高いデータを企業が持ち続けることが追い風になる／経営者が自らデジタルと対峙／知識習得が一気に変わるフェーズ")

QEU:FOUNDER ： “さあね・・・。そもそも小生は、もともとのもともととして、**「いわゆるAI」に対して期待をしたことがない**からね。あんなもの、学習した情報を極度に圧縮し、その膨大な情報の海から、プロンプトで必要と思われる情報を引っ張り出しているだけでしょ？”

C部長 : “AIをビジネスで使うって・・・。”

QEU:FOUNDER ： “Pre-trainの状態では、一般論の情報しか出てこないわけでしょ？AIにはビジネスで差別化になるような「とがった知識」はAIのチカラの範囲にはないです。ただし、粗雑品の大量生産が目的なら別ですが・・・。”

C部長 : “人間が（一般論を）簡単に学ぶには、AIは良い手段ですね。”

QEU:FOUNDER ： “そのためのBONSAIシステムです。そういう意味では、AIを使えばビジネスの生産性がすごく上がりますよ。だから、少なくとも小生にはAIに対する幻滅なんぞはハナから存在しないわけです。ただし、例のStable Diffusionは違いますよ。あれは、そのシステムだけで、すなおに「競争力」になります。だからこそ、**世の中では要注意技術であるとして規制されている**わけで・・・。あとは、新しい高分子化学物質の発明は、言語生成AIの例外的に革新的な応用技術かな・・・。”

C部長 : “何で、高分子化学物質だけが革新的な応用になるんでしようかねえ・・・。”

![imageVLM1-5-9](/2024-09-20-QEUR23_VIVLM5/imageVLM1-5-9.jpg)

QEU:FOUNDER ： “プロンプトで情報を生成するのは、その原理が「補間(interpolation)」にすぎません。ただし、その補間のしくみ自体があまりに複雑すぎて、**「補間だけでも発明になっちゃう」**ことがあるわけです。その重要な一例が高分子化学物質の設計なわけです。同様にフロンティアな応用分野があると、大儲けできますよ。そう考えても、AIに対して幻滅するのは、自分に創造性がないことを表明するだけです。それがいやなら、複雑系が解けるメソッドがあるらしいからやってみれば？”

C部長 : “複雑系が解けるんですか？”

QEU:FOUNDER ： “わざわざ本になっているから、そうなんじゃない？しらんけど・・・。”
