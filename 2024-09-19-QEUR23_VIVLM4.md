---
title: Technology Review: Summary - Automated Visual Inspection Machine Using SOART3 Metrics and ViT
date: 2024-09-19
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## Technology Review: Summary - Automated Visual Inspection Machine Using SOART3 Metrics and ViT

### Name of invention 

Automatic visual inspection machine using SOART3 metrics and ViT

### Technology field

The present invention relates to an automatic computer-based visual inspection machine.

### Technology background

Many machine learning logics for image classification have already been proposed, and have achieved great results(Fig. 1). Among these, CNN(Convolutional Neural Network) has achieved high discrimination ability.

**(Fig. 1: History of image recognition competitions)**

![imageVLM1-4-1](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-1.jpg)

However, if these techniques that have been successful in image discrimination(Fig. 2) are used directly to detect abnormalities through visual inspection, good results may not necessarily be obtained. On the other hand, a technology called Vision Transformer(ViT) has recently been proposed, and this method may be better than CNN for visual inspection. CNN is excellent at identifying individuals because it creates a feature vector that aggregates information through repeated convolutions(Fig. 3). However, CNN does not have good discrimination accuracy when features are spatially separated(Fig. 4). On the other hand, since ViT is a technology derived from natural language processing, there are no such limitations. In some cases, these results have been published as academic papers(Fig. 5)..

**(Fig. 2: Image recognition example)**

![imageVLM1-4-2](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-2.jpg)

**(Fig. 3: Structure of convolutional neural network)**

![imageVLM1-4-3](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-3.jpg)

**(Fig. 4: Vision Transformer detection capability)**

![imageVLM1-4-4](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-4.jpg)

**(Fig. 5: Examples of academic results)**

![imageVLM1-4-5](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-5.jpg)

In addition to the above-mentioned CNN and ViT, many computer-based anomaly detection methods have been proposed, and are being put into practical use mainly for products with extremely high transferability, such as for quality control of printed circuit boards. Typical methods are listed below.

- Image subtraction method
- How to measure distance
- Supervised learning(deep learning)
- *Autoencoder(VAE) is considered an intermediate method between deep learning and image difference method.


### Problems to be solved by this invention.

It is possible to some extent to perform visual inspections using only CNN or ViT. For example, in the agricultural problem below(Fig. 6), the withering of leaves in some images is considered abnormal(Fig. 7).

**(Fig. 6: Agriculture example of anomaly detection)**

![imageVLM1-4-6](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-6.jpg)

**(Fig. 7: Learning image of bean leaf)**

![imageVLM1-4-7](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-7.jpg)

In the above example of disease identification on bean leaves, the ViT model is used to detect abnormalities(diseases). Furthermore, in the case of ViT, an attention map can be generated from the information of the learned model, and the location of anomalies can be discovered(Fig. 8).

**(Fig. 8: Leaf anomaly detection, attention map)**

![imageVLM1-4-8](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-8.jpg)

However, when applied to actual manufacturing sites, it is difficult to directly apply CNN and ViT individual discrimination technology to abnormality detection. Images obtained during visual inspection of actual manufacturing processes do not have the same diversity as in the leaf inspection example described above, and the shapes of the products are almost the same except for defective parts. Furthermore, when inspecting individual parts, the entire product has the same color(Fig. 9).

**(Fig. 9: Manufacturing site example, plastic injection molded product)**

![imageVLM1-4-9](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-9.jpg)

In addition, product defects, even minute ones, often result in a defective product, and many of them can only be detected using high-resolution(ex 1200x1200) images. However, in the case of methods that form learning models and make predictions, such as CNN and ViT, large images require greater training data preparation and computational costs to mature the model. For example, ViT models often use small images such as 224x224, but images of this size are not suitable for visual inspection. Conversely, this requirement for input image size is also the reason why techniques that use images as they are, such as image subtraction(VAE), are still used in visual inspection.

### Means to solve problems.

In this invention, we use ViT and SOART3 synthetic image processing together to solve the above problems. SOART3 is an extension of the Taguchi method technology called RT(Recognition Taguchi) method. The RT method compares a standard vector and a measured vector and generates two metrics: Y1(sensitivity: β) and Y2(SN ratio: η)(Fig. 10).

**(Fig. 10: Principle of RT method)**

![imageVLM1-4-10](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-10.jpg)

The SOART3 method is a method that extends the RT method that outputs 2D metrics to 3D metrics output and outputs an RGB image. The RT method uses the Eugridian distance, which is a comparison of the standard vector and the measured vector after sensitivity correction, as the signal-to-noise ratio. Here, we generalized the distance between two vectors and considered the Minkowski distance(Fig. 11). This distance can be changed from Manhattan distance(p=0) to Chebyshev distance(p=∞) by changing the p value of the parameter. In other words, the SOART3 method uses Manhattan distance and Chebyshev distance instead of Eugrit distance because we want to separate them into two independent metrics and make them three-dimensional(Fig. 12).

**(Fig. 11: Definition of Minkowski distance)**

![imageVLM1-4-11](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-11.jpg)

**(Fig. 12: Concept of SOART3 method)**

![imageVLM1-4-12](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-12.jpg)

Here is an example of the SOART3 method described in a Python program. First, calculate the sensitivity(β) from the standard vector(x) and measurement vector(y) data. We then calculate the Chebyshev distance and Manhattan distance between x and the sensitivity-corrected measurement vector βy, respectively. The Chebyshev distance and the Manhattan distance are generated from the same vector(x, βy), and there seems to be a slight correlation between the two distances, so the Chebyshev distance is logarithmically transformed and then the difference from the Manhattan distance is calculated. I'm taking it. Logarithmic transformation is applied to linearize the value behavior and reduce the size of the learning model.

```python

# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # 感度(β)を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # マンハッタン距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma


```

Additionally, the SOART3 method can be used in single mode(one camera) or double mode(three cameras)(Fig. 13). Single mode is effective for visual inspection of printed circuit boards and multicolored printed matter, and double mode is effective for inspection of three-dimensional products. In this invention, only double mode will be discussed.

**(Fig. 13: Double mode concept)**

![imageVLM1-4-13](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-13.jpg)

The ability to measure three-dimensionality in double mode is based on the same principle that humans(animals) use to measure distance from multiple images(Fig. 14).

**(Fig. 14: Principle of obtaining three-dimensional effect in double mode)**

![imageVLM1-4-14](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-14.jpg)

Here, we will create a composite image using the SOART3(double mode) calculation method. First, a central camera takes multiple product images, converts the original RGB values to grayscale, and generates an average image of them(Fig. 15).

**(Fig. 15: Standard data for round terminals, average image)**

![imageVLM1-4-15](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-15.jpg)

After that, the left and right images of the inspected item are simultaneously captured and converted to grayscale in the same way as standard images(Fig. 16 and 17).

**(Fig. 16: Left camera image)**

![imageVLM1-4-16](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-16.jpg)

**(Fig. 17: Right camera image)**

![imageVLM1-4-17](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-17.jpg)

Processing these three image information(vectors) will give you SOART3 metrics. Double mode takes the difference between the SOART3 metrics of the right and left cameras. As a result, a SOART3 composite image like the one below can be generated(Fig. 18).

**(Fig. 18: SOART3 composite image)**

![imageVLM1-4-18](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-18.jpg)


### Example

In this example, we will introduce an application example for visual inspection of connector terminals of wire harnesses. A wire harness is a component that brings together a group of wires that connect multiple parts in an electrical product(Fig. 19), and we will develop a device to visually inspect the condition of the terminals(pins) of its male connector(Fig. 20).

**(Fig. 19: What is a wire harness?)**

![imageVLM1-4-19](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-19.jpg)

**(Fig. 20: Connector terminal inspection)**

![imageVLM1-4-20](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-20.jpg)

In the present invention, ViT is used to determine pin abnormalities within the connector. In this case, a relatively small model was generated(Fig. 21).

**(Fig. 21: ViT model used in this experiment)**

![imageVLM1-4-21](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-21.jpg)

To create the SOART3 composite image, we created a connector in the virtual space of 3CG software(Blender) and installed the right camera, center camera, and left camera(Fig. 22). The failure modes to be detected are vertical dropout of the round terminal pin(cylindrical) and pin inclination(Fig. 23). Of course, we assume that pin failures occur at each pin location within the connector. At the stage of learning this ViT model, there is only one defective location.

**(Fig. 22: Left-center-right camera images)**

![imageVLM1-4-22](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-22.jpg)

**(Fig. 23: Definition of failure mode)**

![imageVLM1-4-23](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-23.jpg)

First, we first learn data only for connectors with round terminals. The normal and defective connectors were rotated, shifted, and the light source energy fluctuated to take pictures(Fig. 24). In addition, we used not only SOART3 composite images but also captured images as training data. This will increase the amount of training data. When learning data from this single type of terminal, we observed a phenomenon in which ACCURACY(discrimination accuracy) changed slowly during the learning process(Fig. 25).

**(Fig. 24: Training data: including left and right raw images and composite images)**

![imageVLM1-4-24](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-24.jpg)

**(Fig. 25: ViT learning progress)**

![imageVLM1-4-25](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-25.jpg)

Here, as a measure to further accelerate learning, data from a rectangular CG model is added as another terminal type(Fig. 26). In this case, as in the case of the cylindrical terminal described above, an average image of the prism is created and SOART3 processing is performed(Fig. 27).

**(Fig. 26: Prismatic CG model)**

![imageVLM1-4-26](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-26.jpg)

**(Fig. 27: SOART3 composite image of square terminal)**

![imageVLM1-4-2](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-27.jpg)

When training was performed using a combination of round terminal and square images, the EPOCH at which Accuracy began to fluctuate became earlier, and the learning speed was faster than with a single type(Fig. 28). In other words, by increasing the number of terminal types that ViT learns, it seems that the ViT model understands that terminal disconnection is the movement and rotation of shapes(cylinders and prisms), regardless of the shape of the terminal.

**(Fig. 28: Learning progress using a combination of round and square terminals)**

![imageVLM1-4-28](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-28.jpg)

Now, let's compare the changes in the attention map as the learning of the ViT model progresses(Fig. 29 and 30). At the beginning of learning, the locations with high attention were distributed in addition to the defect location. As learning progresses, when the image is defective, attention will be focused on the location where the defect exists. On the other hand, for connector images with no defects, the attention distribution varies widely.

**(Fig. 29: Early stage of learning ~ EPOCH:200)**

![imageVLM1-4-29](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-29.jpg)

**(Fig. 30: Learning completion stage ~ EPOCH:600)**

![imageVLM1-4-30](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-30.jpg)

Using the trained model described above, we will introduce the results of generating an attention map when there are defects in two locations in an inspection image. Even in this case, attention is high at the two locations where the defect is present(Fig. 31 and 32).

**(Fig. 31: Inspection image with defects in two locations)**

![imageVLM1-4-31](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-31.jpg)

**(Fig. 32: Attention map with defects in two locations)**

![imageVLM1-4-32](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-32.jpg)

In this way, visual inspection using SOART3+ViT is considered to have extremely high potential for visual inspection applications. In addition, the present invention can discover types of defects that cannot be detected using conventional discrimination models. If the terminal is incorrect(for example, a round terminal was supposed to be used, but a square terminal was actually used), the normal discrimination model will only judge it as a good product. However, since SOART3 processes the standard image by comparing it with the inspection image, it becomes clear that the terminal has a foreign defect(Fig. 33 and 34). For example, in the defect image below, there is a shadow of a round image inside the square terminal, indicating that there is a defective product.

**(Fig. 33: Image of foreign terminal, part 1)**

![imageVLM1-4-33](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-33.jpg)

**(Fig. 34: Image of foreign terminal, part 2)**

![imageVLM1-4-34](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-34.jpg)

However, since it uses the ViT model, it requires a larger amount of data for training than the CNN model. Therefore, it is not cost-effective to prepare such a large amount of data for the visual inspection of just one connector. Therefore, it seems essential to build a system for fine tuning that applies deep learning transfer learning(Fig. 35). Furthermore, by performing learning mainly on CG images during pre-training and learning on-site images during fine-tuning, the cost of preparing training data can be reduced.

**(Fig. 35: Applying fine tuning)**

![imageVLM1-4-35](/2024-09-19-QEUR23_VIVLM3/imageVLM1-4-35.jpg)


