---
title: QEUR23_VIVLM23 – メトリックス合成画像を使ってファインチューニングする
date: 2024-10-03
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM23 – メトリックス合成画像を使ってファインチューニングする

## ～ 実は、「やりたいこと」は別にある・・・ ～

D先生 ： “前回で、**新メトリックス(N-SORTC)を使った合成画像**が準備できました。今回は、これらの画像を使ってVLMモデルをファインチューニングしましょう。”

![imageVLM1-23-1](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-1.jpg)

QEU:FOUNDER ： “今回も、HuggingFace(HF)のシステムにアップしております。一旦、学習データをアップすると、あとの処理が楽なんだよねえ・・・。本当に、HFには感謝しかないわ・・・。”

![imageVLM1-23-2](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-2.jpg)

D先生 ： “さて、trainデータでレコード数が610になっています。前回(510)のデータよりも、少しだけふやしていますね。”

QEU:FOUNDER ： “まあ、新メトリックスによる合成画像を追加しているからね。ただ、画像タイプの種類を増やした分だけ単一タイプで見ると学習画像あたりの数量が小さくなり、逆にVLMとしては学習しにくくなっている可能性がありますよ。じゃあ、今回は学習した結果のみ行くよ！最初は、学習なし(pre-train)のVLMでの推論です。”

![imageVLM1-23-3](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-3.jpg)

D先生 ： “**Pre-trainでの想定外の質問だった**ことがよくわかります（笑）。”

QEU:FOUNDER ： “その（LLMにとって）想定外の質問を想定内にするのがファインチューニングの目的です。では、学習曲線の結果をドン！！”

![imageVLM1-23-4](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-4.jpg)

D先生 ： “例によって、特別にオーバーフィッティングになっていないです。つまり、学習している内容には矛盾がないようですね。まずは、1つだけの結果をじっくりと見てみたいです。。”

![imageVLM1-23-5](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-5.jpg)

QEU:FOUNDER ： “この画像（↑）では、ロケーションが3Uだそうです。当然に間違いですね。”

D先生 ： “画像を見ると、カメラが傾いているので、左側のピンが全体的にX方向に傾いています。VLMは、ここら辺を**「有意な違い」**として認識したんでしょうね。次は、回答をまとめてみてみましょう。”

![imageVLM1-23-6](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-6.jpg)

D先生 ： “うーん・・・。まだ傾向がわからないです。もう一枚、exampleをお願いします。”

![imageVLM1-23-7](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-7.jpg)

D先生 ： “やっぱり、合成画像の位置検出の方が比較的にうまく行っていると思います。そりゃそうだ・・・。（合成画像の場合には、）白い点がどこにあるのかを見つけるだけですからね。もう一枚だけ行ってみましょう。”

![imageVLM1-23-8](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-8.jpg)

D先生 ： “率直にいって、合成画像だけをたくさん学習すれば、もっとうまく予測できるようになると思いますね。あと、合成画像の場合には2つの画像を並べて比較することも不要です。1枚の画像でも十分判別可能！！そうでしょ？FOUNDER・・・？”

### （論理のロジック）

### A = B
### B = C
### よって、A = C

QEU:FOUNDER ： “そうですよ。・・・でも、小生は、ちょっとした**「VLM論理の実験をやってみたい」**んですよ。我々が昔に設計したディプラーニングモデルと比較して、このVLMモデルは、はるかに高い能力を持っています。・・・であるならば、いっそのこと、「VLMモデルの中で生画像を合成画像に変換してもらいたい」んです。”

D先生 ： “どういう意味？”

QEU:FOUNDER ： “現在の学習データには、生画像と合成画像の間には関連はありません。おそらく、このVLMモデルは2種（生と合成）の画像が別の物体を計測していると思っているはずです。その証拠が、Pre-trainで合成画像を推論したとき反応です。”

D先生 ： “もし、（VLMが）生画像と合成画像が同じものだとわかったら？う～ん・・・、そういう考え方もあるなあ。”

![imageVLM1-23-9](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-9.jpg)

QEU:FOUNDER ： “もし、つぎのトライアルでも全くだめならば、**Unslothへの展開を考えなければならない**ですね。Unslothが採用しているLlama3.2-11b-visionは、Phi3モデルよりも明らかに（パラメタが多く）賢いでしょうから・・・。”



## ～ まとめ ～

QEU:FOUNDER ： “遠くの国で、いままで**「ありそうでなかったこと」**が、とうとう起こったそうですよ。”

![imageVLM1-23-10](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-10.jpg)

C部長 : “**口水**って？ “

[![MOVIE1](http://img.youtube.com/vi/VTIZAuNf5tI/0.jpg)](http://www.youtube.com/watch?v=VTIZAuNf5tI "明報五點半新聞直播 (2024.10.01) 外賣郎向飲品內吐口水")

QEU:FOUNDER ： “**「ケータリング・サービスの人が、お客の食事にツバを混ぜた」**です。”

C部長 : “ギャーッ！！しかし、そいつも「プロ」じゃないなあ・・・。”

![imageVLM1-23-11](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-11.jpg)

QEU:FOUNDER ： “は・・・？**プラットフォーム・ビジネスの下で働いている人は、全然プロじゃない**ですよ。その一方で、ちゃんと雇われている人（↑）は、きちんと給料が上がって年々リスペクトされてきています。なにしろ、***「Sandwich Artist」***ですよ！！”

C部長 : “***「You are the face of our global brand.」***・・・。プラットフォーム・ビジネスの下で働いている人は、アホらしいと思うわね。”

![imageVLM1-23-12](/2024-10-03-QEUR23_VIVLM23/imageVLM1-23-12.jpg)

QEU:FOUNDER ： “**人を福利なしで安く働かせるだけが目的のプラットフォーム・ビジネスは、あと2年ぐらいしか持たない**でしょう。だれもやらなくなるし、製品（サービス）も安全ではない。”

[![MOVIE2](http://img.youtube.com/vi/OoIQRwur_x4/0.jpg)](http://www.youtube.com/watch?v=OoIQRwur_x4 "自民・立憲・公明、３党首がダメすぎた 「きれいな自民党」出身")

C部長 : “彼らが悪いのではない。人々が**当たり前の要求をしている**だけです。”

QEU:FOUNDER ： “今までが異常だっただけです。”
