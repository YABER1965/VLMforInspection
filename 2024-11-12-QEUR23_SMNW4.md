---
title: QEUR23_SMNW4 –EMBEDDINGを予測のために活用する
date: 2024-11-12
tags: ["QEUシステム", "メトリックス", "Python言語", "Siamese Network", "NSOARTC", "データセット", "Embedding", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW4 –EMBEDDINGを予測のために活用する

## ～ ここまでやった！あとはご自分で遊んでください。 ～

### ・・・ ウィニング・ランです。前回のつづきです。 ・・・

D先生 ： “コレ(↓)を見るとEmbeddingの有用性がわかるでしょ？”

![imageSMN1-5-1](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-1.jpg)

C部長 ： “なるほど、Embeddingによる予測の方が実用的になるかもしれません。なにしろ、**SNモデルを通して「製品品質」を抽象化**したわけですね。”

QEU:FOUNDER ： “今回は、ウィニング・ラン（延長戦）としてEmbeddingを使ってあそんでみましょう。Embeddingを使った予測は、モデルによる直接の予測よりも有用なのかどうか・・・。それでは、プログラムをドン！！”

```python
# ---
import os
os.environ["KERAS_BACKEND"] = "tensorflow"

# ---
import keras
import numpy as np

######################################
# DATASET LOADING
######################################
# ---
from datasets import load_dataset

# データセットの読み込み
dataset = load_dataset("YxBxRyXJx/SNWimages_test_1111")
dataset = dataset['train']

# レコードの配列をランダムにシャッフル
shuffled_dataset = dataset.shuffle(seed=42)  # seedは任意の数値で固定することができます

# ----
print("Test len: ", len(shuffled_dataset))
# シャッフルされたデータセットを表示
print(shuffled_dataset['label'])

# ---
X_test = np.zeros([len(shuffled_dataset), 26, 36])
y_test = np.zeros(len(shuffled_dataset))

# ---
for i in range(len(shuffled_dataset)):
    X_test[i,:,:] = np.array(shuffled_dataset[i]['image'])
    y_test[i] = int(shuffled_dataset[i]['label'])

# ---
#shuffled_dataset[0]['image'].size
image_size = 36*26

# ---
# グラフ化
import matplotlib.pyplot as plt

for i in range(10):
    plt.subplot(1, 10, i + 1)
    plt.imshow(X_test[i], cmap="gray")
    plt.title(f'{y_test[i]}')
    plt.axis("off")

# ---
X_test = X_test.reshape(-1, image_size)
X_test = X_test / 255.0
print("X_test shape:", X_test.shape)

# ---
# 1回あたりのデータ生成処理。これができるからSiamese Networkはらくちん！
def one_turn_careation(i, X, y, X_pairs, y_pairs, yp_detail):

        digit = y[i]

        # 同じLabelを表すランダムな画像を見つけます。これは正のペアです。
        positive_digit_index = np.random.choice(np.where(y == digit)[0])

        # 画像のペアをリストに追加します。     
        X_pairs.append([X[i], X[positive_digit_index]])

        # これは正のペアなので、真のラベルは 0 です。同じLabelを表す画像間の距離は小さいはずなので、ラベルとして 0 を使用します。     
        y_pairs.append([0])
        yp_detail.append([0, digit, y[positive_digit_index], positive_digit_index])

        # 異なるLabelを表すランダムな画像を見つけます。これは負のペアです。
        negative_digit_index = np.random.choice(np.where(y != digit)[0])

        # 画像のペアをリストに追加します。
        X_pairs.append([X[i], X[negative_digit_index]])

        # これは負のペアなので、真のラベルは 1 です。異なるLabelを表す画像間の距離は大きいはずなので、ラベルとして 1 を使用します。
        y_pairs.append([1])
        yp_detail.append([1, digit, y[negative_digit_index], negative_digit_index])
        
        return X_pairs, y_pairs, yp_detail

# ---
# 正と負の画像のペアを使用して、Siamese Network をトレーニングします。
# 正のペアは2 つの合格品の画像で構成され、負のペアは合格品と不合格品の2 つの画像で構成されます。
# ---
def generate_pairs(X, y):
    """
    指定された画像の配列から、ポジティブとネガティブの画像のペアのコレクションを作成します。
    正のペアにはLabel=0の画像が 2 つ含まれます。負のペアにはLabel=0とLabel!=0という2 つの画像が含まれます。
    """
    X_pairs = []
    y_pairs = []
    yp_detail = []
    # ペア情報を生成する
    for i in range(len(X_test)):
        if y[i] == 0:
            # one turn
            X_pairs, y_pairs, yp_detail = one_turn_careation(i, X, y, X_pairs, y_pairs, yp_detail)
        
    # ---    
    indices = np.arange(len(X_pairs))
    np.random.shuffle(indices)

    return np.array(X_pairs)[indices], np.array(y_pairs)[indices], np.array(yp_detail)[indices]

# ---
# モデルのトレーニングとテスト用のペアを生成しましょう。
# ---
X_test_pairs, y_test_pairs, y_test_detail = generate_pairs(X_test, y_test)
print("X_test_pairs shape:", X_test_pairs.shape)
print("--- y_test_detail ---")
print(y_test_detail)

# ---
# データフレーム化
import pandas as pd

df_org = pd.DataFrame(y_test_detail,columns=["diff","pic1","pic2","index"])
df_org

```

QEU:FOUNDER ： “今回は、前回に学習したモデルを使って予測し、その能力を検証します。検証用のデータは、このデータフレーム（↓）をベースとします。”

![imageSMN1-5-2](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-2.jpg)

D先生 ： “「INDEX」のコラムの情報は、何ですか？”

QEU:FOUNDER ： “ペア画像のうち、計測側の画像がDETASET上の、どのINDEXに当たるかを示しています。さらにプログラムのつづきをば・・・。”

```python
# ---
import keras
from keras import Input
from keras.layers import Dense, Lambda
from keras.ops import norm
from keras.models import Sequential, Model
from keras.saving import register_keras_serializable
import tensorflow as tf
from tensorflow.keras import backend as K
# ---
# 距離は切り替え可能！
from scipy.spatial.distance import chebyshev, minkowski

# ---
# Register the custom function for serialization
@register_keras_serializable()
def euclidean_distance(twins):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    twin1_output, twin2_output = twins
    return tf.sqrt(tf.reduce_sum(tf.square(twin1_output - twin2_output), axis=1, keepdims=True))

# Define inputs
input1 = Input(shape=(image_size,))
input2 = Input(shape=(image_size,))

# Define the network
network = Sequential(
    [
        Input(shape=(image_size,)),
        Dense(512, activation="relu"),
        Dense(256, activation="relu"),
        Dense(128, activation=None),
    ]
)

# Create twin networks
twin1 = network(input1)
twin2 = network(input2)

# Compute distance using Lambda layer with output_shape specified
distance = Lambda(euclidean_distance, output_shape=(1,))([twin1, twin2])

# Define the model
model = Model(inputs=[input1, input2], outputs=distance)

# Define and register contrastive loss function for serialization
@register_keras_serializable()
def contrastive_loss(y, d):
    margin = 1
    y = tf.cast(y, d.dtype)
    loss = (1 - y) / 2 * K.square(d) + y / 2 * K.square(K.maximum(0.0, margin - d))
    return loss

# ---
# モデルの保存
# ---
#model.save("drive/MyDrive/nsoartc_tanshi_model.keras")

# ---
# モデルの呼び出し
# ---
from tensorflow.keras.models import load_model

model = load_model("drive/MyDrive/nsoartc_tanshi_model.keras")

# ---
# Display the loaded model's architecture
model.summary()

```

D先生 ： “そういえば、前回のプログラムには、**モデルのセーブ（保存）命令**について説明していなかったですね。”

QEU:FOUNDER ： “上記のコメント文を参考にしてください。じゃあ、ここでモデルが与えられたので予測をしてみましょう。”

```python
# ---
num_predict = 1200

# ---
# 10pcsだけ、まとめて計測する
predictions = model.predict([X_test_pairs[0:num_predict, 0], X_test_pairs[0:num_predict, 1]])

# ---
# データフレーム化
df = pd.DataFrame(y_test_detail[0:num_predict],columns=["diff","pic1","pic2","index"])
df['prob'] = np.array(predictions).flatten()

# ---
# 層別ヒストグラムの描画
plt.figure(figsize=(10, 6))

# カテゴリごとにヒストグラムを描画
for category in df['diff'].unique():
    subset = df[df['diff'] == category]
    plt.hist(subset['prob'], bins=30, alpha=0.5, label=f'diff: {category}')

# グラフの設定
plt.title('Stratified Histogram')
plt.xlabel('prob')
plt.ylabel('frequency')
plt.legend()
plt.grid(True)

# グラフの表示
plt.show()

```

C部長： “おおっ・・・。1200件もまとめて予測をしたんですね。それを層別ヒストグラムにまとめると・・・。”

![imageSMN1-5-3](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-3.jpg)

D先生 ： “うわぁ～。2つの山が、かなり重なっていますね。”

QEU:FOUNDER ： “前回の正確度(ACCURACY)計算で、90％もなかった理由がわかりますね。そもそも、**入力（検査）画像もガタが大きい設定になっている**ので、合格品か不合格品なのかがわかりにくいものがあるんですよ。つぎは、いよいよEmbeddingを使った予測に進みましょう。”

```python
# ---
# シーケンシャル モデルを参照して、新しい画像のEMBEDDINGを生成することができます。
embedding_model = model.layers[2]

# ---
# 単位空間のサイズはn=30とする
num_predict = 30
mx_embeddings_tani = np.zeros([num_predict, 128])
mx_tani_detail = np.zeros([num_predict, 4])
# ---
# EMBEDDINGの生成： 標準ベクトル（Diff = 0）
for i in range(num_predict):
    digits = np.where(y_test_detail[:,0] == 0)[0]
    index = np.random.choice(digits)
    image_index = int(y_test_detail[index, 3])
    temp_embeddings_tani = embedding_model.predict(X_test[image_index].reshape(1, -1))[0]
    print(temp_embeddings_tani)
    mx_embeddings_tani[i,:] = temp_embeddings_tani
    mx_tani_detail[i,:] = y_test_detail[index, :]
# ---
print(mx_embeddings_tani)
print("--- mx_tani_detail ---")
print(mx_tani_detail)

# ---
# データフレーム化(TANI)して、内容を確認する
#import pandas as pd
df_tani = pd.DataFrame(mx_tani_detail,columns=["diff","pic1","pic2","index"])
#df_tani

# ---
# 標準ベクトルを生成する
arr_ambedding_tani = np.zeros(128)
for i in range(128):
    arr_ambedding_tani[i] = round(np.mean(mx_embeddings_tani[:,i]),5)
# ---
print(arr_ambedding_tani)

```

D先生 ： “Embeddingにおいては、**平均されたベクトルを使う**んですね。”

![imageSMN1-5-4](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-4.jpg)

QEU:FOUNDER ： “ねえ？Embeddingって便利でしょう？さっき行ったモデルでの予測は、ペア画像を入力して予測するんです。それに対して、**Embeddingを使えば単一画像で予測ができる**んです。プログラムをつづけましょう。いよいよ予測結果の発表です。”

```python
# ---
num_predict = 300
mx_embeddings_measA = np.zeros([num_predict, 128])
mx_measA_detail = np.zeros([num_predict, 4])
# ---
# EMBEDDINGの生成： 計測ベクトル（Diff = 0）
icount = 0
for index in range(1200):
    if y_test_detail[index,0] == 0 and icount < num_predict:
        image_index = int(y_test_detail[index, 3])
        mx_embeddings_measA[icount,:] = embedding_model.predict(X_test[image_index].reshape(1, -1))
        mx_measA_detail[icount,:] = y_test_detail[index, :]
        icount = icount + 1

# ---
# EMBEDDINGの生成(A)： 標準ベクトル（Diff = 0）
arr_distance = []
for i in range(num_predict):
    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(arr_ambedding_tani, mx_embeddings_measA[i,:], 4) # p=4 
    arr_distance.append(vDistance)

# ---
# データフレーム化(MEAS_A)
#import pandas as pd
df_measA = pd.DataFrame(mx_measA_detail,columns=["diff","pic1","pic2","index"])
df_measA['distance'] = arr_distance

# ---
mx_embeddings_measB = np.zeros([num_predict, 128])
mx_measB_detail = np.zeros([num_predict, 4])
# ---
# EMBEDDINGの生成： 計測ベクトル（Diff = 1）
icount = 0
for index in range(1200):
    if y_test_detail[index,0] != 0 and icount < num_predict:
        image_index = int(y_test_detail[index, 3])
        mx_embeddings_measB[icount,:] = embedding_model.predict(X_test[image_index].reshape(1, -1))
        mx_measB_detail[icount,:] = y_test_detail[index, :]
        icount = icount + 1

# ---
# EMBEDDINGの生成(B)： 標準ベクトル（Diff = 1）
arr_distance = []
for i in range(num_predict):
    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(arr_ambedding_tani, mx_embeddings_measB[i,:], 4) # p=4 
    arr_distance.append(vDistance)

# ---
# データフレーム化(MEAS_B)
#import pandas as pd
df_measB = pd.DataFrame(mx_measB_detail,columns=["diff","pic1","pic2","index"])
df_measB['distance'] = arr_distance

# ---
df_all = pd.concat([df_measA, df_measB], axis=0)

# ---
# 層別ヒストグラムの描画
plt.figure(figsize=(10, 6))

# カテゴリごとにヒストグラムを描画
for category in df_all['diff'].unique():
    subset = df_all[df_all['diff'] == category]
    plt.hist(subset['distance'], bins=30, alpha=0.5, label=f'diff: {category}')

# グラフの設定
plt.title('Stratified Histogram')
plt.xlabel('distance')
plt.ylabel('frequency')
plt.legend()
plt.grid(True)

# グラフの表示
plt.show()

```

C部長： “とうとうでたね・・・。正確度は90％ぐらいいくんじゃないだろうか・・・。”

![imageSMN1-5-5](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-5.jpg)

QEU:FOUNDER ： “今回は標準ベクトル(Embedding)を固定しているので、各々のレコードの質を評価することができます。質の悪い画像は学習のときに消して、**再学習**すればいいんですよ。”

D先生 ： “そうすれば予測精度が上がってくるでしょうね。そういえば、FOUNDERは、距離計算において、なぜMinkowski距離を使ったんですか？”

![imageSMN1-5-6](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-6.jpg)

QEU:FOUNDER ： “本当は、マンハッタン距離でもよかったんです。つまり、距離の選択基準は「適当」です（笑）。ただし、小生はユーグリッド距離が嫌いなんです。マハラノビス距離をわざわざ使いたい人は、自分でプログラムを改造してやってみてください。小生は、全く興味がないので・・・。”

![imageSMN1-5-7](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-7.jpg)

D先生 ： “今回で、外観検査自動機のプロジェクトも終わりですかね。今回の開発を通じて、我々の理念のうち、Industrie5.0/Embeddingの意味が分かってきました。これと同様に、LMMでもEmbeddingを開発ターゲットにするんですか？”

QEU:FOUNDER ： “そのつもりです。”

## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “製品品質のバラツキを減らす程度であればPDCAサイクルを回す程度でも解決可能かもしれないが、モノの価値を上げることはできません。ここまで追い込まれたJ国（↓）、もうそろそろ考え方をかえないと・・・。”

![imageSMN1-5-8](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-8.jpg)

## おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

C部長 : “PDCAサイクルの行きつく先が、QC指導者の一言：「皆さん、テレビを見てください」ですからね。それにしても、彼らは変わらないですよね。頑固なのか？”

![imageSMN1-5-9](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-9.jpg)

QEU:FOUNDER ： “まあ、古いんですよ。もう考え方が60年代、デミング時代から全く進歩していない・・・。そして、その**「遅れた考え方を世に押し売りして飯を食っている人たち」**がいる。おっと、「過去形（ひとたちがいた）」かな？コンサルタントといいます。J国は1990年代後半に大不況に陥り、多くの大企業が高齢者（50歳以上）をリストラしました。**その彼らが「進路」として選んだ選択肢の一つが、コンサルタントだった**んです。そして、あのころは政府もコンサルタント費用への**金銭的援助は手厚かった**ですよ。”

C部長 : “いいなあ・・・。政府は、あの頃の人に対しては、いたせりつくせりだ・・・。”

![imageSMN1-5-10](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-10.jpg)

QEU:FOUNDER ： “当の本人は、**「あのころのワシは大変だった。それに引き換え、最近の若いもんは・・・」**と、思ってるぜ・・・（笑）。さて、その政府からお墨付きが得られたコンサルタント様が、その依拠としてのは自分が昔、大企業で得た肩書と会社で得た知識だったんです。さて、その、彼らの知識というのは・・・。”

C部長 : “1990年代で50歳か・・・。彼らの仕事盛りは30歳だから、その知識の鮮度は70～80年代ですね。”

QEU:FOUNDER ： “それら、ひいおじいさんたちのノウハウ（↑）を、なるべく変えずに今日まで引っ張りに引っ張ってきたわけです。J国は・・・。その一方で、海外では・・・。”

![imageSMN1-5-11](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-11.jpg)

C部長 : “たしかに・・・。昔みた、あの映画でも、広告代理店のT〇S売り込みがすごかったからなあ・・・。新聞でも、**「T〇Sは万能だ！スタバでも使える。J国スゴイ！」**とかなんとか・・・。一方、そのころの海外では、ゆっくりとディープラーニングが実用化に向かって言ったんですよね。”

![imageSMN1-5-12](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-12.jpg)

QEU:FOUNDER ： “2000年代の、欧米大学のイノベーションのチカラはすごかったですよね。コンピュータのノーベル賞（チューリング賞）をとった、あの方（↑）でも、短期間にこれだけのイノベーションを起こしたんです。ちなみに、今回我々が使ったSiamese Networkというのは彼の2005年の発明（図中では1993）の一つです。”

C部長 : “J国でも、大学を通じて、このレベルのイノベーションは起きなかったのか・・・。”

![imageSMN1-5-13](/2024-11-12-QEUR23_SMNW4/imageSMN1-5-13.jpg)

QEU:FOUNDER ： “その頃のJ国の大学の状況はこの程度（↑）です。政府も、大学に金を出すくらいなら、コンサルタントに補助金を出すでしょう。**「子に金を出すな、そのくらいならば家長に金を出せ」**という、**立場主義の政策的な発現**ですな・・・。まあ、どのみち、これからはコンサルタント業も衰退していくでしょう。**「売り物」がなくなった**から・・・。”
