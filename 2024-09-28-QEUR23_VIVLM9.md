---
title: QEUR23_VIVLM9 –  ファインチューニングの学習データを少しだけ工夫する
date: 2024-09-28
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM9 –  ファインチューニングの学習データを少しだけ工夫する

## ～ まだまだじゃ。失敗は、成功の元・・・。 ～

QEU:FOUNDER ： “前回のファインチューニングの第1回のトライアルは、率直に言って失敗でした。そこで、今回は少しだけ「工夫」を加えたいと思います。”

![imageVLM1-10-1](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-1.jpg)

D先生 ： “ここで、以前、我々が開発した**SOARTCメトリックスによる外観検査自動機の経験(↓)**を思い出します。あのときは端子の種類を追加しましたね。前回は正方形端子なので、今回は丸形端子とか・・・。”

![imageVLM1-10-2](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-2.jpg)

QEU:FOUNDER ： “端子形状を変えたデータを追加しました。こんな感じ(↓)で・・・。”

![imageVLM1-10-3](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-3.jpg)

D先生 ： “やっぱり、「丸と角」端子の画像を使いましたね。でも、**「simple」ってフォルダ**は何ですか？”

![imageVLM1-10-4](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-4.jpg)

D先生 ： “へっ！？なんで、こんな画像をわざわざ作ったのですか？”

QEU:FOUNDER ： “**「画像に貼り付けた座標をもとに、不良個所のアドレスを出力する」**ことが、今回の目的です。そのためには、中間段階として、もっと問題を簡単にして、**「画像上の赤い星を見つけてください」という質問**に変えてみたんです。”

![imageVLM1-10-5](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-5.jpg)

QEU:FOUNDER ： “あと、データ数はtrainが500件、testが300件になるようにしました。前回よりも、少しだけデータ量を多くしました。それでは、ファインチューニングの学習結果を見てみましょう。以下の結果は、「画像の上部にある文字を読んでください」と指示したものです。”

![imageVLM1-10-6](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-6.jpg)

D先生 ： “これはOCR機能の範囲内なので、Phi-3-visionでは、その程度の課題は簡単にできるでしょう。やはり学習結果を見てみたいです。”

**（前回の学習曲線）**

![imageVLM1-10-7](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-7.jpg)

**（今回の学習曲線）**

![imageVLM1-10-8](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-8.jpg)

D先生 ： “前回と今回を比較して、ほぼ同じ損失値の推移ですね。いよいよ、肝心の推論の結果ですが・・・。”

![imageVLM1-10-9](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-9.jpg)

QEU:FOUNDER ： “新データで学習しても、このモデルは、まだまだ実力不足ですね。もう1件だけ、追加で推論結果を見たいですか？”

D先生 ： “う～ん・・・、もう一回お願いします・・・。”

QEU:FOUNDER： “はいはい。いやぁ、残念ね・・・。”

![imageVLM1-10-10](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-10.jpg)

D先生 ： “ああ、だめか・・・。・・・でも、考えてみれば、以前のプロジェクト(SOARTC外観検査自動機)でも同じ展開でした。メトリックスを使用した合成画像を使う必要があるのかもしれません。FOUNDER・・・。今回のプログラムでは、どんなサイズの画像でも読み込むことができます。・・・でも、システムの内部ではどのようなサイズで処理されているんですかねえ・・・？”

```python
# ---
# 7. Testing
def inference_with_base_model(id, dataset):
  image = dataset[id]["image"].convert("RGB")

  userPrompt = "Referenced image has two images inside. Compare the two images and find the dif-ferences. The two images have coordinate letters 1 to 9 horizontally and U, C, D vertically to find po-sition. You should compare the condition of the cubes at each position one by one. The top image is one of passed product. You should evaluate whether the product in the bottom image is passed or de-fective. If you find differences in the bottom image, explain its location and defect name."
  messages = [
      {"role": "user", "content": f"<|image_1|>\n{userPrompt}"}
  ]

  prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

  inputs = processor(prompt, [image], return_tensors="pt").to(device)
  inputs['cache_position'] = None  # ここでcache_positionを追加

  generation_args = {
      "max_new_tokens": 512,
      "temperature": 0.3,
      "do_sample": True  # do_sampleをTrueに設定
  }

  generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)

  generate_ids = generate_ids[:, inputs["input_ids"].shape[1]:]
  response = processor.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]

  return response

```

QEU:FOUNDER： “**我々の前回のVISIONプロジェクトでは、224x224サイズの画像を読み込みました**。もし画像データをより大きくすると、多量のメモリを使うので計算資源がかかります。たぶん今回も同じくらいじゃない？ちなみに、transformerの資料を見たのですが、そこら辺の情報はわからなかったです。”

D先生 ： “そもそも、我々がメトリックスの合成画像を使用したのは、**モデルに入力できる画像が小さすぎる**ことが原因だったですよね。”

QEU:FOUNDER ： “・・・というか、**外観検査の場合は、画像の95％は良品と同じであり、たった5%だけが良品と異なる**画像を評価する必要があります。画像データを大きくできないのであれば、適切なデータ処理を通じて、異常情報を濃縮する必要があったんです。”

D先生 ： “次は、いよいよ**「メトリックスの適用」**ですね。”

QEU:FOUNDER  ： “今回は、前回よりも少しだけ進化させます。開発テーマになるので、たぶん長くなるよ。”


## ～ まとめ ～

### ・・・ いままでの議論の結論になります ・・・

QEU:FOUNDER ： “いままでの議論が、非線形プロセスに関するQEUシステムの考え方ですね。”

![imageVLM1-10-11](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-11.jpg)

C部長 : “**PDCAサイクル**ってダメですか？”

![imageVLM1-10-12](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-12.jpg)

C部長 : “いまでも多くの人が、日常的に**「PDCAをまわす」**と言っていますよ。”

QEU:FOUNDER ： “**PDCA(Plan-Do-Check-Act)ってリニア手法の産物ですよ**。非線形のプロセスにリニア手法を適用すると、バラツキを抑えると必ず結果の分布がターゲットからずれます。そのずれを修正するのが、A(Act)の段階です。”

![imageVLM1-10-13](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-13.jpg)

QEU:FOUNDER ： “ですから、我々のように**非線形に適合した手法をつかったらAの段階は不要になります**。もし、結果に満足せず継続して合わせ込みを究めたいのであれば、ひきつづきDMAICSサイクルを回して、つぎのD段階に行けばいいんです。”

C部長 : “だから、ディープラーニング時代の非線形のプロセスの制御において**「DMAICS(Define-Measure-Analysis-Improve-Control-Shear)」は必然である**と・・・。”

QEU:FOUNDER ： “そういうことね。はっきり言って、**PDCAという言葉を使っている限りは景気はよくならない**と思います。そういえば、我らがUnslothがとうとうMultimodalのモデルをリリースしたね。”

![imageVLM1-10-14](/2024-09-28-QEUR23_VIVLM9/imageVLM1-10-14.jpg)

C部長 : “なぜ、すぐに使わないんですか？”

QEU:FOUNDER ： “Phi3-visionも十分に良いモデルです。それを使っているので、**モデルを途中でかえたくない**んです。途中で切り替えると、せっかく工夫をしたときの手ごたえがわからなくなります。”

C部長 : “だれか、先回りしてVision-Unslothの適用事例をつくってくれないかなあ・・・。”

QEU:FOUNDER ： “だれか、奇特なお方が支援してくれることを期待します。”
