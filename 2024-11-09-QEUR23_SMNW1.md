---
title: QEUR23_SMNW1 – NSOARTC合成画像を作ってみる
date: 2024-11-09
tags: ["QEUシステム", "メトリックス", "Python言語", "Siamese Network", "NSOARTC", "データセット", "Embedding", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW1 – NSOARTC合成画像を作ってみる

## ～ 最も簡単な外観検査のトライアルをやってみました ～

QEU:FOUNDER ： “さて、これからメトリックスの生成に入りましょう。前回は「NSOARTCを使いました」とか言っていましたが、実は「半分しか」使っていません。”

![imageSMN1-2-1](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-1.jpg)

D先生 ： “**NSOA(RT)C**となっています。実は、処理プロセスの下半分のRT法に関する部分は使っていないのですね。”

**（ステップ1）**

![imageSMN1-2-2](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-2.jpg)

**（ステップ2）**

![imageSMN1-2-3](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-3.jpg)

QEU:FOUNDER ： “前回は、上半分しか使っていません。もとの画像が小さすぎるのです。次元削減が極端に進みますからね。今回は、せっかく上半分が終わっているので、その「上半分」を読み込んで「下半分」のみをやっていきましょう。まとめてやるので、上下をまとめてやると時間がかかりすぎるのです。”

C部長 ： “そもそも、そこまで**「前加工(pre-processing)」にこだわる**必要があるのかなあ・・・。”

![imageSMN1-2-4](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-4.jpg)

D先生 ： “C部長、Siamese Networkのモデルの構造を見てごらん・・・。”

QEU:FOUNDER ： “ここまで簡単なディープラーニングのモデルを使って、判別精度をよくするには前加工が必須ですよ。あと、事例のモデルｎ入力情報量が784=28x28になっています。もし、NSOA(RT)Cのアウトプット画像（382x214）を、そのまま使うとどうなると思う？”

C部長： “そういわれてみれば、そうですね。”

QEU:FOUNDER ： “それでは、プログラムを晒します。ドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: metrics_via_NSOARTC(2).py
# NSOARTCメトリックス(下半分)を出力する
# ---------------------------------------------------
# モジュールのインポート
import math
import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt

###########################
# クラスの定義
###########################
# ---
# 距離は切り替え可能！
from scipy.spatial.distance import chebyshev, minkowski

#=================================================
# MAIN PROGRAM : マトリックスの生成と合成画像の表示
#=================================================
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(y,beta*x, 4) # p=4 

    # 絶対値（マンハッタン）距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の変換
    log_beta = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = log_yita - math.log(vDistance+1.0)
    
    return round(log_beta,5), round(log_yita,5), round(log_gamma,5)

# ---------------------------
# Primitive image(beta, yita, gamma)を計算する
def calc_PrimImage(img_Gray_array, img_rgb_array): 
    # ---
    img_Gray_array = img_Gray_array[:, :] / 255.0
    img_rgb_array = img_rgb_array[:, :, :] / 255.0
    # ---
    # 距離(DST)メトリックスの生成
    jmax = 38+1
    imax = 35+1
    DST_matrix = np.zeros([imax,jmax,3])
    MAX_matrix = np.zeros([imax,jmax])
    #icount = 0
    for i, iy in enumerate(list(range(0,214,6))):
        for j, jx in enumerate(list(range(0,382,10))):
            # ---
            arr_cut_Gray = img_Gray_array[iy:iy+5,jx:jx+9].flatten()
            #print(mx_cut_Gray)    
            # --
            arr_cut_red = img_rgb_array[iy:iy+5,jx:jx+9,0].flatten()
            arr_cut_green = img_rgb_array[iy:iy+5,jx:jx+9,1].flatten()
            arr_cut_blue = img_rgb_array[iy:iy+5,jx:jx+9,2].flatten()
            #print(mx_cut_red)   
            # ---
            red_beta, red_yita, red_gamma = calc_soaRT3(arr_cut_red, arr_cut_Gray)
            green_beta, green_yita, green_gamma = calc_soaRT3(arr_cut_green, arr_cut_Gray)
            blue_beta, blue_yita, blue_gamma = calc_soaRT3(arr_cut_blue, arr_cut_Gray)
            # ---
            # yita
            #DST_matrix[i,j,:] = [red_yita, green_yita, blue_yita]
            #MAX_matrix[i,j] = np.sum([red_yita, green_yita, blue_yita])
            # ---
            # gamma
            DST_matrix[i,j,:] = [red_gamma, green_gamma, blue_gamma]
            MAX_matrix[i,j] = math.sqrt(np.sum([red_gamma**2, green_gamma**2, blue_gamma**2]))

    return DST_matrix, MAX_matrix

# ---------------------------
# 画像ファイルの内容を作画する
def draw_image(img_array, str_title, str_type): 
    if str_type == 'Gray':
        # Gray画像を表示
        plt.imshow(img_array, cmap='gray')
    
    else:
        # RGB画像を表示
        plt.imshow(img_array)
    plt.title(str_title)
    plt.axis('off')  # 軸を非表示にする
    plt.show()  

#=================+===============================
# SUB PROGRAM : 画像ファイルを読み込む、パラメタを指定する
#=================================================
# 標準画像を読み込み表示する
standard_image = "small_average_pic_circle.jpg"
# ---
list_image = ["NA"]*9
list_image[0] = "./camera120_2_481_443_92_m009_008_OK_DST.jpg"
list_image[1] = "./camera151_0_365_329_89_m019_003_OK_DST.jpg"
list_image[2] = "./camera7_2_312_417_91_m01_02_BENDNG_DST.jpg"
list_image[3] = "./camera11_0_365_354_92_m013_m001_BENDNG_DST.jpg"
list_image[4] = "./camera2_2_319_425_89_0_0_BENDNG_DST.jpg"
list_image[5] = "./camera8_2_420_344_88_m008_012_BENDNG_DST.jpg"
list_image[6] = "./camera10_0_428_355_90_006_007_BENDNG_DST.jpg"
list_image[7] = "./camera7_2_322_456_92_008_m009_BENDNG_DST.jpg"
list_image[8] = "./camera6_2_438_447_91_005_m009_BENDNG_DST.jpg"
print(list_image)

#=================+===========================
# インプット（2枚の画像）
#=============================================
# ---
# Gray画像ファイルを読み込む
image_path = standard_image
image = Image.open(image_path)

# グレースケールに変換
gray_image = image.convert('L')

# Gray:2次元の配列に変換
img_Gray_array = np.array(gray_image)

# Gray画像を表示
str_title = 'Gray'
str_type = 'Gray'
draw_image(img_Gray_array, str_title, str_type)

# ---
# RGB画像ファイルの読み込み
image_path = list_image[0]
img = Image.open(image_path)

# RGBに変換
img_rgb = img.convert('RGB')

# RGB:2次元x3チャンネルの配列に変換
img_rgb_array = np.array(img_rgb)

# RGB画像を表示
str_title = 'RGB'
str_type = 'RGB'
draw_image(img_rgb_array, str_title, str_type)

#=================+===========================
# メイン計算
#=============================================
# 標準画像を読み込み表示する
# ---------------------------
# Primitive image(beta, yita, gamma)を計算する
DST_matrix, MAX_matrix = calc_PrimImage(img_Gray_array, img_rgb_array)
#print(MAX_matrix)

#=================+===========================
# アウトプット（ヒートマップ）
#=============================================
# ヒートマップを作成する
plt.imshow(MAX_matrix, cmap='hot', interpolation='nearest')

# カラーバーを追加
plt.colorbar()

# タイトルとラベルの設定
plt.title('Heatmap Example')
plt.xlabel('X-axis Label')
plt.ylabel('Y-axis Label')

# ヒートマップを表示
plt.show()

```

QEU:FOUNDER ： “まずは最初の1枚です。この製品は２つとも合格品です。”

![imageSMN1-2-5](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-5.jpg)

D先生 ： “ヒートマップで出力したんですね。たしかに、単純なディープラーニングモデルを使っているんですから、いっそのこと画像よりもベクトルをそのまま入力する方がいいですね。それにしても、特徴がより抽出されてわかりやすくなっています。”

QEU:FOUNDER ： “RT法のいいところは、計測画像の特徴が標準画像を通してフィルタリングされることでしょうね。それに伴い、計測画像のシフトや回転も若干は補正されるでしょう。”

![imageSMN1-2-6](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-6.jpg)

D先生 ： “不良品の画像も見たいですね。”

![imageSMN1-2-7](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-7.jpg)

D先生 ： “カメラの角度によるのですが、不良の見え方は微妙なんですね。ディープラーニングで、果たしてどこまで判別できるのか・・・。今回のラベル設計は、どのようにするのですか？”

![imageSMN1-2-8](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-8.jpg)

QEU:FOUNDER ： “ピンのアドレスを入力します。それが最も簡単です。ちなみに**「’OK’=0」**となります。”

D先生 ： “このヒートマップを画像にするんですか？”

QEU:FOUNDER ： “HFデータセットの設計の件ですね。それは、現時点では未定です。”


## ～ まとめ ～

C部長 : “あっちゃ～ぁ・・・。”

![imageSMN1-2-9](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-9.jpg)

QEU:FOUNDER ： “あ～あ・・・。”

C部長 : “いいことだと思いますか？”

[![MOVIE1](http://img.youtube.com/vi/u2IKBdbsNYU/0.jpg)](http://www.youtube.com/watch?v=u2IKBdbsNYU "やっぱり斎藤元彦の支持者は異常者しかいないとはっきりわかる件")

QEU:FOUNDER ： “ぜんぜん・・・。ろくなことが起こらないと思います。この手（↑）のことが、増えると思います。”

C部長 : “どうすればいいんでしょうね？”

![imageSMN1-2-10](/2024-11-09-QEUR23_SMNW1/imageSMN1-2-10.jpg)

QEU:FOUNDER ： “自分が、（自分がコントロールしている）本当に信頼できるAIを持ち。それで外部からの情報をスクリーニングしながら消化していく時代がくるんじゃないかなあ・・・。そのためには、我々BONSAIシステムの構造はヒントにはなると思います。BONSAI4を企画しているのだが、なかなか手がつかないなあ・・・。”
