---
title: QEUR23_SMNW10 – (祝!)Unslothの「新」VLM用インスタンスを推論で使ってみる
date: 2024-11-12
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW10 – (祝!)Unslothの「新」VLM用インスタンスを推論で使ってみる

## ～ UnslothのTeamは、よくやった！あとは皆が使い倒す義務があります。 ～

### ・・・ 意外と使えて驚いた。 ・・・

D先生 ： “なに？**UnslothがVLM(Visual Language Model)のインスタンスを開発して公開した**って？”

![imageSMNW3-1-1](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-1.jpg)

C部長 ： “Unslothのページを久々に開いてみると、新しいBlog(↑)が出てました。前々からの懸案だったのを、とうとう解決したんですね。すごいですねえ・・・。”

QEU:FOUNDER ： “率直に言って、VLMでUnslothの技術を適用するのは無理だと思っていたので、とてもうれしいです。よく見てみると、今回は**VLM専用のノートブック**も紹介しているじゃないですか・・・。”

![imageSMNW3-1-2](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-2.jpg)

D先生 ： “じゃあ、これにあやかって、学習をやってみますか？”

QEU:FOUNDER ： “まずは、単純な推論をやってみましょう。推論用のプログラムをドン！！”

![imageSMNW3-1-3](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-3.jpg)

QEU:FOUNDER ： “おっと、ここで一言・・・。まずは、ウォームアップとして「猫ちゃん（↑）」の推論をしてみましょう。”

```python
# ---
from unsloth import FastVisionModel # FastLanguageModel for LLMs
import torch

# 4bit pre quantized models we support for 4x faster downloading + no OOMs.
fourbit_models = [
    "unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit", # Llama 3.2 vision support
    "unsloth/Llama-3.2-11B-Vision-bnb-4bit",
    "unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit", # Can fit in a 80GB card!
    "unsloth/Llama-3.2-90B-Vision-bnb-4bit",

    "unsloth/Pixtral-12B-2409-bnb-4bit",              # Pixtral fits in 16GB!
    "unsloth/Pixtral-12B-Base-2409-bnb-4bit",         # Pixtral base model

    "unsloth/Qwen2-VL-2B-Instruct-bnb-4bit",          # Qwen2 VL support
    "unsloth/Qwen2-VL-7B-Instruct-bnb-4bit",
    "unsloth/Qwen2-VL-72B-Instruct-bnb-4bit",

    "unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit",      # Any Llava variant works!
    "unsloth/llava-1.5-7b-hf-bnb-4bit",
] # More models at https://huggingface.co/unsloth

model, tokenizer = FastVisionModel.from_pretrained(
    "unsloth/Llama-3.2-11B-Vision-Instruct",
    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for long context
)

#################################
# 単独画像：猫でやってみる
#################################
from PIL import Image

# ---
#url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg"
#image = Image.open("drive/MyDrive/IMG_6124.JPG").convert("RGB")
image_cat = Image.open("drive/MyDrive/IMG_6124.JPG")

# ---
FastVisionModel.for_inference(model) # Enable for inference!

instruction = "Describe what you see in this image."
messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image_cat,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

from transformers import TextStreamer
text_streamer = TextStreamer(tokenizer, skip_prompt = True)
outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)
response = tokenizer.batch_decode(outputs)
# ---
split_string = '<|start_header_id|>assistant<|end_header_id|>\n\n'
index_response = response[0].index(split_string)
cut_response = response[0][index_response+len(split_string):]
print(cut_response)


# ---
#The image depicts two kittens situated on a desk or table, beneath an Apple monitor, near an elec-trical outlet.\n\nThe kitten on the left boasts a light-brown coat with darker stripes and distinctive white paw pads and fur tuft between its paws. It appears to be gazing down. Meanwhile, the kitten on the right features a predominantly gray coat with lighter and darker gray stripes, small patches of white fur, and white fur tufts between its paws. This kitten seems to be gazing off to the side.\n\nThe light-colored wooden desk or table beneath these kittens appears to support a wooden power outlet and a cable cord wrapped around
#この画像には、Apple モニターの下、コンセントの近くの机またはテーブルの上に 2 匹の子猫が座っている様子が写っています。\n\n左側の子猫は、明るい茶色の毛皮に濃い縞模様、特徴的な白い肉球、足の間の毛の房が特徴です。下を向いているように見えます。一方、右側の子猫は、主に灰色の毛皮に明るい灰色と濃い灰色の縞模様、小さな白い毛皮の斑点、足の間の白い毛の房が特徴です。この子猫は横を向いているように見えます。\n\nこれらの子猫の下にある明るい色の木製の机またはテーブルには、木製の電源コンセントと、その周囲に巻き付けられたケーブル コードが置かれているようです。

```

D先生 ： “推論の結果は、プログラムのコメントとしているんですね。”

QEU:FOUNDER ： “こっちの方がわかりやすいからね。このトライアルは1枚だけの画像です。次は、**2枚の猫の画像で比較をやってみましょう**。”

```python
#################################
# 画像比較その１：猫でやってみる
#################################
# ---
from PIL import Image

# ---
image_cat1 = Image.open("drive/MyDrive/IMG_6124.JPG")
image_cat2 = Image.open("drive/MyDrive/IMG_6125.JPG")

# ---
FastVisionModel.for_inference(model) # Enable for inference!

# ---
images = [image_cat1, image_cat2]

#(case1 instruction)
instruction = "Image1 and image2 are provided. Describe major differences between image1 and im-age2 within 50 words."
#(case2 instruction)
instruction = "Image1 and image2 of two cats are provided. Describe major differences in cat's ac-tion between image1 and image2 within 50 words."

# ---
messages = [
    { "role": "user",
      "content" : [
        {"type" : "text",  "text"  : instruction},
        {"type" : "image", "image" : "image1"},
        {"type" : "image", "image" : "image2"} ]
    }
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    images,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

from transformers import TextStreamer
text_streamer = TextStreamer(tokenizer, skip_prompt = True)
outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)
response = tokenizer.batch_decode(outputs)
# ---
split_string = '<|start_header_id|>assistant<|end_header_id|>\n\n'
index_response = response[0].index(split_string)
cut_response = response[0][index_response+len(split_string):]
print(cut_response)

# ---
#(case1 result)
#The image presents two kittens lying on a wooden surface. One kitten exhibits a relaxed demeanor with its mouth closed, while the other appears startled with its eyes wide open and its mouth open.\n\n**Key differences between the two kittens:**\n\n*   **Facial expression:**\n    *   One kit-ten displays a calm expression with closed lips and eyes relaxed.\n    *   The other kitten appears scared with eyes wide open and lips open in a shocked manner.\n*   **Paw position:**\n    *   One kit-ten keeps both its paws tucked near its body.\n    *   The other kitten displays a paw extended in an open position.\n
#この画像には、木の床に横たわる 2 匹の子猫が写っています。1 匹の子猫は口を閉じてリラックスした様子を見せていますが、もう 1 匹は目を大きく見開き、口を開けて驚いた様子を見せています。\n\n**2 匹の子猫の主な違い:**\n\n* **表情:**\n * 1 匹の子猫は唇を閉じて目がリラックスした穏やかな表情を見せています。\n * もう 1 匹の子猫は目を大きく見開き、唇を開けてショックを受けた様子で怖がっている様子を見せています。\n* **足の位置:**\n * 1 匹の子猫は両足を体に近づけています。\n * もう 1 匹の子猫は足を伸ばして開いた姿勢を見せています。\n

# ---
#(case2 result)
#Here are the differences between the actions of the two cats in the images:\n\n* In image one, the kitten on the left is lying down and looking to the right.\n* In image two, the kitten on the right is al-so lying down but looking up.\n\nThere are no major differences in their actions between the two im-ages.
#画像に写っている 2 匹の猫の行動の違いは次のとおりです。\n\n* 画像 1 では、左側の子猫は横になって右を向いています。\n* 画像 2 では、右側の子猫も横になっていますが、上を見ています。\n\n 2 つの画像では、行動に大きな違いはありません。

```

D先生 ： “質問を変えてみたんですね。それにしても、質問（プロンプト）を少し変えるだけで全然変わりますね。”

QEU:FOUNDER ： “VLMモデルに対して、注目する対象は猫であることを教えたんです。”

C部長： “このノウハウを、外観検査に応用できませんかね？”

![imageSMNW3-1-4](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-4.jpg)

QEU:FOUNDER ： “じゃあ、むかしコネクタの端子検査をシミュレートした実験をもう一度やってみましょう。２つの、**NSOART処理を行った画像**を比較しましょう。LLMは、その違いを認識してくれるのか？それでは、プログラムをドン！！”

```python
#################################
# 比較画像その2：製品検査画像でやってみる
#################################
# ---
from PIL import Image

# ---
image_isp1 = Image.open("drive/MyDrive/CIRCLE_2_305_406_89_0_0_BENDNG_DST.jpg")
image_isp2 = Im-age.open("drive/MyDrive/CIRCLE_2_369_357_91_m006_m012_BENDNG_DST.jpg")

# ---
FastVisionModel.for_inference(model) # Enable for inference!

# ---
#(case1 instruction)
images = [image_isp1, image_isp2]
instruction = "Image1 and image2 are shown. Describe major differences between image1 and im-age2 within 20 words."
#(case2 instruction)
instruction = "Image1 and image2 are shown. Describe major differences between image1 and im-age2 within 20 words. Pay particular attention to where the white circle is."
#(case3 instruction)
instruction = "Image1 and image2 of black and white cylinders are shown. These photos shows the cylinder from above. Describe major differences between image1 and image2 within 30 words. Pay particular attention to where the white cylinder is."

# ---
messages = [
    { "role": "user",
      "content" : [
        {"type" : "text",  "text"  : instruction},
        {"type" : "image", "image" : "image1"},
        {"type" : "image", "image" : "image2"} ]
    }
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    images,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

from transformers import TextStreamer
text_streamer = TextStreamer(tokenizer, skip_prompt = True)
outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)
response = tokenizer.batch_decode(outputs)
# ---
split_string = '<|start_header_id|>assistant<|end_header_id|>\n\n'
index_response = response[0].index(split_string)
cut_response = response[0][index_response+len(split_string):]
print(cut_response)

# ---
#The image shows a collection of light bulbs in two boxes. The primary distinction is that the second box features more bulbs than the initial box.
#この画像には、2 つの箱に入った電球のコレクションが示されています。主な違いは、2 番目の箱には最初の箱よりも多くの電球が入っていることです。

# ---
#The provided images depict different parts of the keyboard's top. Image1 highlights the keys that correspond to the first row of letters, while image2 showcases the entire keyboard.\n\nThe key differ-ence between image1 and image2 is that image1 does not show any keys corresponding to the num-bers or the key containing the symbol in image2, while image1 features a row of keys containing dif-ferent symbols or numbers.\n\nThis suggests that image1 is a more detailed view of the keyboard's top, while image2 is a broader view that includes all the keys.
#提供された画像は、キーボード上部のさまざまな部分を示しています。画像 1 は最初の文字の行に対応するキーを強調表示し、画像 2 はキーボード全体を示しています。\n\n画像 1 と画像 2 の主な違いは、画像 1 には数字に対応するキーや画像 2 の記号を含むキーが表示されていないのに対し、画像 1 にはさまざまな記号や数字を含むキーの行が表示されていることです。\n\nこれは、画像 1 がキーボード上部のより詳細なビューであるのに対し、画像 2 はすべてのキーを含むより広いビューであることを示しています。

# ---
#**Differences Between Image 1 and Image 2:**\n\n*   **Position of White Cylinder**: In **image1**, the white cylinder is at the **left edge** of the image. In **image2**, the white cylinder is at the **right edge** of the image.
#**画像 1 と画像 2 の違い:**\n\n* **白い円柱の位置**: **画像 1** では、白い円柱は画像の **左端** にあります。**画像 2** では、白い円柱は画像の **右端** にあります。

```

D先生 ： “すごいなあ・・・。2つ目のプロンプトでは、かなり我々の**理想となる回答**を得られましたね。”

QEU:FOUNDER ： “今回の画像は、XY軸のアドレスが付記していないですからね。それでも、可能な限り正確な欠陥位置を得ることができました。もし、このやり方で、Finetuningすれば・・・。”

D先生 ： “楽しみですね。”

QEU:FOUNDER ： “・・・ということで、次回につづく。”


## ～ まとめ ～

QEU:FOUNDER ： “H県の県知事選挙は、ある**「麗しきファンタジスタ」**の登場により、大きな展開を迎えました。今後の展開がどうなるかはともかく、J国の歴史にのこる事態になるのは間違いありません。ちょっとだけ、まとめておきましょう。”

![imageSMNW3-1-5](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-5.jpg)

C部長 : “現知事（↓）のパワハラ問題により、H県では選挙が行われました。ここで、**「疑惑」ではなく「問題」**という言葉を使いました。**百条委員会**という第3者会議が開かれ、そこでパワハラに当たるかどうかを審査し、パワハラ認定されています。ちなみに、2人の県職員が「犠牲」になっています。ここで、「現知事」という言葉は、選挙時点では「元知事」です。あえて、わかりやすくなるように表現しています。”

![imageSMNW3-1-6](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-6.jpg)

QEU:FOUNDER ： “その後に選挙が行われ、大方の見方は「チャレンジャーが勝つ」だったのが、なんと！！現知事が防衛したんです！！**有権者は、「パワハラはなかった」、「現知事はいい人」、「現知事は既得権益と戦った」と考えた**わけです。それが、ファンタジスタの大活躍により、すべてPR（広告活動）であったことがばれたんです。・・・というか、SNSにより**「全面公開」**されていた。”

![imageSMNW3-1-7](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-7.jpg)

C部長 : “この写真（↑）は、いくらなんでも「すごすぎる」わ・・・。ちなみに、このファンタジスタは知事選挙の選挙区に所属しています。・・・とすると、この仕事は選挙買収にあたります。”

![imageSMNW3-1-8](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-8.jpg)

QEU:FOUNDER ： “さらに、このファンタジスタはH県から多くの仕事を請け負っていました。選挙のPRでは、**「既得権益者と戦う」**だったのが、実は本人が既得権益者であったと・・・（笑）。実は、さらに複雑な側面があるのだが、そこまで細かいことは言いません。我々の注目している側面は、コレ（↓）です。地図をドン！！Cさん、この図を見て、どう感じますか？”

![imageSMNW3-1-9](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-9.jpg)

C部長 : “チャレンジャーが尼崎で市長をしていたので、その区域で人気があるのは当然です。でも、あれれ・・・？なぜ都市部で現職が人気になるの？田舎には高齢者の比率が高くなるので、現職の人気が高くなるはずなのに・・・。”

![imageSMNW3-1-10](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-10.jpg)

QEU:FOUNDER ： “選挙戦の初期に、テレビ・メディアは現職に有利なシーンをいくつも準備したわけです。ヤラセかどうかは、ここでは問いません。高齢者はテレビをよく見るので、当然、現職を支持するようになります。しかし、選挙後の統計の結果、むしろ都市部がより支持されています。これが謎です。”

![MOVIE1](http://img.youtube.com/vi/rX-7dktNAGE/0.jpg)](http://www.youtube.com/watch?v=rX-7dktNAGE "斎藤元彦・兵庫県知事と「高齢男性」問題。")

QEU:FOUNDER ： “そこで注目されているのは、オッサン（↑）のいう**通俗道徳**の問題です。我々は、それに加味して、「企業の内部統制上、パワハラは不可欠」という認識を付け加えています。”


### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

C部長 : “このコメント（↑）は、**某超有名企業を卒業したコンサルタント様**がQC大会を総括して発言したものでしたっけ・・・。**婉曲ではあるが、モロにパワハラだよね**。いまでも、J国の多くの企業では、従業員を管理し、品質を上げ、生産性を上げるにはパワハラは不可欠だと思っています。”

![imageSMNW3-1-11](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-11.jpg)

C部長 : “へえ・・・、そうなんだ・・・。J国って、**昔から生産性が高くない**んだ。まあ、あたりまえだ。（サービス）残業時間も多かったしね。それを押し付けているボクの立場でいうのも何だが、ホントに**「余計な仕事」**も多いからなあ・・・。”

![MOVIE2](http://img.youtube.com/vi/s85CURADbK4/0.jpg)](http://www.youtube.com/watch?v=s85CURADbK4 "ハラスメント理論から見たジャニーズと宝塚。人生と社会の苦悩の本質。安冨歩東大教授。")

QEU:FOUNDER ： “1年前に言われたじゃないですか、**「東のジャ〇ーズ、西の宝〇」**って・・・。J国って、ハラスメントなくして、組織とコミュニティが持たないようにできているんです。その一方で、ハラスメントが比較的少ない他国の生産性が上がっている。それはなぜか？”

C部長 : “**社会のもつハラスメントが、人々の創造性を殺している**んでしょうね。つまり、J国ではモノとサービスの付加価値を上げる活動が妨害されている。”

![imageSMNW3-1-12](/2024-11-24-QEUR23_SMNW10/imageSMNW3-1-12.jpg)

QEU:FOUNDER ： “**そんな無駄なことはやめましょう！**これがQEUシステムの提案なわけです。思えば、QEUのプロジェクトが本格化した2012？または2013年だったか・・・。ある新聞の1月1日特別版の記事に、「industrie 4.0にJ国も乗り出す！」とかいう景気の良い記事が載っていました。その記事には、ある経営者のコメントが載っており、「この程度のことは、わが社ではすでにやっているが・・・」と記されていました。おいおい・・・。その**「わが社ではすでにやっているが・・・」の維持のために、どれだけの人間が残業をし、パワハラに苦しんでいる**と思っているんだ？そこら辺に思いを馳せる創造力はないのか？**近年のJ国の衰退の根本問題は、ここらへんの想像力の欠如にある**と思うんです。何はともあれ、検査から変えていきましょう。検査は、ハラスメントの宝庫だから・・・。”

