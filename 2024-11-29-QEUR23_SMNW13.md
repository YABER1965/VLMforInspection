---
title: QEUR23_SMNW13 – Unslothの1shotでVLMを学習してみる
date: 2024-11-29
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNW13 – Unslothの1shotでVLMを学習してみる

## ～ かなりうまく行った！！ ～

D先生 ： “前回は、最も普通のZERO-SHOT学習を行ったモデルを使って、1SHOT-PROMPTで推論をしてみました。それによれば、回答の**「枠組み(FORMAT)」**こそ、そこそこ正確に形成できましたが、回答の精度はダメダメです。それでも、VLMモデルでも1SHOT推論が出来るのがわかったのは、新たな知見でした。”

![imageSMNW3-4-1](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-1.jpg)

QEU:FOUNDER ： “1SHOT推論ができれば、やれることが大きく広がります。次は、1SHOT-PROMPTによる学習をやります。ただし、1SHOTにするのは、学習データの一部だけです。この学習データの生成の部分だけは、プログラムをさらしてみましょう。”

```python
# ---
def find_address(mx_image_DST, mx_image_RAW, str_type):
    # ---
    str_address = "NA"
    list_number = list(range(10))
    j_img1 = random.choice(list_number) 
    j_img2 = random.choice(list_number) 
    # ---
    if str_type == 'CYLN_DST':
        str_dir1 = "drive/MyDrive/passed_image/DST_STAR/"
        filename1 = str_dir1 + mx_image_DST[j_img1, 0]
        str_address = mx_image_DST[j_img1, 1]
    else:
        str_dir1 = "drive/MyDrive/passed_image/RAW_STAR/"
        filename1 = str_dir1 + mx_image_RAW[j_img1, 0]
        str_address = mx_image_RAW[j_img1, 1]
    # ---   
    if str_type == 'CYLN_DST':
        str_dir2 = "drive/MyDrive/passed_image/DST/"
        filename2 = str_dir2 + mx_image_DST[j_img2, 0]       
    else:
        str_dir2 = "drive/MyDrive/passed_image/RAW/"
        filename2 = str_dir2 + mx_image_RAW[j_img2, 0]

    return filename1, filename2, str_address

# ---
# 3画像用のプロンプト生成器
def convert_three_conversation(mx_image_DST, mx_image_RAW, sample):
    # ----
    arr_image_DST = mx_image_DST[:, 0]
    #arr_image_DST
    arr_image_RAW = mx_image_RAW[:, 0]
    #arr_image_RAW
    # ----
    str_dir = sample["dir"]
    str_position = sample["position"]
    str_type = sample["type"]
    str_bbox = sample["bbox_str"]
    # ----
    # ランダム画像名とアドレスを読み込む
    filename1, filename2, str_address = find_address(mx_image_DST, mx_image_RAW, str_type)
    # ----
    # answer of 1shot
    str_1shot = f"- image type->{str_type}\n- quantity of pins->27 pins\n- position of star->{str_address}"
    # ----
    image1 = Image.open(filename1) 
    # ----
    instruction = "NA"
    if str_type == 'CYLN_DST':
        instruction = instruction_DST
    else:
        instruction = instruction_RAW
    # ----
    index_bbox = str_bbox.index("<loc")
    str_defect = str_bbox[:index_bbox]
    str_defective = "passed"
    if str_defect != "passed":
        str_defective = "defective"
    # ----
    str_answer = f"- image type->{str_type}\n- quantity of pins->27 pcs\n- your judgement->{str_defective}\n- defect mode->{str_defect}\n- defect position->{str_position}"
    # ----
    image2 = Image.open(filename2) 
    image3 = sample["image"]
    # ----
    conversation = [
        { "role": "user",
          "content" : [
            {"type" : "text",  "text"  : instruction_STAR},
            {"type" : "image", "image" : image1} ]
        },
        { "role": "assistant",
          "content" : [
            {"type" : "text",  "text"  : str_1shot},]
        },
        { "role": "user",
          "content" : [
            {"type" : "text",  "text"  : instruction},
            {"type" : "image", "image" : image2},
            {"type" : "image", "image" : image3} ]
        },
        { "role" : "assistant",
          "content" : [
            {"type" : "text",  "text"  : str_answer} ]
        },
    ]
    return { "messages" : conversation }
    
# ---
# 2画像用のプロンプト生成器
def convert_two_conversation(arr_image_DST, arr_image_RAW, sample):
    # ----
    str_dir = sample["dir"]
    str_position = sample["position"]
    str_type = sample["type"]
    str_bbox = sample["bbox_str"]
    # ----
    instruction = "NA"
    if str_type == 'CYLN_DST':
        instruction = instruction_DST
    else:
        instruction = instruction_RAW
    # ----
    index_bbox = str_bbox.index("<loc")
    str_defect = str_bbox[:index_bbox]
    str_defective = "passed"
    if str_defect != "passed":
        str_defective = "defective"
    # ----
    str_answer = f"- image type->{str_type}\n- quantity of pins->27 pcs\n- your judgement->{str_defective}\n- defect mode->{str_defect}\n- defect position->{str_position}"
    # ----
    if str_type == 'CYLN_DST':
        str_dir = "drive/MyDrive/passed_image/DST/"
        filename = random.choice(arr_image_DST)
        image1 = Image.open(str_dir + filename) 
    else:
        str_dir = "drive/MyDrive/passed_image/RAW/"
        filename = random.choice(arr_image_RAW)
        image1 = Image.open(str_dir + filename)
    image2 = sample["image"]
    
    # ----
    conversation = [
        { "role": "user",
          "content" : [
            {"type" : "text",  "text"  : instruction},
            {"type" : "image", "image" : image1},
            {"type" : "image", "image" : image2} ]
        },
        { "role" : "assistant",
          "content" : [
            {"type" : "text",  "text"  : str_answer} ]
        },
    ]
    return { "messages" : conversation }

# ---
arr_image_DST = mx_image_DST[:, 0]
arr_image_RAW = mx_image_RAW[:, 0]

# ---
# データセットを生成する
converted_dataset = []
for i, sample in enumerate(dataset):
    # ---
    if i < 500:
        converted_dataset.append(convert_three_conversation(mx_image_DST, mx_image_RAW, sam-ple))
    else:
        converted_dataset.append(convert_two_conversation(arr_image_DST, arr_image_RAW, sam-ple))

# ---
converted_dataset

```

C部長 ： “1SHOT推論を500件だけ生成したんですね。このコードは、学習データの構成部分でしょ？前回のものと比べて、ずいぶん複雑だなあ・・・。”

QEU:FOUNDER ： “前回の締めの議論で言ったでしょう？今回のプログラムはどうしても複雑になるって・・・。ですから、今回の学習プログラムは公開しないので、ご興味があれば、過去のプログラムを参考にしてご自分で作成してください。さて、今回は、ちょっとした新たな発見がありました。1SHOTを学習すると、T4(16GB)のGPUではオーバーフローしました。そこで、**しかたなくL4(24GB)のGPUをつかいました**。”

![imageSMNW3-4-2](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-2.jpg)

D先生 ： “1SHOTに変更した目的は、**赤い星の画像（↓）を通して**、欠陥位置の表示方法を教えるためでしたよね。その学習によって、VLMモデルのアタマが大きくなってしまったんですね。”

![imageSMNW3-4-3](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-3.jpg)

QEU:FOUNDER ： “Unslothのメリットは、本来はGPUを節約することなのだが、まあいいか・・・。結果をみてみましょう。最初に1SHOT推論の結果をみてみましょう。”

**(事例1)**

![imageSMNW3-4-4](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-4.jpg)

**(事例2)**

![imageSMNW3-4-5](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-5.jpg)

**(事例3)**

![imageSMNW3-4-6](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-6.jpg)

D先生 ： “やった！「枠組み」がちゃんとできているじゃないですか！！現時点では、精度は求めませんよ・・・。でも、1SHOT推論というのは、モデル学習後も必要なんですか？”

QEU:FOUNDER ： “さあ・・・（笑）。次は、ZERO-SHOT推論でやってみましょう。”

**(事例1)**

![imageSMNW3-4-7](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-7.jpg)

D先生 ： “なんだ・・・。ZERO-SHOT推論でも、全然できるじゃないですか。”

**(事例2)**

![imageSMNW3-4-8](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-8.jpg)

**(事例3)**

![imageSMNW3-4-9](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-9.jpg)

QEU:FOUNDER ： “ここでは、3枚の画像を出力しています。検出精度（正確度）が、いまいちですね。”

D先生 ： “アドレスの文字もちょっとおかしいです。赤い星を検出するためのプロンプトを見せてくれますか？”

**You are a visual inspector who find defect on a product. Image1 shows a group of pins (cylinders) on the product. This image shows pins from above. There are alphanumeric characters located above and left of the product. These alphanumeric characters are used to generate address where the defect is located. Image1 has a red star as defect. You should specify a location of the red star. After your inspection, you should describe the image type, quantity of pins, and position of a red star.**

あなたは、製品上の欠陥を検出する目視検査員です。画像1は、製品上のピン（シリンダー）のグループを示しています。この画像は、ピンを上から見たものです。製品画像の上側と左側には英数字が配置されています。これらは、あなたが見つけた欠陥がどの位置に存在するかを示すアドレスを生成するために使います。画像1には、1つの赤い星があります。あなたは、その赤い星の位置を指定してください。検査後、画像の種類、ピンの数、および赤い星の場所を記述する必要があります。

QEU:FOUNDER ： “上側の数字が１から９であること。左側の文字が「U,C,D」であることについて、明確に記述しておけばよかったですね。”

C部長： “それでも正確度は上がらんと思うが。どうかなあ？”

QEU:FOUNDER ： “このコードを少しだけ改造して、もう一度学習してみましょう。その後、「QWEN2」を使って、同様に学習して比較をしましょう。”

![imageSMNW3-4-10](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-10.jpg)

C部長 ： “今回は、一応アダプタをHugging Faceにアップしたんですね。”

QEU:FOUNDER ： “今回のものは、「成果物」と言えるでしょうに・・・。次にいきましょう。”


## ～ まとめ ～

### ・・・ ご存じありませんか？QEU:FOUNDERは国際派です ・・・

C部長 : “めずらしく、FOUNDERがPCを見て考え事をしている・・・。すいません。FOUNDER!!”

QEU:FOUNDER ： “**Oui!?**”

C部長 : “あれ、その返事は・・・。今はやりの**F語**じゃないですか？”

![imageSMNW3-4-11](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-11.jpg)

QEU:FOUNDER ： “いやいや・・・。実は、G国に関することを考えていたんです。急にCさんから、声掛けがあったので、間違ってF語が出てきました。それにしても、G国の状況は大変らしいねえ・・・。”

![imageSMNW3-4-12](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-12.jpg)

QEU:FOUNDER ： “イーロンさんのいう、**「won’t make it」**って、どういう意味？”

![imageSMNW3-4-13](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-13.jpg)

C部長 : “そんなこともしらないんですか？「自称」国際派が・・・（笑）。ボクが翻訳しますよ。あれあれ・・・。”

QEU:FOUNDER ： “こりゃあ、大変なことになるかもね。”

![imageSMNW3-4-14](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-14.jpg)

C部長 : “あの人たち(↑)も、徐々に温室の外に放出ですか。もう冬です。外は寒いですから、お気をつけて・・・。”

![MOVIE1](http://img.youtube.com/vi/OW3X8zx627A/0.jpg)](http://www.youtube.com/watch?v=OW3X8zx627A "斎藤知事 代理人弁護士の扱いが鬼畜すぎる")

QEU:FOUNDER ： “今回の一連の問題（↑）の根本問題について、孔子がこう言っていたそうだ。それを聞いて、「なるほど」と思いました。”

![imageSMNW3-4-15](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-15.jpg)

C部長 : “なんですか？”

### 孔子様：「恒産なくして恒心無し。恒心無くしてワンチャンあり。」

C部長 : “FOUNDER・・・。メチャクチャいっていませんか？”

![imageSMNW3-4-16](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-16.jpg)

QEU:FOUNDER ： “**ワンチャンは「特需」といういみ**・・・。つまり、より厳密に言うと「国家的大イベントにぶらさがる人たち」をいいます。健全な経済は、**「民間の強靭な需要（恒産）」に支えられるべき**なんです。”

![imageSMNW3-4-17](/2024-11-29-QEUR23_SMNW13/imageSMNW3-4-17.jpg)

C部長 : “ぼくら、腹ペコです・・・。”

やつら満腹 俺たち空腹

腹が減ったら 腹が立つ

雨は降る でも土は固い

鍋には料理 でも量がない

**Them belly full, but we hungry;**

**A hungry mob is a angry mob.**

**A rain a-fall, but the dutty tough;**

**A yot a-yook, but d' yood no 'nough.**

QEU:FOUNDER ： “へえ、これはC部長の趣味！？なんと、ボブ・マーリーかね・・・。”
