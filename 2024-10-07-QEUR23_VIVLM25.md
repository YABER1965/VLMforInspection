---
title: QEUR23_VIVLM25:  単体画像を追加してファインチューニングする
date: 2024-10-07
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "Vision language Model"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VIVLM25:  単体画像を追加してファインチューニングする

## ～ 当たり前だが、「(Phi-3-visionは)できる子」なんです ～

QEU:FOUNDER ： “‘今回のファインチューニングが、この「Phi-3-visionのファインチューニング」の最終回です。もっとも簡単な単体画像を使ってファインチューニングしましょう。”

![imageVLM1-25-1](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-1.jpg)

D先生 ： “N-SOARTCメトリックスの処理画像だけなんですか？生画像があってもよさそうなものなのに・・・。”

QEU:FOUNDER ： “以前、自分で言っていたくせに・・・（笑）。処理画像は、標準画像と比較した結果なので、**この画像を使うことは自動的に標準画像と計測画像を見ていることと同じ**なんです。今回は、ひさびさに、プログラムの一部をさらします。ドン！！”

```python
# ---
#import os
import numpy as np
import pandas as pd

import base64
import requests
from PIL import Image
from io import BytesIO

import transformers
from peft import LoraConfig, get_peft_model, PeftModel

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision.transforms.functional import resize, to_pil_image
from torchvision import transforms

from datasets import concatenate_datasets, load_dataset
import evaluate

import matplotlib.pyplot as plt
from textwrap import wrap

torch.manual_seed(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

dtype=torch.bfloat16

batch_size = 1
base_model_id = "microsoft/Phi-3-vision-128k-instruct"
model_dir = "drive/MyDrive/FTmodels/peft_tanshi_1006"
     
# ---
#2. Load Dataset
raw_train_datasetA = load_dataset("YxBxRyXJx/VMLimages_train_1004") 
raw_test_datasetA = load_dataset("YxBxRyXJx/VMLimages_test_1004") 
# ---
raw_train_datasetB = load_dataset("YxBxRyXJx/VMLimages_SINGLE_train_1006") 
raw_test_datasetB = load_dataset("YxBxRyXJx/VMLimages_SINGLE_train_1006") 
# ---
raw_train_dataset = concatenate_datasets([raw_train_datasetA['train'], raw_train_datasetB['train']])
raw_test_dataset = concatenate_datasets([raw_test_datasetA['train'], raw_test_datasetB['train']])
print(raw_train_dataset)

# ---
#3. Load Model and Processor
model = transformers.AutoModelForCausalLM.from_pretrained(
    base_model_id,
    torch_dtype=dtype,
    device_map="auto",
    trust_remote_code=True,
)

processor = transformers.AutoProcessor.from_pretrained(base_model_id, trust_remote_code=True)
model = model.to(device)
print(model)

```

QEU:FOUNDER ： “コードの内容で変わったところ、わかるでしょ？”

D先生 ： “へえ・・・、こんなやり方があるんですね。2つのデータセットを結合しています。”

![imageVLM1-25-2](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-2.jpg)

QEU:FOUNDER ： “マージによって、データの量がかなり多くなりました。次に学習曲線をみてみましょう。”

![imageVLM1-25-3](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-3.jpg)

D先生 ： “うへぇ・・・、計算時間が相当に増えました。その分だけ、学習損失値が改善されています。ひょっとしたら、比較画像でもパフォーマンスが改善してくれるのか？”

![imageVLM1-25-4](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-4.jpg)

D先生 ： “ああ・・・、やっぱり「がっかり（な結果）」ですね。数枚の結果をみたんでしょう？”

QEU:FOUNDER ： “はい、数枚の結果を見ましたが、「もう全滅」です。これで、Phi-3-visionの非力さに関する我々の仮説がさらに強化されました。今回のテーマは、単品画像での評価です。結果を見てみましょう。”

![imageVLM1-25-5](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-5.jpg)

D先生 ： “やっぱり、我々の仮説の通り、単体では推論のレベルが高いですね。”

QEU:FOUNDER ： “もう一枚、推論結果をみてみましょう。”

![imageVLM1-25-6](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-6.jpg)

D先生 ： “やっぱり結果が微妙にずれています。こんなにわかりやすい処理画像でも、このレベルです。もしも、生データであれば大変な学習量が必要でしょう。・・・ん？ちょっと待った！！位置座標の文字体系が違っていませんか？”

QEU:FOUNDER ： “以前、いじったコードの残骸が修正されずに残っていました。この大量の学習が終わった後なので、もう諦めました。”

D先生 ： “・・・となると、今回の学習後でも、ＶＬＭは、プロンプトの指示をあまりみていないのかな？これはこれで、**「新しい知見」**といえます。さて、いよいよUnslothでllama3.2-visionを使いますか？”

![imageVLM1-25-7](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-7.jpg)

QEU:FOUNDER  ： “まあ、やるつもりではいるが、う～ん・・・。本当にできるのかなあ・・・。Webでちょっと調べたのですが、不安ですな・・・。だめだったら、BONSAIに戻りましょう。”



## ～ まとめ ～

QEU:FOUNDER ： “最近は、こんなことが流行っているそうですね。”

[![MOVIE1](http://img.youtube.com/vi/qI-se-LEY3E/0.jpg)](http://www.youtube.com/watch?v=qI-se-LEY3E "横田一・石破首相、萩生田氏を非公認へ")

C部長 : “そりゃぁ・・・、我々、「庶民には響く話題」ですよ。それが何か・・・？￥ “

QEU:FOUNDER ： “個人的には、こっち（↓）の方が驚きました。”

![imageVLM1-25-8](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-8.jpg)

C部長 : “あ？「とある博士様」が、「これはBRICSシフトのサインだ！！」と言っていましたよ。それが何か？ “

![imageVLM1-25-9](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-9.jpg)

QEU:FOUNDER ： “A国って、怖いと思ったわ・・・。”

C部長 : “すんません。**SUPER PAC**って？”

![imageVLM1-25-10](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-10.jpg)

C部長 : “はぁ・・・。これがLGBTQ関連の代表的SPACなのか・・・。意外なことに、中には共和党員もいますね。”

QEU:FOUNDER ： “要するに、この記事は**選挙のお金の流れが変わった**ことを報道したんでしょ？LGBTQに反感を持つ人の気持ちもわからんでもない。でもね・・・。その反対も**「なんだかなあ」**と思うの・・・。”

[![MOVIE2](http://img.youtube.com/vi/LBCjrBAyqdo/0.jpg)](http://www.youtube.com/watch?v=LBCjrBAyqdo "あれから1年。暴れ続けるイスラエルを許すな")

QEU:FOUNDER ： “LGBTQに反感を持つ人って、むしろ**「自己啓発書が好きな人々」**じゃない？”

![imageVLM1-25-11](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-11.jpg)

QEU:FOUNDER ： “「はぁ・・・（溜息）」って・・・（笑）。”

![imageVLM1-25-12](/2024-10-07-QEUR23_VIVLM25/imageVLM1-25-12.jpg)

C部長 : “A国においても、**「人間は〇ぬまで幸せになれないものなんです」**。懐かしい歌詞です、「殿下」ですか・・・。”

QEU:FOUNDER ： “**「風の時代(new sign of time)」**では、少しは良くなるかもよ・・・（笑）。”
